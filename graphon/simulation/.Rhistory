ggplot(data, aes(fill=cluster, y=percentage, x=cell_type)) +
geom_bar(position="stack", stat="identity")+
xlab("Cell type") + ylab("Percentage")
array_tmp = apply(array_tmp_2,c(2,3),function(x)x/sum(x))[,2:4,thres]
clus_size_perc = array_tmp_2[,1,thres]/sum(array_tmp_2[,1,thres])
array_tmp = cbind(array_tmp,marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","value")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=value, x=cell_type)) +
geom_bar(position="stack", stat="identity") +
xlab("Cell type") + ylab("Percentage")
##### Calculate islet+/-/NA composition of clusters -----
get_composition_array = function(file_list, Lside=T){
array_tmp = array(dim = c(4,7,length(file_list)))
for (i in 1:length(file_list)) {
file = file_list[i]
load(file)
if(Lside){
tmp=L_result_new
}
else{
tmp=R_result_new
}
composition_matrix = matrix(0,nrow=length(tmp$clus_result$clusters), ncol=7)
for (q in 1:length(tmp$clus_result$clusters)) {
tmp_L = L_result_new; tmp_R = R_result_new
islet_res = islet[c(tmp_L$id[tmp_L$clus_result$clusters[[q]]],tmp_R$id[tmp_R$clus_result$clusters[[q]]])]
composition_matrix[q,2:4] = c(length(which(islet_res==1)), length(which(islet_res==0)), sum(is.na(islet_res)))
composition_matrix[q,1] = length(islet_res)
composition_matrix[q,5:7] = composition_matrix[q,2:4]/composition_matrix[q,1]
}
colnames(composition_matrix) = c("Cluster Size", "MN", "Ventral IN", "CoLA/CoSA", "MN(%)", "Ventral IN(%)", "CoLA/CoSA(%)")
rownames(composition_matrix) = c("Cluster 2", "Cluster 1", "Cluster 3", "Iso Nodes")[1:nrow(composition_matrix)]
array_tmp[1:nrow(composition_matrix),,i]=composition_matrix
}
dimnames(array_tmp) <- list(  rownames(composition_matrix), colnames(composition_matrix) ,seq(0.1,0.7,0.1))
return(array_tmp[c(2,1,3,4),,])
}
file_list = list.files(path='/Users/bgemily/Dropbox/DynamicSBM/Data/real_data_results/islet_20170202/',pattern = "*Nclus3",full.names = T)
array_tmp_1 = get_composition_array(file_list, Lside=T)
file_list = list.files(path='/Users/bgemily/Dropbox/DynamicSBM/Data/real_data_results/islet_20170216/',pattern = "*Nclus3",full.names = T)
array_tmp_2 = get_composition_array(file_list, Lside=F)
thres = 4
## composition of estimated clusters
plot(1,type='n',xlim=c(0,1)-0.5,ylim=c(0,1)-0.5,xlab="relative MN(%)",ylab="relative Ventral IN(%)", main="cluster composition")
abline(h=0,lty=2,col="gray"); abline(v=0,lty=2,col="gray")
overall_MN = sum(array_tmp_1[,2,thres])/sum(array_tmp_1[,1,thres])
overall_VenIN = sum(array_tmp_1[,3,thres])/sum(array_tmp_1[,1,thres])
for (q in 1:4) {
for (thres in thres) {
points(array_tmp_1[q,5,thres]-overall_MN, array_tmp_1[q,6,thres]-overall_VenIN,
col=switch(q,"red","green","blue","black"),
cex=(array_tmp_1[q,1,thres]/10),
pch=21)
}
}
overall_MN = sum(array_tmp_2[,2,thres])/sum(array_tmp_2[,1,thres])
overall_VenIN = sum(array_tmp_2[,3,thres])/sum(array_tmp_2[,1,thres])
for (q in 1:4) {
for (thres in thres) {
points(array_tmp_2[q,5,thres]-overall_MN, array_tmp_2[q,6,thres]-overall_VenIN,
col=switch(q,"red","green","blue","black"),
cex=(array_tmp_2[q,1,thres]/10),
pch=24)
}
}
## composition of cell types
array_tmp = apply(array_tmp_1,c(2,3),function(x)x/sum(x))[,2:4,thres]
clus_size_perc = array_tmp_1[,1,thres]/sum(array_tmp_1[,1,thres])
array_tmp = cbind(array_tmp,marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","percentage")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=percentage, x=cell_type)) +
geom_bar(position="stack", stat="identity")+
xlab("Cell type") + ylab("Percentage")
array_tmp = apply(array_tmp_2,c(2,3),function(x)x/sum(x))[,2:4,thres]
clus_size_perc = array_tmp_2[,1,thres]/sum(array_tmp_2[,1,thres])
array_tmp = cbind(array_tmp,marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","value")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=value, x=cell_type)) +
geom_bar(position="stack", stat="identity") +
xlab("Cell type") + ylab("Percentage")
apply(array_tmp_1,c(1,3),function(x)x/sum(x))
apply(array_tmp_1,c(1,3),function(x)x[2:4]/sum(x[2:4]))
array_tmp_1
# composition of estimated clusters: stacked barplot
array_tmp = apply(array_tmp_1,c(1,3),function(x)x[2:4]/sum(x[2:4]))[,,thres]
array_tmp
array_tmp_1[,1,thres]
colSums(array_tmp_1[,2:4,thres])
sum(array_tmp_1[,1,thres])
clus_size_perc = colSums(array_tmp_1[,2:4,thres])/sum(array_tmp_1[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
data = reshape2::melt(array_tmp)
data
data = reshape2::melt(array_tmp)
names(data) = c("Cell_type","Cluster","Percentage")
library(ggplot2)
ggplot(data, aes(fill=Cell_type, y=Percentage, x=Cluster)) +
geom_bar(position="stack", stat="identity")
##### Calculate islet+/-/NA composition of clusters -----
get_composition_array = function(file_list, Lside=T){
array_tmp = array(dim = c(4,7,length(file_list)))
for (i in 1:length(file_list)) {
file = file_list[i]
load(file)
if(Lside){
tmp=L_result_new
}
else{
tmp=R_result_new
}
composition_matrix = matrix(0,nrow=length(tmp$clus_result$clusters), ncol=7)
for (q in 1:length(tmp$clus_result$clusters)) {
tmp_L = L_result_new; tmp_R = R_result_new
islet_res = islet[c(tmp_L$id[tmp_L$clus_result$clusters[[q]]],tmp_R$id[tmp_R$clus_result$clusters[[q]]])]
composition_matrix[q,2:4] = c(length(which(islet_res==1)), length(which(islet_res==0)), sum(is.na(islet_res)))
composition_matrix[q,1] = length(islet_res)
composition_matrix[q,5:7] = composition_matrix[q,2:4]/composition_matrix[q,1]
}
colnames(composition_matrix) = c("Cluster Size", "MN", "Ventral IN", "CoLA/CoSA", "MN(%)", "Ventral IN(%)", "CoLA/CoSA(%)")
rownames(composition_matrix) = c("Cluster 2", "Cluster 1", "Cluster 3", "Iso Nodes")[1:nrow(composition_matrix)]
array_tmp[1:nrow(composition_matrix),,i]=composition_matrix
}
dimnames(array_tmp) <- list(  rownames(composition_matrix), colnames(composition_matrix) ,seq(0.1,0.7,0.1))
return(array_tmp[c(2,1,3,4),,])
}
file_list = list.files(path='/Users/bgemily/Dropbox/DynamicSBM/Data/real_data_results/islet_20170202/',pattern = "*Nclus3",full.names = T)
array_tmp_1 = get_composition_array(file_list, Lside=T)
file_list = list.files(path='/Users/bgemily/Dropbox/DynamicSBM/Data/real_data_results/islet_20170216/',pattern = "*Nclus3",full.names = T)
array_tmp_2 = get_composition_array(file_list, Lside=F)
thres = 4
## composition of estimated clusters: scatter plot
plot(1,type='n',xlim=c(0,1)-0.5,ylim=c(0,1)-0.5,xlab="relative MN(%)",ylab="relative Ventral IN(%)", main="cluster composition")
abline(h=0,lty=2,col="gray"); abline(v=0,lty=2,col="gray")
overall_MN = sum(array_tmp_1[,2,thres])/sum(array_tmp_1[,1,thres])
overall_VenIN = sum(array_tmp_1[,3,thres])/sum(array_tmp_1[,1,thres])
for (q in 1:4) {
for (thres in thres) {
points(array_tmp_1[q,5,thres]-overall_MN, array_tmp_1[q,6,thres]-overall_VenIN,
col=switch(q,"red","green","blue","black"),
cex=(array_tmp_1[q,1,thres]/10),
pch=21)
}
}
overall_MN = sum(array_tmp_2[,2,thres])/sum(array_tmp_2[,1,thres])
overall_VenIN = sum(array_tmp_2[,3,thres])/sum(array_tmp_2[,1,thres])
for (q in 1:4) {
for (thres in thres) {
points(array_tmp_2[q,5,thres]-overall_MN, array_tmp_2[q,6,thres]-overall_VenIN,
col=switch(q,"red","green","blue","black"),
cex=(array_tmp_2[q,1,thres]/10),
pch=24)
}
}
# composition of estimated clusters: stacked barplot
array_tmp = apply(array_tmp_1,c(1,3),function(x)x[2:4]/sum(x[2:4]))[,,thres]
clus_size_perc = colSums(array_tmp_1[,2:4,thres])/sum(array_tmp_1[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cell_type","Cluster","Percentage")
library(ggplot2)
ggplot(data, aes(fill=Cell_type, y=Percentage, x=Cluster)) +
geom_bar(position="stack", stat="identity")
array_tmp = apply(array_tmp_2,c(1,3),function(x)x[2:4]/sum(x[2:4]))[,,thres]
clus_size_perc = colSums(array_tmp_2[,2:4,thres])/sum(array_tmp_2[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cell_type","Cluster","Percentage")
library(ggplot2)
ggplot(data, aes(fill=Cell_type, y=Percentage, x=Cluster)) +
geom_bar(position="stack", stat="identity")
## composition of cell types
array_tmp = apply(array_tmp_1,c(2,3),function(x)x/sum(x))[,2:4,thres]
clus_size_perc = array_tmp_1[,1,thres]/sum(array_tmp_1[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","percentage")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=percentage, x=cell_type)) +
geom_bar(position="stack", stat="identity")+
xlab("Cell type") + ylab("Percentage")
array_tmp = apply(array_tmp_2,c(2,3),function(x)x/sum(x))[,2:4,thres]
clus_size_perc = array_tmp_2[,1,thres]/sum(array_tmp_2[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","value")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=value, x=cell_type)) +
geom_bar(position="stack", stat="identity") +
xlab("Cell type") + ylab("Percentage")
library("optparse")
option_list = list(
make_option(c("-n", "--N_rep"), type="integer", default=50)
);
opt_parser = OptionParser(option_list=option_list);
opt = parse_args(opt_parser);
N_rep = opt$N_rep
# Simulate Gaussian process -------------------------------------------------------------
library(MASS)
gaussprocess <- function(from = 0, to = 300, K = function(s, t) {0.8^abs(s-t)*0.03^2/(1-0.8^2)},
start = 0, m = 300, mu = rep(0, times = m)) {
# Simulates a Gaussian process with a given kernel
#
# args:
#   from: numeric for the starting location of the sequence
#   to: numeric for the ending location of the sequence
#   K: a function that corresponds to the kernel (covariance function) of
#      the process; must give numeric outputs, and if this won't produce a
#      positive semi-definite matrix, it could fail; default is a Wiener
#      process
#   start: numeric for the starting position of the process
#   m: positive integer for the number of points in the process to simulate
#
# return:
#   A data.frame with variables "t" for the time index and "xt" for the value
#   of the process
t <- seq(from = from, to = to, length.out = m)
Sigma <- sapply(t, function(s1) {
sapply(t, function(s2) {
K(s1, s2)
})
})
path <- mvrnorm(mu = mu, Sigma = Sigma)
path <- path - path[1] + start  # Must always start at "start"
return(data.frame("t" = t, "xt" = path))
}
# explore kernel function ------------------------------------------------------------
# # square exponential kernel
# GP = gaussprocess(from=0,to=300,m=300,K=function(s,t)(0.05)^2*exp(-(s-t)^2/(2*3^2)))
# plot(GP$t,GP$xt, type='l')
#
# # AR(1) process
# rho = 0.8; sigma=0.03
# GP = gaussprocess(from=0,to=300,m=300,K=function(s,t)rho^abs(s-t)*sigma^2/(1-rho^2))
# plot(GP$t,GP$xt, type='l')
#
# plot(cor.full.ave[,1,30],type='l')
#
# type I error ------------------------------------------------------------
# N_rep = 10
# Plots: type I error vs rho, where type I error = (# GP with mean zero & max>rho) / (# GP with mean zero).
rho = 0.8; sigma=0.03
GP_mat = replicate(N_rep, gaussprocess(K=function(s,t)rho^abs(s-t)*sigma^2/(1-rho^2)))
GP_max = apply(GP_mat,2,function(x)max(x$xt))
rho_vec = seq(0.1,0.9,0.1)
type_I_error_vec = rho_vec
for (i in 1:length(rho_vec)) {
rho = rho_vec[i]
type_I_error_vec[i] = sum(GP_max>rho) / length(GP_max)
}
pdf(file="./plots/type_I_error.pdf",width = 4,height = 4)
plot(y=type_I_error_vec,x=rho_vec,type='l',xlab="Threshold",ylab="Type I error")
dev.off()
# white Gaussian kernel
# GP = gaussprocess(from=0,to=300,m=300,K=function(s,t)(0.05)^2*I(s==t))
# plot(GP$t,GP$xt, type='l')
# cluster correlation curves, power, and uncertainty ----------------------------------------------
# N_rep = 10
file = list.files(pattern="cor_full_ave*")[1]
load(file)
file = list.files(pattern="func_20150410*")[1]
load(file)
cor_mat = apply(cor.full.ave[,which(locs[,2]<0),which(locs[,2]<0)], 1, function(A)c(A[upper.tri(A)]))
# centers = cluster::pam(cor_mat,5)$medoids
centers = kmeans(cor_mat,5)$centers
order = order(apply(centers,1,max))
centers = centers[order,]
pdf(file="./plots/typical_correlation.pdf",width = 4,height = 4)
plot(1,type='n',xlim=c(0,300),ylim=c(-0.1,1),xlab="Time",ylab="Correlation")
for (k in 1:nrow(centers)) {
lines(centers[k,],col=k)
}
dev.off()
# Plots: power vs rho, where power = (# GP with mean=center & max>rho) / (# GP with mean=center).
pdf(file="./plots/power.pdf",width = 4,height = 4)
plot(1,type='n',xlim=c(min(rho_vec),max(rho_vec)),ylim=c(0,1),xlab="Threshold",ylab="Power")
for (k in 1:nrow(centers)) {
center = centers[k,]
GP_mat = replicate(N_rep, gaussprocess(m=length(center),mu=center))
GP_max = apply(GP_mat,2,function(x)max(x$xt))
rho_vec = seq(0.1,0.9,0.1)
power_vec = rho_vec
for (i in 1:length(rho_vec)) {
rho = rho_vec[i]
power_vec[i] = sum(GP_max>rho) / length(GP_max)
}
lines(y=power_vec,x=rho_vec,col=k)
}
dev.off()
# Plot: uncertainty vs rho, where uncertainty = var(edge time for GP with certain mean function).
pdf(file="./plots/edge_time_uncertainty.pdf",width = 4,height = 4)
plot(1,type='n',xlim=c(min(rho_vec),max(rho_vec)),ylim=c(0,50),xlab="Threshold",ylab="s.d. of edge time")
for (k in 1:nrow(centers)) {
center = centers[k,]
GP_mat = replicate(N_rep, gaussprocess(m=length(center),mu=center))
rho_vec = seq(0.1,0.9,0.1)
uncertainty_vec = rho_vec
for (i in 1:length(rho_vec)) {
rho = rho_vec[i]
edge_time_vec = apply(GP_mat,2,function(x)which(x$xt>rho)[1])
uncertainty_vec[i] = sd(edge_time_vec[which(!is.na(edge_time_vec))])
}
lines(y=uncertainty_vec,x=rho_vec,col=k)
}
dev.off()
##### Calculate islet+/-/NA composition of clusters -----
get_composition_array = function(file_list, Lside=T){
array_tmp = array(dim = c(4,7,length(file_list)))
for (i in 1:length(file_list)) {
file = file_list[i]
load(file)
if(Lside){
tmp=L_result_new
}
else{
tmp=R_result_new
}
composition_matrix = matrix(0,nrow=length(tmp$clus_result$clusters), ncol=7)
for (q in 1:length(tmp$clus_result$clusters)) {
tmp_L = L_result_new; tmp_R = R_result_new
islet_res = islet[c(tmp_L$id[tmp_L$clus_result$clusters[[q]]],tmp_R$id[tmp_R$clus_result$clusters[[q]]])]
composition_matrix[q,2:4] = c(length(which(islet_res==1)), length(which(islet_res==0)), sum(is.na(islet_res)))
composition_matrix[q,1] = length(islet_res)
composition_matrix[q,5:7] = composition_matrix[q,2:4]/composition_matrix[q,1]
}
colnames(composition_matrix) = c("Cluster Size", "MN", "Ventral IN", "CoLA/CoSA", "MN(%)", "Ventral IN(%)", "CoLA/CoSA(%)")
rownames(composition_matrix) = c("Cluster 2", "Cluster 1", "Cluster 3", "Iso Nodes")[1:nrow(composition_matrix)]
array_tmp[1:nrow(composition_matrix),,i]=composition_matrix
}
dimnames(array_tmp) <- list(  rownames(composition_matrix), colnames(composition_matrix) ,seq(0.1,0.7,0.1))
return(array_tmp[c(2,1,3,4),,])
}
file_list = list.files(path='/Users/bgemily/Dropbox/DynamicSBM/Data/real_data_results/islet_20170202/',pattern = "*Nclus3",full.names = T)
array_tmp_1 = get_composition_array(file_list, Lside=T)
file_list = list.files(path='/Users/bgemily/Dropbox/DynamicSBM/Data/real_data_results/islet_20170216/',pattern = "*Nclus3",full.names = T)
array_tmp_2 = get_composition_array(file_list, Lside=F)
thres = 4
## composition of estimated clusters: scatter plot
plot(1,type='n',xlim=c(0,1)-0.5,ylim=c(0,1)-0.5,xlab="relative MN(%)",ylab="relative Ventral IN(%)", main="cluster composition")
abline(h=0,lty=2,col="gray"); abline(v=0,lty=2,col="gray")
overall_MN = sum(array_tmp_1[,2,thres])/sum(array_tmp_1[,1,thres])
overall_VenIN = sum(array_tmp_1[,3,thres])/sum(array_tmp_1[,1,thres])
for (q in 1:4) {
for (thres in thres) {
points(array_tmp_1[q,5,thres]-overall_MN, array_tmp_1[q,6,thres]-overall_VenIN,
col=switch(q,"red","green","blue","black"),
cex=(array_tmp_1[q,1,thres]/10),
pch=21)
}
}
overall_MN = sum(array_tmp_2[,2,thres])/sum(array_tmp_2[,1,thres])
overall_VenIN = sum(array_tmp_2[,3,thres])/sum(array_tmp_2[,1,thres])
for (q in 1:4) {
for (thres in thres) {
points(array_tmp_2[q,5,thres]-overall_MN, array_tmp_2[q,6,thres]-overall_VenIN,
col=switch(q,"red","green","blue","black"),
cex=(array_tmp_2[q,1,thres]/10),
pch=24)
}
}
# composition of estimated clusters: stacked barplot
array_tmp = apply(array_tmp_1,c(1,3),function(x)x[2:4]/sum(x[2:4]))[,,thres]
clus_size_perc = colSums(array_tmp_1[,2:4,thres])/sum(array_tmp_1[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cell_type","Cluster","Percentage")
library(ggplot2)
ggplot(data, aes(fill=Cell_type, y=Percentage, x=Cluster)) +
geom_bar(position="stack", stat="identity")
array_tmp = apply(array_tmp_2,c(1,3),function(x)x[2:4]/sum(x[2:4]))[,,thres]
clus_size_perc = colSums(array_tmp_2[,2:4,thres])/sum(array_tmp_2[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cell_type","Cluster","Percentage")
library(ggplot2)
ggplot(data, aes(fill=Cell_type, y=Percentage, x=Cluster)) +
geom_bar(position="stack", stat="identity")
## composition of cell types
array_tmp = apply(array_tmp_1,c(2,3),function(x)x/sum(x))[,2:4,thres]
clus_size_perc = array_tmp_1[,1,thres]/sum(array_tmp_1[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","percentage")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=percentage, x=cell_type)) +
geom_bar(position="stack", stat="identity")+
xlab("Cell type") + ylab("Percentage")
array_tmp = apply(array_tmp_2,c(2,3),function(x)x/sum(x))[,2:4,thres]
clus_size_perc = array_tmp_2[,1,thres]/sum(array_tmp_2[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","value")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=value, x=cell_type)) +
geom_bar(position="stack", stat="identity") +
xlab("Cell type") + ylab("Percentage")
array_tmp_1
array_tmp_2
clus_size_perc
array_tmp_1
array_tmp_2
array_tmp_1
array_tmp = apply(array_tmp_1+array_tmp_2,c(2,3),function(x)x/sum(x))[,2:4,thres]
clus_size_perc = (array_tmp_1+array_tmp_2)[,1,thres]/sum((array_tmp_1+array_tmp_2)[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","value")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=value, x=cell_type)) +
geom_bar(position="stack", stat="identity") +
xlab("Cell type") + ylab("Percentage")
array_tmp
array_tmp_1+array_tmp_2
clus_size_perc
sum((array_tmp_1+array_tmp_2)[,1,thres])
(array_tmp_1+array_tmp_2)[,1,thres]
data
ggplot(data, aes(fill=Cluster, y=value, x=cell_type)) +
geom_bar(position="stack", stat="identity") +
xlab("Cell type") + ylab("Percentage")+
annotation_custom("b",xmin=5,xmax=5,ymin=-0.07,ymax=-0.07)
(array_tmp_1+array_tmp_2)[,1,thres]
array_tmp_1+array_tmp_2
colSums((array_tmp_1+array_tmp_2)[,2:4])
colSums((array_tmp_1+array_tmp_2)[,2:4,thres])
sum((array_tmp_1+array_tmp_2)[,1,thres])
ggplot(data, aes(fill=Cluster, y=value, x=cell_type)) +
geom_bar(position="stack", stat="identity") +
xlab("Cell type") + ylab("Percentage")+
scale_x_discrete(labels=c("MN" = "MN(n=73)", "Ventral IN" = "Ventral IN(n=39)",
"CoLA/CoSA" = "CoLA/CoSA(n=19)"))
array_tmp_1+array_tmp_2
thres
thres=3
array_tmp = apply(array_tmp_1+array_tmp_2,c(2,3),function(x)x/sum(x))[,2:4,thres]
colSums((array_tmp_1+array_tmp_2)[,2:4,thres])
clus_size_perc = (array_tmp_1+array_tmp_2)[,1,thres]/sum((array_tmp_1+array_tmp_2)[,1,thres])
array_tmp = cbind(array_tmp,Marginal=clus_size_perc)
# array_tmp = sweep(array_tmp,1,clus_size_perc)
data = reshape2::melt(array_tmp)
names(data) = c("Cluster","cell_type","value")
library(ggplot2)
ggplot(data, aes(fill=Cluster, y=value, x=cell_type)) +
geom_bar(position="stack", stat="identity") +
xlab("Cell type") + ylab("Percentage")+
scale_x_discrete(labels=c("MN" = "MN(n=73)", "Ventral IN" = "Ventral IN(n=39)",
"CoLA/CoSA" = "CoLA/CoSA(n=19)"))
rm(list=ls())
file_path = "./functions"
file.sources = list.files(path = file_path, pattern = "*.R$", full.names = TRUE)
sapply(file.sources, source)
mem2clus
pdfNrdsamp_fun_list
gener_edge_time_mat
del_iso_nodes
do_cluster
get_one_ARI()
get_one_ARI
fun2pdfarray
mem2clus
gener_edge_time_mat
get_init
get_one_ARI
merge_clusters
do_cluster
get_center_pdf_array
get_node_cdf_array
shift
mem2clus
get_center_pdf_array
get_clus_degree_mat
pairwise_dist_mat
clus2mem
est_n0_mat
adjs_edge_time_mat
get_pdf_vec
get_dist_betw_pdfarray
est_n0_vec
align_pdf_gd
align_multi_curves_gd
align_curves_gd
align_curves_gd_
align_multi_curves_gd_
get_theta_gamma_prime
fft
order
gradient
distance
order
est_edge_time
visual_realdata
visual_realdata_2
plot_edge_time_mat
plot_pdf_array
plot_network
