%!TEX root = Main.tex


\section{Introduction}


% \subsection*{Motivation}
Dynamic networks emerge in many area,
such as the neuronal network in the brain during disease[] or learning tasks[], 
the social network in a time period[], etc.
A lot of work has been done in order to study the dynamic networks,
but most of these research focus on analyzing the dynamics in a well-developed network.
In this paper, we concentrate on the growing networks where isolated nodes  develop into a mature functioning network.
To the best of our knowledge, there is no existing study about the growing networks, partly because of the lack of data.
Fortunately, the data collected by \citet{Wan2019} provides us the possibility to pursue this study.


In this paper, we focus on the neural data provided by \cite{Wan2019}.
Since the neuronal network is complicated, we try to break it down and propose to model it by identifying the typical roles of individual neurons. 
As supported by \cite{Wan2019}, neurons in a growing network play different roles in terms of active time and connecting patterns. 
The connecting pattern of a neuron can be described as the occurrence time of edges that include this neuron. 
% a collection of point processes representing the connection between this neuron and each of the rest individual neurons.
Neurons with the same roles perform similar activities and thus have similar connecting patterns. 
Learning these roles can help us understand the development procedure of growing networks.


However, being able to identify the typical roles in a single growing network is  infeasible because 
the growing network  is transient --- 
there is only one measurement of a growing network due to its non-stationarity.
Due to this limit, we combine networks of other subjects as additional samples.
% and there is only one sample from each subject.
% This requires our method to be able to combine multiple subjects and borrow information from other networks.
This is not trivial, because the neurons in different networks are not one-to-one mapped, 
and the roles identified from different subjects are not transferable
. 
This constrains our ability to study the common features across subjects.
For this reason, we propose to use the stochastic block model as it allows to combine multiple networks and hence resolve the above problems.
[SBM is.... It has been applied to ...]


There are, nevertheless, some unique properties of the data that are beyond the scope of the stochastic block model.
First, the connection between two neurons is measured over time.
Second, the connecting pattern between two neurons are determined not only by their roles but also by their active time, which varies from node to node.
Third, the connection is also effected by the spatial distance between neurons --- connection cannot occur if two neurons are too away from each other.
To incorporate such uniqueness, we propose a generalized stochastic block model in this paper.
[Note that these properties also appear in other problems, e.g. venmo...]


\subsection*{Related work}
	The stochastic block model is first proposed by \citet{Holland1983}.
	It has many dynamic extensions,
	\citet{Yang2011,Xu2014a,Matias2016,Xu2015} use the Markov chain to model the time-varying  connecting probabilities and/or the clustering matrix. 
	(Varitional) EM algorithm is commonly used for inference.
	\citet{Matias2018} adapt the stochastic block model to the context of recurrent interaction events in continuous time, 
	where the recurrent events are modeled by Poisson processes with intensities determined by the nodes' group memberships. 
	A semiparametric version of the variational EM algorithm is proposed, where the maximization over intensities is obtained by a histogram approach and/or a kernel estimator.

	There are many other fitting methods of the stochastic block model that have been proposed, including spectral clustering \citet{Liu2018}, convex relaxation \citet{Li2018,Chen2014}, semidefinite programming relaxation \citet{Amini2018}, low-rank approximation \citet{Le2016b} etc.

	Optimal rate of convergence is also studied.
	\citet{Gao2015a} provides an optimal rate under the mean squared error for the stochastic block model.
	\citet{Pensky2019a} 
	derives a penalized least square estimator in a dynamic network setting, and shows that the estimator satisfies an oracle inequality and  attains the minimax lower bound for the risk.




	% \item Convex relaxation methods for community detection have been studied in \citet{Li2018,Li2017,Peng2005}.



\subsection*{Contribution}
	In this paper, we propose a method for analyzing the growing networks. Our method is able to identify the roles of individual nodes and the connecting patterns.
	We adapt the stochastic block model to the growing networks context by generalizing the connecting probabilities to intensities of point processes. 
	In addition, we incorporate the time delay of each node so that our model is able to handle the network where nodes become active over time.
	We derive a least square estimator and show that the estimator converges [in a certain rate].
	Finally, an algorithm combining the k-means method and the shape invariant method is proposed for estimation.



\subsection*{Future work}
Future working directions include (but not limited to)
	(i) identifying clusters with similar connecting pattern but different active time phase or different vertex degree,
	(ii) incorporating the movement of nodes,
	(iii) seeking for a convex relaxation method that convexify over both clustering matrix and time lags
	(convex relaxation can also be adapted to solve the penalized least square problem in \citet{Pensky2019a}),
	(iv) try other clustering methods.





\subsection*{Organization}
The rest of this paper is organized as follows. 
In Section \ref{sec:model}, we review the stochastic block model and introduce the proposed dynamic generalization of the stochastic block model.
We introduce the least square estimator and the estimation algorithm in Section \ref{sec:method}.
Theoretical results are provided in Section \ref{sec:theory}. Section \ref{sec:simulation} shows the numerical experiments.



