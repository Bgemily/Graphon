%!TEX root = Main.tex


\section{Introduction}
~ 

\subsection*{Motivation}
\begin{itemize}
	\item Introduce the growing network in zebrafish, where the edges are increasing and the nodes are fixed (or assumed to be fixed?).\\
	How do we obtain the pictures of the growing network from the real data?
	\item The network in different zebrafish are different in the sense that neurons are not one-one correspondent. 
	But there should be some similarity among the growing networks in different zebrafish. 
	The key to comparing networks is to find a measure of similarity.
	\item From the real data we can see that neurons have different functional roles, e.g. some neurons become active in advance to the edge (or ensemble) formation and some do not.
	This observation gives rise to the hypothesis that the edge formation may be led by some ``leaders'', and that the neurons can be clustered by the roles they are playing in the network development. 
	\item To sum up, our problem is to identify some typical patterns that are comparable among subjects, and classify the neurons according to those patterns.

\end{itemize}

\subsection*{Introduce the stochastic block model}
	\begin{itemize}
	\item Assume neurons are classified to several groups according to their ``roles'' in the development of the network, and the edge formation time between two nodes is determined only by their group memberships.
	\item This setup falls in the framework of the stochastic block model, where the groups are determined by the ``roles'' of neurons and the connecting probabilities are generalized to the typical patterns.

	\end{itemize}

\subsection*{Literature review}

\begin{itemize}
	\item The stochastic block model is first proposed by \citet{Wang1987}.
	\item There are many dynamic extensions of stochastic block model. 
	\citet{Yang2011,Xu2014a,Matias2016,Xu2015} use the Markov chain to model the time-varying  connecting probabilities and/or the clustering matrix. 
	EM algorithm or iterative optimization algorithm is commonly used for inference.
	\item Minimax optimal estimators are also studied.
	\citet{Gao2015a} provides a minimax rate for the stochastic block model with high intra-cluster connection and low inter-cluster connection.
	\citet{Pensky2019a} proposes a vectorization technique to simplify the tensor estimation in the dynamic network setting, and derives a penalized least square estimator that satisfies an oracle inequality and  attains the minimax lower bound for the risk.
	\item \citet{Matias2018} adapt the stochastic block model to the context of recurrent interaction events in continuous time, 
	where the recurrent events are modeled by Poisson processes with intensities determined by the nodes' group memberships. 
	The maximum likelihood estimator is proposed, but no theoretical analysis is available in the paper. 

	% \item Convex relaxation methods for community detection have been studied in \citet{Li2018,Li2017,Peng2005}.

\end{itemize}



\subsection*{Contribution}
\begin{itemize}
	\item We develop a method for analyzing typical connecting patterns in a growing network with spatial constraints on edges and time delay of nodes.

	\item We derive a least square estimator and show its consistency (and the minimax optimality?). 
	The proof is based on \citet{Gao2015a}.

	\item We propose a k-means algorithm equipped with a shape invariant method for inference.

	% \item We integrate the point processes in order to obtain the statistical equivalence of nodes from the same cluster.

\end{itemize}


\subsection*{Future work}
\begin{itemize}
	\item Seek for a convex relaxation method that convexify over both clustering matrix and time lags. 
	% We also obtain the proximity condition for this convex relaxation method to recover the global optima. 
	(Convex relaxation can also be adapted to solve the penalized least square problem in \citet{Pensky2019a}.)

	\item Try other clustering methods.

	\item Identify clusters with similar connecting pattern but different active time phase or different vertex degree. 

\end{itemize}



\subsection*{Organization}



