Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Bigot2013,
abstract = {We study the problem of estimating a mean pattern from a set of similar curves in the setting where the variability in the data is due to random geometric deformations and additive noise. We propose an estimator based on the notion of Fr{\'{e}}chet mean that is a generalization of the standard notion of averaging to non-Euclidean spaces. We derive a minimax rate for this estimation problem, and we show that our estimator achieves this optimal rate under the asymptotics where both the number of curves and the number of sampling points go to infinity.},
annote = {Estimator is based on Frechet mean.

Estimator achieves the optimal rate when both number of curves and the number of sampling points go to infinity.

Compute the shifts to align the curves.

Gradient descent is used to optimize over shifts.

The smoothed Frechet mean converges at the optimal rate.},
author = {Bigot, J{\'{e}}r{\'{e}}mie and Gendre, Xavier},
doi = {10.1214/13-AOS1104},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Bigot, Gendre - 2013 - MINIMAX PROPERTIES OF FR{\'{E}}CHET MEANS OF DISCRETELY SAMPLED CURVES.pdf:pdf},
journal = {Ann. Stat.},
keywords = {62G08,62G20,Fr{\'{e}}chet mean,Sobolev balls,curve registration,deformable models,functional data analysis,lie group action,minimax rate of convergence,non-Euclidean metric},
number = {2},
pages = {923--956},
title = {{Minimax properties of Fr{\'{e}}chet means of discretely sampled curves}},
volume = {41},
year = {2013}
}
@article{Wang1987,
author = {Wang, Yuchung J; and Wong, George Y},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Wang, George, Wong - 1987 - Stochastic Blockmodels for Directed Graphs.pdf:pdf},
journal = {J. Am. Stat. Assoc.},
number = {397},
pages = {8--19},
title = {{Stochastic Blockmodels for Directed Graphs}},
volume = {82},
year = {1987}
}
@article{Abbe2018,
abstract = {The stochastic block model (SBM) is a random graph model with different group of vertices connecting differently. It is widely employed as a canonical model to study clustering and community detection, and provides a fertile ground to study the information-theoretic and computational tradeoffs that arise in combinatorial statistics and more generally data science. This monograph surveys the recent developments that establish the fundamental limits for community detection in the SBM, both with respect to information-theoretic and computational tradeoffs, and for various recovery requirements such as exact, partial and weak recovery. The main results discussed are the phase transitions for exact recovery at the Chernoff-Hellinger threshold, the phase transition for weak recovery at the Kesten-Stigum threshold, the optimal SNR-mutual information tradeoff for partial recovery, and the gap between information-theoretic and computational thresholds.},
archivePrefix = {arXiv},
arxivId = {1703.10146},
author = {Abbe, Emmanuel},
doi = {10.1561/0100000067},
eprint = {1703.10146},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Abbe - 2018 - Community detection and stochastic block models(2).pdf:pdf},
issn = {15672328},
journal = {Found. Trends Commun. Inf. Theory},
number = {1-2},
pages = {1--162},
title = {{Community detection and stochastic block models}},
volume = {14},
year = {2018}
}
@article{Le2016a,
abstract = {Community detection is one of the fundamental problems of network analysis, for which a number of methods have been proposed. Most model-based or criteria-based methods have to solve an optimization problem over a discrete set of labels to find communities, which is computationally infeasible. Some fast spectral algorithms have been proposed for specific methods or models, but only on a case-by-case basis. Here we propose a general approach for maximizing a function of a network adjacency matrix over discrete labels by projecting the set of labels onto a subspace approximating the leading eigenvectors of the expected adjacency matrix. This projection onto a low-dimensional space makes the feasible set of labels much smaller and the optimization problem much easier. We prove a general result about this method and show how to apply it to several previously proposed community detection criteria, establishing its consistency for label estimation in each case and demonstrating the fundamental connection between spectral properties of the network and various model-based approaches to community detection. Simulations and applications to real-world data are included to demonstrate our method performs well for multiple problems over a wide range of parameters.},
author = {Le, Can M. and Levina, Elizaveta and Vershynin, Roman},
doi = {10.1214/15-AOS1360},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Le, Levina, Vershynin - 2016 - Optimization via low-rank approximation for community detection in networks.pdf:pdf},
issn = {00905364},
journal = {Ann. Stat.},
keywords = {Community detection,Social networks,Spectral clustering,Stochastic block model},
month = {feb},
number = {1},
pages = {373--400},
publisher = {Institute of Mathematical Statistics},
title = {{Optimization via low-rank approximation for community detection in networks}},
volume = {44},
year = {2016}
}
@article{Albert2015,
abstract = {Motivated by a neuroscience question about synchrony detection in spike trains analysis, we deal with the independence testing problem for point processes. We introduce non-parametric test statistics, which are rescaled general U-statistics, whose corresponding critical values are constructed from bootstrap and randomisation or permutation approaches, making as few assumptions as possible on the underlying distribution of the point processes. We derive general consistency results for the bootstrap and for the permutation w.r.t. to Wasserstein's metric, which induce weak convergence as well as convergence of second order moments. The obtained bootstrap or permutation independence tests are thus proved to be asymptotically of the prescribed size, and to be consistent against any reasonable alternative, randomisation or permutation independence tests having the further advantage to be exactly (that is non-asymptotically) of the prescribed level, even when Monte Carlo methods are used to approximate the randomised quantiles.},
author = {Albert, M{\'{e}}lisande and Bouret, Yann and Fromont, Magalie and Reynaud-Bouret, Patricia},
doi = {10.1214/15-AOS1351},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Albert et al. - 2015 - Bootstrap and permutation tests of independence for point processes(2).pdf:pdf},
issn = {00905364},
journal = {Ann. Stat.},
keywords = {Bootstrap,Independence test,Neuroscience,Permutation,Point processes,Randomization,Spike train analysis,U-statistics},
month = {dec},
number = {6},
pages = {2537--2564},
publisher = {Institute of Mathematical Statistics},
title = {{Bootstrap and permutation tests of independence for point processes}},
volume = {43},
year = {2015}
}
@article{Zhou2013,
abstract = {How will the behaviors of individuals in a social network be influenced by their neighbors, the authorities and the communities? Such knowledge is often hidden from us and we only observe its manifestation in the form of recurrent and time-stamped events occurring at the individuals involved. It is an important yet challenging problem to infer the network of social inference based on the temporal patterns of these historical events. We propose a convex optimization approach to discover the hidden network of social influence by modeling the recurrent events at different individuals as multi-dimensional Hawkes processes. Furthermore, our estimation procedure, using nuclear and ℓ1ℓ1 norm regularization simultaneously on the parameters, is able to take into account the prior knowledge of the presence of neighbor interaction, authority influence, and community coordination. To efficiently solve the problem, we also design an algorithm ADM4 which combines techniques of alternating direction method of multipliers and majorization minimization. We experimented with both synthetic and real world data sets, and showed that the proposed method can discover the hidden network more accurately and produce a better predictive model.},
author = {Zhou, Ke and Zha, Hongyuan and Song, Le},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhou, Zha, Song - 2013 - Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes.pdf:pdf},
issn = {1533-7928},
journal = {J. Mach. Learn. Res.},
pages = {641--649},
title = {{Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes}},
volume = {31},
year = {2013}
}
@article{Lyzinski2017,
abstract = {In disciplines as diverse as social network analysis and neuroscience, many large graphs are believed to be composed of loosely connected smaller graph primitives, whose structure is more amenable to analysis We propose a robust, scalable, integrated methodology for community detection and community comparison in graphs. In our procedure, we first embed a graph into an appropriate Euclidean space to obtain a low-dimensional representation, and then cluster the vertices into communities. We next employ nonparametric graph inference techniques to identify structural similarity among these communities. These two steps are then applied recursively on the communities, allowing us to detect more fine-grained structure. We describe a hierarchical stochastic blockmodel - namely, a stochastic blockmodel with a natural hierarchical structure - and establish conditions under which our algorithm yields consistent estimates of model parameters and motifs, which we define to be stochastically similar groups of subgraphs. Finally, we demonstrate the effectiveness of our algorithm in both simulated and real data. Specifically, we address the problem of locating similar sub-communities in a partially reconstructed Drosophila connectome and in the social network Friendster.},
archivePrefix = {arXiv},
arxivId = {1503.02115},
author = {Lyzinski, Vince and Tang, Minh and Athreya, Avanti and Park, Youngser and Priebe, Carey E.},
doi = {10.1109/TNSE.2016.2634322},
eprint = {1503.02115},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Lyzinski et al. - 2017 - Community Detection and Classification in Hierarchical Stochastic Blockmodels(2).pdf:pdf},
issn = {23274697},
journal = {IEEE Trans. Netw. Sci. Eng.},
keywords = {Community detection,classification,hierarchical random graphs,stochastic blockmodel},
month = {jan},
number = {1},
pages = {13--26},
publisher = {IEEE Computer Society},
title = {{Community Detection and Classification in Hierarchical Stochastic Blockmodels}},
volume = {4},
year = {2017}
}
@techreport{Kempa,
abstract = {We present a framework for learning abstract relational knowledge, with the aim of explaining how people acquire intuitive theories of physical, biological, or social systems. Our algorithm infers a generative relational model with latent classes, simultaneously determining the kinds of entities that exist in a domain, the number of these latent classes, and the relations between classes that are possible or likely. This model goes beyond previous category-learning models in psychology , which consider the attributes associated with individual categories but not the relationships that can exist between categories. We apply this domain-general framework in two specific domains: learning the structure of kinship systems and learning causal theories.},
author = {Kemp, Charles and Griffiths, Thomas L and Tenenbaum, Joshua B},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Kemp, Griffiths, Tenenbaum - Unknown - Discovering Latent Classes in Relational Data.pdf:pdf},
title = {{Discovering Latent Classes in Relational Data}}
}
@article{Perry2013,
abstract = {Network data often take the form of repeated interactions between senders and receivers tabulated over time. A primary question to ask of such data is which traits and behaviors are predictive of interaction. To answer this question, a model is introduced for treating directed interactions as a multivariate point process: a Cox multiplicative intensity model using covariates that depend on the history of the process. Consistency and asymptotic normality are proved for the resulting partial-likelihood-based estimators under suitable regularity conditions, and an efficient fitting procedure is described. Multicast interactions--those involving a single sender but multiple receivers--are treated explicitly. The resulting inferential framework is then employed to model message sending behavior in a corporate e-mail network. The analysis gives a precise quantification of which static shared traits and dynamic network effects are predictive of message recipient selection.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1703v3},
author = {Perry, Patrick O. and Wolfe, Patrick J.},
doi = {10.1111/rssb.12013},
eprint = {arXiv:1011.1703v3},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Perry, Wolfe - 2013 - Point process modelling for directed interaction networks.pdf:pdf;:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Perry, Wolfe - 2013 - Point process modeling for directed interaction networks.pdf:pdf},
issn = {13697412},
journal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
keywords = {Cox proportional hazards model,Network data analysis,Partial likelihood inference,Point processes},
month = {nov},
number = {5},
pages = {821--849},
title = {{Point process modeling for directed interaction networks}},
volume = {75},
year = {2013}
}
@article{Pensky2019c,
author = {Pensky, Marianna and Zhang, Teng},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/Pensky and ZHang 2019.pdf:pdf},
keywords = {62F12, 05C80, 62H30Time-varying network, dynamic s,adaptive estimation,and phrases,dynamic stochastic block,model,received march 2018,spectral clustering,time-varying network},
pages = {678--709},
title = {{Spectral clustering in the dynamic stochastic block model}},
volume = {13},
year = {2019}
}
@article{Skaggs,
author = {Skaggs, William E and Mcnaughton, Bruce L and Gothard, Katalin M and Markus, Etan J},
file = {:Users/bgemily/Documents/Academic/SC/Stage1/671-an-information-theoretic-approach-to-deciphering-the-hippocampal-code.pdf:pdf},
number = {1990},
pages = {1030--1038},
title = {{An Information-Theoretic Approach to Deciphering the Hippocampal Code}}
}
@article{Durrett2010,
abstract = {A useful reference for those who apply probability to work, PROBABILITY: THEORY AND EXAMPLES focuses attention on examples and results while developing theory.},
author = {Durrett, Rick},
doi = {10.2307/2532227},
file = {:Users/bgemily/Documents/Academic/MAT{\_}235/PTE5{\_}011119.pdf:pdf},
isbn = {0534424414},
issn = {0006341X},
journal = {Biometrics},
number = {3},
pages = {497},
pmid = {16156020},
title = {{Probability: Theory and Examples Rick Durrett January 29, 2010}},
url = {http://books.google.com/books?id=NPYYAQAAIAAJ{\&}pgis=1},
volume = {49},
year = {2010}
}
@article{Sun2016,
abstract = {Matrix factorization is a popular approach for large-scale matrix completion. The optimization formulation based on matrix factorization can be solved very efficiently by standard algorithms in practice. However, due to the non-convexity caused by the factorization model, there is a limited theoretical understanding of this formulation. In this paper, we establish a theoretical guarantee for the factorization formulation to correctly recover the underlying low-rank matrix. In particular, we show that under similar conditions to those in previous works, many standard optimization algorithms converge to the global optima of a factorization formulation, and recover the true low-rank matrix. We study the local geometry of a properly regularized factorization formulation and prove that any stationary point in a certain local region is globally optimal. A major difference of our work from the existing results is that we do not need resampling in either the algorithm or its analysis. Compared to other works on nonconvex optimization, one extra difficulty lies in analyzing nonconvex constrained optimization when the constraint (or the corresponding regularizer) is not "consistent" with the gradient direction. One technical contribution is the perturbation analysis for non-symmetric matrix factorization.},
author = {Sun, Ruoyu and Luo, Zhi Quan},
doi = {10.1109/TIT.2016.2598574},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Sun, Luo - 2016 - Guaranteed Matrix Completion via Non-Convex Factorization.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Matrix completion,Perturbation analysis,SGD,alternating minimization,matrix factorization,nonconvex optimization},
month = {nov},
number = {11},
pages = {6535--6579},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Guaranteed Matrix Completion via Non-Convex Factorization}},
volume = {62},
year = {2016}
}
@article{Zhao2012,
abstract = {Community detection is a fundamental problem in network analysis, with applications in many diverse areas. The stochastic block model is a common tool for model-based community detection, and asymptotic tools for checking consistency of community detection under the block model have been recently developed. However, the block model is limited by its assumption that all nodes within a community are stochastically equivalent, and provides a poor fit to networks with hubs or highly varying node degrees within communities, which are common in practice. The degree-corrected stochastic block model was proposed to address this shortcoming and allows variation in node degrees within a community while preserving the overall block community structure. In this paper we establish general theory for checking consistency of community detection under the degree-corrected stochastic block model and compare several community detection criteria under both the standard and the degree-corrected models. We show which criteria are consistent under which models and constraints, as well as compare their relative performance in practice. We find that methods based on the degree-corrected block model, which includes the standard block model as a special case, are consistent under a wider class of models and that modularity-type methods require parameter constraints for consistency, whereas likelihood-based methods do not. On the other hand, in practice, the degree correction involves estimating many more parameters, and empirically we find it is only worth doing if the node degrees within communities are indeed highly variable. We illustrate the methods on simulated networks and on a network of political blogs.},
annote = {Degree-corrected method: address the problem caused by stochastically equivalence (hubs), allows variation in node degrees within a cluster, while preserving the overall block community structure.},
author = {Zhao, Yunpeng and Levina, Elizaveta and Zhu, Ji I},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhao, Levina, Zhu - 2012 - CONSISTENCY OF COMMUNITY DETECTION IN NETWORKS UNDER DEGREE-CORRECTED STOCHASTIC BLOCK MODELS.pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
keywords = {62G20,Community detection,consistency,degree-corrected stochastic block models},
month = {aug},
number = {4},
pages = {2266--2292},
publisher = {Institute of Mathematical Statistics},
title = {{Consistency of community detection in networks under degree-corrected stochastic block models}},
volume = {40},
year = {2012}
}
@article{Blondel2008,
abstract = {We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection methods in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2 million customers and by analysing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad hoc modular networks. {\textcopyright} 2008 IOP Publishing Ltd.},
annote = {Use node features such as language to show the homogeneity of communities.},
archivePrefix = {arXiv},
arxivId = {0803.0476},
author = {Blondel, Vincent D. and Guillaume, Jean Loup and Lambiotte, Renaud and Lefebvre, Etienne},
doi = {10.1088/1742-5468/2008/10/P10008},
eprint = {0803.0476},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Blondel et al. - 2008 - Fast unfolding of communities in large networks.pdf:pdf},
issn = {17425468},
journal = {J. Stat. Mech. Theory Exp.},
keywords = {Networks,New applications of statistical mechanics,Random graphs},
month = {oct},
number = {10},
title = {{Fast unfolding of communities in large networks}},
volume = {2008},
year = {2008}
}
@article{Candes2009a,
author = {Cand{\`{e}}s, Emmanuel J. and Recht, Benjamin},
doi = {10.1007/s10208-009-9045-5},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Cand{\`{e}}s, Recht - 2009 - Exact Matrix Completion via Convex Optimization.pdf:pdf},
issn = {1615-3375},
journal = {Found. Comput. Math.},
month = {dec},
number = {6},
pages = {717--772},
title = {{Exact Matrix Completion via Convex Optimization}},
url = {http://link.springer.com/10.1007/s10208-009-9045-5},
volume = {9},
year = {2009}
}
@techreport{Nowicki2001,
author = {Nowicki, Krzysztof and Snijders, Tom A B},
booktitle = {J. Am. Stat. Assoc.},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Nowicki, Snijders - 2001 - Estimation and Prediction for Stochastic Blockstructures.pdf:pdf},
number = {455},
pages = {1077--1087},
title = {{Estimation and Prediction for Stochastic Blockstructures}},
volume = {96},
year = {2001}
}
@article{Picard2018,
abstract = {We propose a novel continuous testing framework to test the intensities of Poisson Processes. This framework allows a rigorous definition of the complete testing procedure, from an infinite number of hypothesis to joint error rates. Our work extends traditional procedures based on scanning win-dows, by controlling the family-wise error rate and the false discovery rate in a non-asymptotic manner and in a continuous way. The decision rule is based on a p-value process that can be estimated by a Monte-Carlo procedure. We also propose new test statistics based on kernels. Our method is applied in Neurosciences and Genomics through the standard test of homogeneity, and the two-sample test.},
author = {Picard, Franck and Reynaud-Bouret, Patricia and Roquain, Etienne},
doi = {10.1093/biomet/asy044},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Picard, Reynaud-Bouret, Roquain - 2018 - Continuous testing for Poisson process intensities A new perspective on scanning statistics.pdf:pdf},
issn = {14643510},
journal = {Biometrika},
keywords = {False discovery rate,Familywise error rate,Multiple testing,Poisson process.},
month = {dec},
number = {4},
pages = {931--944},
publisher = {Oxford University Press},
title = {{Continuous testing for Poisson process intensities: A new perspective on scanning statistics}},
volume = {105},
year = {2018}
}
@article{Chen2016,
abstract = {We consider two closely related problems: planted clustering and submatrix localization. In the planted clustering problem, a random graph is generated based on an underlying cluster structure of the nodes; the task is to recover these clusters given the graph. The submatrix localization problem concerns locating hidden submatrices with elevated means inside a large real-valued random matrix. Of particular interest is the setting where the number of clusters/submatrices is allowed to grow unbounded with the problem size. These formulations cover several classical models such as planted clique, planted densest subgraph, planted partition, planted coloring, and the stochas-tic block model, which are widely used for studying community detection, graph clustering and bi-clustering. For both problems, we show that the space of the model parameters (cluster/submatrix size, edge probabilities and the mean of the submatrices) can be partitioned into four disjoint regions corresponding to decreasing statistical and computational complexities: (1) the impossible regime, where all algorithms fail; (2) the hard regime, where the computationally expensive Maximum Likelihood Estimator (MLE) succeeds; (3) the easy regime, where the polynomial-time convexified MLE succeeds; (4) the simple regime, where a local counting/thresholding procedure succeeds. Moreover, we show that each of these algorithms provably fails in the harder regimes. Our results establish the minimax recovery limits, which are tight up to universal constants and hold even with a growing number of clusters/submatrices, and provide order-wise stronger performance guarantees for polynomial-time algorithms than previously known. Our study demonstrates the tradeoffs between statistical and computational considerations, and suggests that the minimax limits may not be achievable by polynomial-time algorithms.},
author = {Chen, Yudong and Xu, Jiaming},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Chen, Xu, Xu CHEN - 2016 - Statistical-Computational Tradeoffs in Planted Problems and Submatrix Localization with a Growing Number of C.pdf:pdf},
journal = {J. Mach. Learn. Res.},
keywords = {bi-clustering,computational hardness,convex relaxation,graph clus-tering,minimax recovery,planted clique,planted coloring,planted partition,submatrix localization},
pages = {1--57},
title = {{Statistical-Computational Tradeoffs in Planted Problems and Submatrix Localization with a Growing Number of Clusters and Submatrices}},
volume = {17},
year = {2016}
}
@article{Hawkes1971,
abstract = {The point spectral matrix is obtained for a class of mutually exciting point processes. The solution makes use of methods similar to those used in solving Wiener-Hopf integral equations. POINT},
author = {Hawkes, Alan G.},
doi = {10.1111/j.2517-6161.1971.tb01530.x},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Hawkes - 1971 - Point Spectra of Some Mutually Exciting Point Processes.pdf:pdf},
journal = {J. R. Stat. Soc. Ser. B},
month = {oct},
number = {3},
pages = {438--443},
publisher = {Wiley},
title = {{Point Spectra of Some Mutually Exciting Point Processes}},
volume = {33},
year = {1971}
}
@article{Li2018,
abstract = {This paper surveys recent theoretical advances in convex optimization approaches for community detection. We introduce some important theoretical techniques and results for establishing the consistency of convex community detection under various statistical models. In particular, we discuss the basic techniques based on the primal and dual analysis. We also present results that demonstrate several distinctive advantages of convex community detection, including robustness against outlier nodes, consistency under weak assortativity, and adaptivity to heterogeneous degrees. This survey is not intended to be a complete overview of the vast literature on this fast-growing topic. Instead, we aim to provide a big picture of the remarkable recent development in this area and to make the survey accessible to a broad audience. We hope that this expository article can serve as an introductory guide for readers who are interested in using, designing, and analyzing convex relaxation methods in network analysis.},
annote = {Review of convex relaxation

focus on (p-q)-SBM and maximization of likelihood?},
archivePrefix = {arXiv},
arxivId = {1810.00315},
author = {Li, Xiaodong and Chen, Yudong and Xu, Jiaming},
eprint = {1810.00315},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Li, Chen, Xu - 2018 - Convex Relaxation Methods for Community Detection.pdf:pdf},
month = {sep},
title = {{Convex Relaxation Methods for Community Detection}},
url = {http://arxiv.org/abs/1810.00315},
year = {2018}
}
@article{Chen2014,
abstract = {Graph clustering involves the task of dividing nodes into clusters, so that the edge density is higher within clusters as opposed to across clusters. A natural, classic, and popular statistical setting for evaluating solutions to this problem is the stochastic block model, also referred to as the planted partition model. In this paper, we present a new algorithm - a convexified version of maximum likelihood - for graph clustering. We show that, in the classic stochastic block model setting, it outperforms existing methods by polynomial factors when the cluster size is allowed to have general scalings. In fact, it is within logarithmic factors of known lower bounds for spectral methods, and there is evidence suggesting that no polynomial time algorithm would do significantly better. We then show that this guarantee carries over to a more general extension of the stochastic block model. Our method can handle the settings of semirandom graphs, heterogeneous degree distributions, unequal cluster sizes, unaffiliated nodes, partially observed graphs, planted clique/coloring, and so on. In particular, our results provide the best exact recovery guarantees to date for the planted partition, planted k-disjoint-cliques and planted noisy coloring models with general cluster sizes; in other settings, we match the best existing results up to logarithmic factors.},
archivePrefix = {arXiv},
arxivId = {1210.3335},
author = {Chen, Yudong and Sanghavi, Sujay and Xu, Huan},
doi = {10.1109/TIT.2014.2346205},
eprint = {1210.3335},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Chen, Sanghavi, Xu - 2014 - Improved graph clustering.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Graph clustering,convex optimization,maximum likehood estimator,stochastic block model},
month = {oct},
number = {10},
pages = {6440--6455},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Improved graph clustering}},
volume = {60},
year = {2014}
}
@article{Lu,
abstract = {Clustering is a fundamental problem in statistics and machine learning. Lloyd's algorithm, proposed in 1957, is still possibly the most widely used clustering algorithm in practice due to its simplicity and empirical performance. However, there has been little theoretical investigation on the statistical and computational guarantees of Lloyd's algorithm. This paper is an attempt to bridge this gap between practice and theory. We investigate the performance of Lloyd's algorithm on clustering sub-Gaussian mixtures. Under an appropriate initialization for labels or centers, we show that Lloyd's algorithm converges to an exponentially small clustering error after an order of log n iterations, where n is the sample size. The error rate is shown to be minimax optimal. For the two-mixture case, we only require the initializer to be slightly better than random guess. In addition, we extend the Lloyd's algorithm and its analysis to community detection and crowdsourcing, two problems that have received a lot of attention recently in statistics and machine learning. Two variants of Lloyd's algorithm are proposed respectively for community detection and crowdsourcing. On the theoretical side, we provide statistical and computational guarantees of the two algorithms, and the results improve upon some previous signal-to-noise ratio conditions in literature for both problems. Experimental results on simulated and real data sets demonstrate competitive performance of our algorithms to the state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {0000.0000},
author = {Lu, Yu and Zhou, Harrison H},
eprint = {0000.0000},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Lu, Zhou - Unknown - STATISTICAL AND COMPUTATIONAL GUARANTEES OF LLOYD'S ALGORITHM AND ITS VARIANTS.pdf:pdf},
title = {{Statistical and Computational Guarantees of Lloyd's Algorithm and its Variants}}
}
@article{Edelman1998a,
abstract = {In this paper we develop new Newton and conjugate gradient algorithms on the Grassmann and Stiefel manifolds. These manifolds represent the constraints that arise in such areas as the symmetric eigenvalue problem, nonlinear eigenvalue problems, electronic structures computations, and signal processing. In addition to the new algorithms, we show how the geometrical framework gives penetrating new insights allowing us to create, understand, and compare algorithms. The theory proposed here provides a taxonomy for numerical linear algebra algorithms that provide a top level mathematical view of previously unrelated algorithms. It is our hope that developers of new algorithms and perturbation theories will benefit from the theory, methods, and examples in this paper.},
author = {Edelman, Alan and Arias, TOM{\'{A}}S A. and Smith, Steven T.},
doi = {10.1137/S0895479895290954},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/edelman98.pdf:pdf},
issn = {08954798},
journal = {SIAM J. Matrix Anal. Appl.},
keywords = {Conjugate gradient,Eigenvalue optimization,Eigenvalues and eigenvectors,Grassmann manifold,Invariant subspace,Newton's method,Orthogonality constraints,Rayleigh quotient iteration,Sequential quadratic programming,Stiefel manifold},
title = {{The geometry of algorithms with orthogonality constraints}},
year = {1998}
}
@techreport{Kemp,
abstract = {We present a framework for learning abstract relational knowledge, with the aim of explaining how people acquire intuitive theories of physical, biological, or social systems. Our algorithm infers a generative relational model with latent classes, simultaneously determining the kinds of entities that exist in a domain, the number of these latent classes, and the relations between classes that are possible or likely. This model goes beyond previous category-learning models in psychology , which consider the attributes associated with individual categories but not the relationships that can exist between categories. We apply this domain-general framework in two specific domains: learning the structure of kinship systems and learning causal theories.},
author = {Kemp, Charles and Griffiths, Thomas L and Tenenbaum, Joshua B},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Kemp, Griffiths, Tenenbaum - Unknown - Discovering Latent Classes in Relational Data.pdf:pdf},
title = {{Discovering Latent Classes in Relational Data}}
}
@article{Gao2018,
abstract = {This paper surveys some recent developments in fundamental limits and optimal algorithms for network analysis. We focus on minimax optimal rates in three fundamental problems of network analysis: graphon estimation, community detection, and hypothesis testing. For each problem, we review state-of-the-art results in the literature followed by general principles behind the optimal procedures that lead to minimax estimation and testing. This allows us to connect problems in network analysis to other statistical inference problems from a general perspective.},
archivePrefix = {arXiv},
arxivId = {1811.06055},
author = {Gao, Chao and Ma, Zongming},
eprint = {1811.06055},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gao, Ma - 2018 - Minimax Rates in Network Analysis Graphon Estimation, Community Detection and Hypothesis Testing.pdf:pdf},
journal = {arXiv:1811.06055},
month = {nov},
title = {{Minimax Rates in Network Analysis: Graphon Estimation, Community Detection and Hypothesis Testing}},
url = {http://arxiv.org/abs/1811.06055},
year = {2018}
}
@article{Su2018,
abstract = {Estimating the probabilities of linkages in a network has gained increasing interest in recent years. One popular model for network analysis is the exchangeable graph model (ExGM) characterized by a two-dimensional function known as a graphon. Estimating an underlying graphon becomes the key of such analysis. Several nonparametric estimation methods have been proposed , and some are provably consistent. However, if certain useful features of the nodes (e.g., age and schools in social network context) are available, none of these methods was designed to incorporate this source of information to help with the estimation. This paper develops a consistent graphon estimation method that integrates the information from both the adjacency matrix itself and node features. We show that properly leveraging the features can improve the estimation. A cross-validation method is proposed to automatically select the tuning parameter of the method.},
archivePrefix = {arXiv},
arxivId = {1809.00420v1},
author = {Su, Yi and Wong, Raymond K W and Lee, Thomas C M},
eprint = {1809.00420v1},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Su, Wong, Lee - 2018 - Network estimation via graphon with node features.pdf:pdf},
keywords = {consistency,exchangeable graph model,feature assisted neighborhood smoothing (FANS),generative model,nonparametric},
title = {{Network estimation via graphon with node features}},
year = {2018}
}
@article{Matias2018,
abstract = {To model recurrent interaction events in continuous time, an extension of the stochastic block model is proposed where every individual belongs to a latent group and interactions between two individuals follow a conditional inhomogeneous Poisson process with intensity driven by the individuals' latent groups. The model is shown to be identifiable and its estimation is based on a semiparametric variational expectation-maximization algorithm. Two versions of the method are developed, using either a nonparametric histogram approach (with an adaptive choice of the partition size) or kernel intensity estimators. The number of latent groups can be selected by an integrated classification likelihood criterion. Finally, we demonstrate the performance of our procedure on synthetic experiments, analyse two datasets to illustrate the utility of our approach and comment on competing methods.},
annote = {Model the interactions {\{}(t{\_}m,i{\_}m,j{\_},),m=1,...M{\}} by point process:
1. Each node belongs to a latent cluster;
2, Interactions between two nodes i, j are Poisson processes with intensity function only dependent on there clusters k,l

They showed the identifiability of cluster probability vector $\backslash$pi and inter-group intensities $\backslash$alpha (up to label switching)

To infer the above parameters, variational EM algorithm is proposed. 
$\backslash$alpha is infered by histogram or kernel method.


They have many samples (i.e. interactions between each pair of nodes), while we have at most one. So we need to integrate interactions within each group in order to infer the intensity.},
archivePrefix = {arXiv},
arxivId = {1512.07075},
author = {Matias, Catherine and Rebafka, Tabea and Villers, Fanny},
doi = {10.1093/biomet/asy016},
eprint = {1512.07075},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Matias, Rebafka, Villers - 2018 - A semiparametric extension of the stochastic block model for longitudinal networks.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
number = {3},
pages = {665--680},
title = {{A semiparametric extension of the stochastic block model for longitudinal networks}},
url = {https://academic.oup.com/biomet/article/105/3/665/5032575 http://arxiv.org/abs/1512.07075},
volume = {105},
year = {2018}
}
@article{Matias2016,
abstract = {Statistical node clustering in discrete time dynamic networks is an emerging field that raises many challenges. Here, we explore statistical properties and frequentist inference in a model that combines a stochastic block model (SBM) for its static part with independent Markov chains for the evolution of the nodes groups through time. We model binary data as well as weighted dynamic random graphs (with discrete or continuous edges values). Our approach, motivated by the importance of controlling for label switching issues across the different time steps, focuses on detecting groups characterized by a stable within group connectivity behavior. We study identifiability of the model parameters , propose an inference procedure based on a variational expectation maximization algorithm as well as a model selection criterion to select for the number of groups. We carefully discuss our initialization strategy which plays an important role in the method and compare our procedure with existing ones on synthetic datasets. We also illustrate our approach on dynamic contact networks, one of encounters among high school students and two others on animal interactions. An implementation of the method is available as a R package called dynsbm.},
annote = {From Duplicate 2 (Statistical clustering of temporal networks through a dynamic stochastic block model - Matias, Catherine; Miele, Vincent)

Infer the number of clusters?},
archivePrefix = {arXiv},
arxivId = {1506.07464v2},
author = {Matias, Catherine and Miele, Vincent},
doi = {10.1111/rssb.12200},
eprint = {1506.07464v2},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Matias, Miele - 2016 - Statistical clustering of temporal networks through a dy-namic stochastic block model.pdf:pdf},
isbn = {1506.07464v2},
issn = {13697412},
journal = {J. R. Stat. Soc. Ser. B (Statistical Methodol.},
keywords = {()},
month = {sep},
number = {4},
pages = {1119--1141},
title = {{Statistical clustering of temporal networks through a dynamic stochastic block model}},
url = {http://doi.wiley.com/10.1111/rssb.12200 http://lbbe.univ-lyon1.fr/dynsbm},
volume = {79},
year = {2017}
}
@article{Karrer2011,
abstract = {Stochastic blockmodels have been proposed as a tool for detecting community structure in networks as well as for generating synthetic networks for use as benchmarks. Most blockmodels, however, ignore variation in vertex degree, making them unsuitable for applications to real-world networks, which typically display broad degree distributions that can significantly distort the results. Here we demonstrate how the generalization of blockmodels to incorporate this missing element leads to an improved objective function for community detection in complex networks. We also propose a heuristic algorithm for community detection using this objective function or its non-degree-corrected counterpart and show that the degree-corrected version dramatically outperforms the uncorrected one in both real-world and synthetic networks.},
author = {Karrer, Brian and Newman, M. E.J.},
doi = {10.1103/PhysRevE.83.016107},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Karrer, Newman - 2011 - Stochastic blockmodels and community structure in networks.pdf:pdf},
issn = {15393755},
journal = {Phys. Rev. E - Stat. Nonlinear, Soft Matter Phys.},
month = {jan},
number = {1},
title = {{Stochastic blockmodels and community structure in networks}},
volume = {83},
year = {2011}
}
@article{Boyd2010,
author = {Boyd, S and Parikh, N and Chu, E and Eckstein, J and Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
doi = {10.1561/2200000016},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Boyd et al. - 2010 - Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.pdf:pdf},
journal = {Found. Trends R Mach. Learn.},
number = {1},
pages = {1--122},
title = {{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}},
volume = {3},
year = {2010}
}
@article{Matrix1983,
author = {Matrix, Incomplete},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Matrix - 1983 - Simulation.pdf:pdf},
pages = {1--8},
title = {{Simulation}},
year = {1983}
}
@article{Pensky2019a,
abstract = {In the present paper we consider a dynamic stochastic network model. The objective is estimation of the tensor of connection probabilities {\$}\backslashLambda{\$} when it is generated by a Dynamic Stochastic Block Model (DSBM) or a dynamic graphon. In particular, in the context of the DSBM, we derive a penalized least squares estimator {\$}\backslashwidehat{\{}\backslashLambda{\}}{\$} of {\$}\backslashLambda{\$} and show that {\$}\backslashwidehat{\{}\backslashLambda{\}}{\$} satisfies an oracle inequality and also attains minimax lower bounds for the risk. We extend those results to estimation of {\$}\backslashLambda{\$} when it is generated by a dynamic graphon function. The estimators constructed in the paper are adaptive to the unknown number of blocks in the context of the DSBM or to the smoothness of the graphon function. The technique relies on the vectorization of the model and leads to much simpler mathematical arguments than the ones used previously in the stationary set up. In addition, all results in the paper are non-asymptotic and allow a variety of extensions.},
annote = {From Duplicate 1 (Dynamic network models and graphon estimation - Pensky, Marianna)

From Duplicate 1 (DYNAMIC NETWORK MODELS AND GRAPHON ESTIMATION - Pensky, Marianna)

1. Fully nonparametric model that does not assume a probabilistic mechanism which governs the evolution of the network in time. It treats connection probabilities for each group as functional data.

2. Provides a minimax study of estimation of the tensor of connection probabilities in a dynamic setting. And the approach is nonasymptotic.

3. Use vectorization of the model. This technique allows to reduce the problem of estimatin of an unknown tensor of connection probabilities to a solution of a functional linear regression problem with sub-Gaussian errors.},
archivePrefix = {arXiv},
arxivId = {1607.00673},
author = {Pensky, Marianna},
doi = {10.1214/18-aos1751},
eprint = {1607.00673},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Pensky - 2019 - DYNAMIC NETWORK MODELS AND GRAPHON ESTIMATION(2).pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
keywords = {05C80,60G05,62F35,Dynamic network,graphon,minimax rate,nonparametric regression,stochastic block model},
month = {aug},
number = {4},
pages = {2378--2403},
publisher = {Institute of Mathematical Statistics},
title = {{Dynamic network models and graphon estimation}},
url = {https://doi.org/10.1214/18-AOS1751},
volume = {47},
year = {2019}
}
@article{Ronn2009,
author = {R{\o}nn, Birgitte B and Skovgaard, Ib M},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/R{\o}nn, Skovgaard - 2009 - Nonparametric maximum likelihood estimation of randomly time-transformed curves.pdf:pdf},
journal = {Brazilian J. Probab. Stat.},
number = {1},
pages = {1--17},
title = {{Nonparametric maximum likelihood estimation of randomly time-transformed curves}},
volume = {23},
year = {2009}
}
@techreport{Daleya,
author = {Daley, D J and Springer, Vere-Jones},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Daley, Springer - Unknown - An Introduction to the Theory of Point Processes Volume I Elementary Theory and Methods, Second Edition.pdf:pdf},
title = {{An Introduction to the Theory of Point Processes: Volume I: Elementary Theory and Methods, Second Edition}}
}
@article{Armijo1966,
abstract = {Project Euclid - mathematics and statistics online},
author = {Armijo, Larry},
doi = {10.2140/pjm.1966.16.1},
issn = {00308730},
journal = {Pacific J. Math.},
title = {{Minimization of functions having lipschitz continuous first partial derivatives}},
year = {1966}
}
@article{Zhao,
abstract = {We propose a general approach for change-point detection in dynamic networks. The proposed method is model-free and covers a wide range of dynamic networks. The key idea behind our approach is to effectively utilize the network structure in designing change-point detection algorithms. This is done via an initial step of graphon estimation, where we propose a modified neighborhood smoothing (MNBS) algorithm for estimating the link probability matrices of a dynamic network. Based on the initial graphon estimation, we then develop a screening and thresholding algorithm for multiple change-point detection in dynamic networks. The convergence rate and consistency for the change-point detection procedure are derived as well as those for MNBS. When the number of nodes is large (e.g., exceeds the number of temporal points), our approach yields a faster convergence rate in detecting change-points comparing with an algorithm that simply employs averaged information of the dynamic network across time. Numerical experiments demonstrate robust performance of the proposed algorithm for change-point detection under various types of dynamic networks, and superior performance over existing methods is observed. A real data example is provided to illustrate the effectiveness and practical impact of the procedure.},
archivePrefix = {arXiv},
arxivId = {1908.01823v1},
author = {Zhao, Zifeng and Chen, Li and Lin, Lizhen},
eprint = {1908.01823v1},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhao, Chen, Lin - Unknown - Change-point detection in dynamic networks via graphon estimation.pdf:pdf},
title = {{Change-point detection in dynamic networks via graphon estimation}}
}
@article{Perry2013,
abstract = {Network data often take the form of repeated interactions between senders and receivers tabulated over time. A primary question to ask of such data is which traits and behaviors are predictive of interaction. To answer this question, a model is introduced for treating directed interactions as a multivariate point process: a Cox multiplicative intensity model using covariates that depend on the history of the process. Consistency and asymptotic normality are proved for the resulting partial-likelihood-based estimators under suitable regularity conditions, and an efficient fitting procedure is described. Multicast interactions--those involving a single sender but multiple receivers--are treated explicitly. The resulting inferential framework is then employed to model message sending behavior in a corporate e-mail network. The analysis gives a precise quantification of which static shared traits and dynamic network effects are predictive of message recipient selection.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1703v3},
author = {Perry, Patrick O. and Wolfe, Patrick J.},
doi = {10.1111/rssb.12013},
eprint = {arXiv:1011.1703v3},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Perry, Wolfe - 2013 - Point process modelling for directed interaction networks(2).pdf:pdf},
issn = {13697412},
journal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
keywords = {Cox proportional hazards model,Network data analysis,Partial likelihood inference,Point processes},
month = {nov},
number = {5},
pages = {821--849},
title = {{Point process modelling for directed interaction networks}},
url = {http://doi.wiley.com/10.1111/rssb.12013},
volume = {75},
year = {2013}
}
@article{Airoldi2013,
abstract = {Non-parametric approaches for analyzing network data based on exchangeable graph models (ExGM) have recently gained interest. The key object that defines an ExGM is often referred to as a graphon. This non-parametric perspective on network modeling poses challenging questions on how to make inference on the graphon underlying observed network data. In this paper, we propose a computationally efficient procedure to estimate a graphon from a set of observed networks generated from it. This procedure is based on a stochastic blockmodel approximation (SBA) of the graphon. We show that, by approximating the graphon with a stochastic block model, the graphon can be consistently estimated, that is, the estimation error vanishes as the size of the graph approaches infinity.},
archivePrefix = {arXiv},
arxivId = {1311.1731},
author = {Airoldi, Edoardo M and Costa, Thiago B and Chan, Stanley H},
eprint = {1311.1731},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Airoldi, Costa, Chan - 2013 - Stochastic blockmodel approximation of a graphon Theory and consistent estimation(2).pdf:pdf},
month = {nov},
title = {{Stochastic blockmodel approximation of a graphon: Theory and consistent estimation}},
url = {http://arxiv.org/abs/1311.1731},
year = {2013}
}
@article{Li2017,
abstract = {Given a set of data, one central goal is to group them into clusters based on some notion of similarity between the individual objects. One of the most popular and widely-used approaches is k-means despite the computational hardness to find its global minimum. We study and compare the properties of different convex relaxations by relating them to corresponding proximity conditions, an idea originally introduced by Kumar and Kannan. Using conic duality theory, we present an improved proximity condition under which the Peng-Wei relaxation of k-means recovers the underlying clusters exactly. Our proximity condition improves upon Kumar and Kannan, and is comparable to that of Awashti and Sheffet where proximity conditions are established for projective k-means. In addition, we provide a necessary proximity condition for the exactness of the Peng-Wei relaxation. For the special case of equal cluster sizes, we establish a different and completely localized proximity condition under which the Amini-Levina relaxation yields exact clustering, thereby having addressed an open problem by Awasthi and Sheffet in the balanced case. Our framework is not only deterministic and model-free but also comes with a clear geometric meaning which allows for further analysis and generalization. Moreover, it can be conveniently applied to analyzing various data generative models such as the stochastic ball models and Gaussian mixture models. With this method, we improve the current minimum separation bound for the stochastic ball models and achieve the state-of-the-art results of learning Gaussian mixture models.},
annote = {The exact recovery by the Peng-Wei relaxation is possible if and only if the proximity condition is satistied.

Does the proximity condition mean "well seperated?"},
archivePrefix = {arXiv},
arxivId = {1710.06008},
author = {Li, Xiaodong and Li, Yang and Ling, Shuyang and Strohmer, Thomas and Wei, Ke},
eprint = {1710.06008},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2017 - When Do Birds of a Feather Flock Together k-Means, Proximity, and Conic Programming(2).pdf:pdf},
month = {oct},
title = {{When Do Birds of a Feather Flock Together? k-Means, Proximity, and Conic Programming}},
url = {http://arxiv.org/abs/1710.06008},
year = {2017}
}
@article{Vimond2010,
abstract = {In this paper, we observe a fixed number of unknown 2$\pi$-periodic functions differing from each other by both phases and amplitude. This semiparametric model appears in literature under the name "shape invariant model." While the common shape is unknown, we introduce an asymptotically efficient estimator of the finite-dimensional parameter (phases and amplitude) using the profile likelihood and the Fourier basis. Moreover, this estimation method leads to a consistent and asymptotically linear estimator for the common shape.},
annote = {Using trigonometric polynomial to obtain an estimation of common shape curve (including unknown parameters) =={\textgreater}{\textgreater} Obtain the profile log-likelihood =={\textgreater}{\textgreater} Estimator of parameters =={\textgreater}{\textgreater} Estimated common shape.},
archivePrefix = {arXiv},
arxivId = {1010.0796v1},
author = {Vimond, Myriam},
doi = {10.1214/07-AOS566},
eprint = {1010.0796v1},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Vimond - 2010 - EFFICIENT ESTIMATION FOR A SUBCLASS OF SHAPE INVARIANT MODELS.pdf:pdf},
journal = {Ann. Stat.},
number = {3},
pages = {1885--1912},
title = {{Efficient estimation for a subclass of shape invariant models}},
volume = {38},
year = {2010}
}
@article{Chi2019,
abstract = {Substantial progress has been made recently on developing provably accurate and efficient algorithms for low-rank matrix factorization via nonconvex optimization. While conventional wisdom often takes a dim view of nonconvex optimization algorithms due to their susceptibility to spurious local minima, simple iterative methods such as gradient descent have been remarkably successful in practice. The theoretical footings, however, had been largely lacking until recently. In this tutorial-style overview, we highlight the important role of statistical models in enabling efficient nonconvex optimization with performance guarantees. We review two contrasting approaches: (1) two-stage algorithms, which consist of a tailored initialization step followed by successive refinement; and (2) global landscape analysis and initialization-free algorithms. Several canonical matrix factorization problems are discussed, including but not limited to matrix sensing, phase retrieval, matrix completion, blind deconvolution, robust principal component analysis, phase synchronization, and joint alignment. Special care is taken to illustrate the key technical insights underlying their analyses. This article serves as a testament that the integrated consideration of optimization and statistics leads to fruitful research findings.},
archivePrefix = {arXiv},
arxivId = {arXiv:1809.09573v1},
author = {Chi, Yuejie and Lu, Yue M. and Chen, Yuxin},
doi = {10.1109/tsp.2019.2937282},
eprint = {arXiv:1809.09573v1},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/Chi et al. 2018.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Trans. Signal Process.},
pages = {1--1},
title = {{Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview}},
year = {2019}
}
@article{Hanneke2010,
abstract = {We propose a family of statistical models for social network evolution over time, which represents an extension of Exponential Random Graph Models (ERGMs). Many of the methods for ERGMs are readily adapted for these models, including maximum likelihood estimation algorithms. We discuss models of this type and their properties, and give examples, as well as a demonstration of their use for hypothesis testing and classification. We believe our temporal ERG models represent a useful new framework for modeling time-evolving social networks, and rewiring networks from other domains such as gene regulation circuitry, and communication networks.},
author = {Hanneke, Steve and Fu, Wenjie and Xing, Eric P.},
doi = {10.1214/09-EJS548},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Hanneke, Fu, Xing - 2010 - Discrete temporal models of social networks.pdf:pdf},
issn = {19357524},
journal = {Electron. J. Stat.},
pages = {585--605},
title = {{Discrete temporal models of social networks}},
volume = {4},
year = {2010}
}
@article{Fienberg2006,
author = {Fienberg, Stephen E. and Wasserman, Stanley},
doi = {10.2307/2287039},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Fienberg, Wasserman - 2006 - An Exponential Family of Probability Distributions for Directed Graphs Comment.pdf:pdf},
issn = {01621459},
journal = {J. Am. Stat. Assoc.},
month = {may},
number = {373},
pages = {54},
publisher = {JSTOR},
title = {{An Exponential Family of Probability Distributions for Directed Graphs: Comment}},
volume = {76},
year = {2006}
}
@article{Le2016b,
abstract = {Community detection is one of the fundamental problems of network analysis, for which a number of methods have been proposed. Most model-based or criteria-based methods have to solve an optimization problem over a discrete set of labels to find communities, which is computationally infea-sible. Some fast spectral algorithms have been proposed for specific methods or models, but only on a case-by-case basis. Here, we propose a general approach for maximizing a function of a network adjacency matrix over discrete labels by projecting the set of labels onto a subspace approximating the leading eigenvectors of the expected adjacency matrix. This projection onto a low-dimensional space makes the feasible set of labels much smaller and the optimization problem much easier. We prove a general result about this method and show how to apply it to several previously proposed community detection criteria, establishing its consistency for label estimation in each case and demonstrating the fundamental connection between spectral properties of the network and various model-based approaches to community detection. Simulations and applications to real-world data are included to demonstrate our method performs well for multiple problems over a wide range of parameters.},
author = {Le, Can M and Levina, Elizaveta and Vershynin, Roman},
doi = {10.1214/15-AOS1360},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Le, Levina, Vershynin - 2016 - OPTIMIZATION VIA LOW-RANK APPROXIMATION FOR COMMUNITY DETECTION IN NETWORKS(2).pdf:pdf},
journal = {Ann. Stat.},
keywords = {62G20,62H25,62H30,Community detection,social networks,spectral clustering,stochastic block model},
number = {1},
pages = {373--400},
title = {{Optimization via low-rank approximation for community detection in networks}},
volume = {44},
year = {2016}
}
@article{Lawton1971,
author = {Lawton, William H. and Sylvestre, Edward A.},
doi = {10.2307/1267173},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Lawton, Sylvestre - 1971 - Self Modeling Curve Resolution.pdf:pdf},
issn = {00401706},
journal = {Technometrics},
month = {aug},
number = {3},
pages = {617},
title = {{Self Modeling Curve Resolution}},
url = {https://www.jstor.org/stable/1267173?origin=crossref},
volume = {13},
year = {1971}
}
@article{Holme,
abstract = {The power of any kind of network approach lies in the ability to simplify a complex system so that one can better understand its function as a whole. Sometimes it is beneficial, however, to include more information than in a simple graph of only nodes and links. Adding information about times of interactions can make predictions and mechanistic understanding more accurate. The drawback, however, is that there are not so many methods available, partly because temporal networks is a relatively young field, partly because it more difficult to develop such methods compared to for static networks. In this colloquium, we review the methods to analyze and model temporal networks and processes taking place on them, focusing mainly on the last three years. This includes the spreading of infectious disease, opinions, rumors, in social networks; information packets in computer networks; various types of signaling in biology, and more. We also discuss future directions.},
annote = {Review paper.},
archivePrefix = {arXiv},
arxivId = {1508.01303v3},
author = {Holme, Petter},
eprint = {1508.01303v3},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Holme - Unknown - Modern temporal network theory A colloquium.pdf:pdf},
title = {{Modern temporal network theory: A colloquium}},
url = {http://www.sociopatterns.org/.}
}
@article{Gao2017,
abstract = {Community detection is a fundamental statistical problem in network data analysis. In this paper, we present a polynomial time two-stage method that provably achieves optimal statistical performance in misclassification proportion for stochastic block model under weak regularity conditions. Our two-stage procedure consists of a refinement stage motivated by penalized local maximum likelihood estimation. This stage can take a wide range of weakly consistent community detection procedures as its initializer, to which it applies and outputs a community assignment that achieves optimal misclassification proportion with high probability. The theoretical property is confirmed by simulated examples.},
author = {Gao, Chao and Ma, Zongming and Zhang, Anderson Y and Zhou, Harrison H},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2017 - Achieving Optimal Misclassification Proportion in Stochastic Block Models.pdf:pdf},
journal = {J. Mach. Learn. Res.},
keywords = {Clustering,Community detection,Minimax rates,Network analysis,Spectral clustering},
pages = {1--45},
title = {{Achieving Optimal Misclassification Proportion in Stochastic Block Models}},
url = {http://jmlr.org/papers/v18/16-245.html.},
volume = {18},
year = {2017}
}
@article{Kay2016,
author = {Kay, Kenneth and Sosa, Marielena and Chung, Jason E and Mattias, P and Larkin, Margaret C and Frank, Loren M},
doi = {10.1038/nature17144},
file = {:Users/bgemily/Documents/Academic/SC/Stage1/nature17144.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
number = {7593},
pages = {258--264},
publisher = {Nature Publishing Group},
title = {{A hippocampal network for spatial coding during immobility and sleep}},
url = {http://dx.doi.org/10.1038/nature17144},
volume = {531},
year = {2016}
}
@article{Li2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1612.04717v6},
author = {Li, Tianxi and Levina, Elizaveta and Zhu, Ji},
eprint = {arXiv:1612.04717v6},
file = {:Users/bgemily/Documents/Academic/SC/Stage2/Theory/1612.04717.pdf:pdf},
pages = {1--50},
title = {{Network cross-validation by edge sampling}},
year = {2019}
}
@article{Lee2019a,
abstract = {There have been rapid developments in model-based clustering of graphs, also known as block modelling, over the last ten years or so. We review different approaches and extensions proposed for different aspects in this area, such as the type of the graph, the clustering approach, the inference approach, and whether the number of groups is selected or estimated. We also review models that combine block modelling with topic modelling and/or longitudinal modelling, regarding how these models deal with multiple types of data. How different approaches cope with various issues will be summarised and compared, to facilitate the demand of practitioners for a concise overview of the current status of these areas of literature.},
archivePrefix = {arXiv},
arxivId = {1903.00114},
author = {Lee, Clement and Wilkinson, Darren J.},
doi = {10.1007/s41109-019-0232-2},
eprint = {1903.00114},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Lee, Wilkinson - 2019 - A review of stochastic block models and extensions for graph clustering(2).pdf:pdf},
issn = {23648228},
journal = {Appl. Netw. Sci.},
keywords = {Longitudinal modelling,Mixed membership models,Model-based clustering,Statistical inference,Stochastic block models,Topic modelling},
month = {dec},
number = {1},
pages = {1--50},
publisher = {Springer},
title = {{A review of stochastic block models and extensions for graph clustering}},
volume = {4},
year = {2019}
}
@article{Newman,
abstract = {We propose and study a set of algorithms for discovering community structure in networks-natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using any one of a number of possible ''betweenness'' measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems.},
annote = {Generate a graph / Known network {\textgreater}{\textgreater} Use the proposed algorithm to construct a dendrogram {\textgreater}{\textgreater} Compute the modularity (quality of clustering) {\textgreater}{\textgreater} The peak of modularity coincides with the ground truth / Compare the group results with true groups (when {\#}groups is small)},
author = {Newman, M E J and Girvan, M},
doi = {10.1103/PhysRevE.69.026113},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Newman, Girvan - Unknown - Finding and evaluating community structure in networks.pdf:pdf},
keywords = {0510a,8723Ge,8920Hh,numbers: 8975Hc},
title = {{Finding and evaluating community structure in networks}}
}
@article{Wang1997,
annote = {Dynamic time warping: find the best match between two curves by some alignment w, based on minimizing a cost function (e.g. l2)

Structural analysis: Identify the individual structural points which are features that are common to all or most curves =={\textgreater} Shift functions based on the locations of the structural points =={\textgreater} Obtain structural average

Incorporate derivatives of functions into the cost function in order to align maxima, minima, and inflection points of curves.},
author = {Wang, Kongming and Gasser, Theo},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Gasser - 1997 - ALIGNMENT OF CURVES BY DYNAMIC TIME WARPING 1.pdf:pdf},
journal = {Ann. Stat.},
number = {3},
pages = {1276},
title = {{Alignment of curves by dynamic time warping}},
volume = {25},
year = {1997}
}
@article{Yang2011,
abstract = {Although a large body of work is devoted to finding communities in static social networks, only a few studies examined the dynamics of communities in evolving social networks. In this paper, we propose a dynamic stochastic block model for finding communities and their evolution in a dynamic social network. The proposed model captures the evolution of communities by explicitly modeling the transition of community memberships for individual nodes in the network. Unlike many existing approaches for modeling social networks that estimate parameters by their most likely values (i.e., point estimation), in this study, we employ a Bayesian treatment for parameter estimation that computes the posterior distributions for all the unknown parameters. This Bayesian treatment allows us to capture the uncertainty in parameter values and therefore is more robust to data noise than point estimation. In addition, an efficient algorithm is developed for Bayesian inference to handle large sparse social networks. Extensive experimental studies based on both synthetic data and real-life data demonstrate that our model achieves higher accuracy and reveals more insights in the data than several state-of-the-art algorithms. {\textcopyright} 2010 The Author(s).},
annote = {Assumes that for each node, its membership forms a Markov chain independent of other nodes; however, the connection probabilities do not change in time.

Employ a Bayesian treatment for parameter estimation that computes the posterior distributions for all the unknown parameters.},
author = {Yang, Tianbao and Chi, Yun and Zhu, Shenghuo and Gong, Yihong and Jin, Rong},
doi = {10.1007/s10994-010-5214-7},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Yang et al. - 2011 - Detecting communities and their evolutions in dynamic social networks - A Bayesian approach.pdf:pdf},
issn = {08856125},
journal = {Mach. Learn.},
keywords = {Bayesian inference,Community,Community evolution,Dynamic stochastic block model,Gibbs sampling,Social network},
month = {feb},
number = {2},
pages = {157--189},
title = {{Detecting communities and their evolutions in dynamic social networks - A Bayesian approach}},
volume = {82},
year = {2011}
}
@article{Frank1986,
abstract = {Log-linear statistical models are used to characterize ran- dom graphs with general dependence structure and with Markov dependence. Sufficient statistics for Markov graphs are shown to be given by counts of various triangles and stars. Inparticular, we show under which assumptions the triad counts are sufficient statistics. We discuss inference methodology for some simple Markov graphs.},
author = {Frank, Ove and Strauss, David},
doi = {10.1080/01621459.1986.10478342},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Frank, Strauss - 1986 - Markov graphs.pdf:pdf},
issn = {1537274X},
journal = {J. Am. Stat. Assoc.},
keywords = {Graph inference,Log-linear network model,Markov field},
number = {395},
pages = {832--842},
title = {{Markov graphs}},
volume = {81},
year = {1986}
}
@article{Klopp2017,
abstract = {Inhomogeneous random graph models encompass many network models such as stochastic block models and latent position models. We consider the problem of statistical estimation of the matrix of connection probabilities based on the observations of the adjacency matrix of the network. Taking the stochastic block model as an approximation, we construct estimators of network connection probabilities-the ordinary block constant least squares estimator, and its restricted version. We show that they satisfy oracle inequalities with respect to the block constant oracle. As a consequence, we derive optimal rates of estimation of the probability matrix. Our results cover the important setting of sparse networks. Another consequence consists in establishing upper bounds on the minimax risks for graphon estimation in the L 2 norm when the probability matrix is sampled according to a graphon model. These bounds include an additional term accounting for the "agnostic" error induced by the variability of the latent unobserved variables of the graphon model. In this setting, the optimal rates are influenced not only by the bias and variance components as in usual nonparametric problems but also include the third component, which is the agnostic error. The results shed light on the differences between estimation under the empirical loss (the probability matrix estimation) and under the integrated loss (the graphon estimation). 1. Introduction. Consider a network defined as an undirected graph with n nodes. Assume that we observe the values A ij ∈ {\{}0, 1{\}} where A ij = 1 is interpreted as the fact that the nodes i and j are connected and A ij = 0 otherwise. We set A ii = 0 for all 1 ≤ i ≤ n and we assume that A ij is a Bernoulli random variable with parameter (0) ij = P(A ij = 1) for 1 ≤ j {\textless} i ≤ n. The random variables A ij , 1 ≤ j {\textless} i ≤ n, are assumed independent. We denote by A the adjacency matrix, that is, the n × n symmetric matrix with entries A ij for 1 ≤ j {\textless} i ≤ n and zero di},
author = {Klopp, Olga and Tsybakov, Alexandre B. and Verzelen, Nicolas},
doi = {10.1214/16-AOS1454},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Klopp, Tsybakov, Verzelen - 2017 - Oracle inequalities for network models and sparse graphon estimation.pdf:pdf},
issn = {00905364},
journal = {Ann. Stat.},
keywords = {Inhomogeneous random graph,Networks,Oracle inequality,Sparse graphon,Sparsity,Stochastic block model},
month = {feb},
number = {1},
pages = {316--354},
publisher = {Institute of Mathematical Statistics},
title = {{Oracle inequalities for network models and sparse graphon estimation}},
volume = {45},
year = {2017}
}
@article{Economics2019,
author = {Economics, Financial and Associa-, American Statistical and Sigkdd, A C M and Conference, International and Discovery, Knowledge and Mining, Data},
file = {:Users/bgemily/Documents/Academic/SC/Stage1/References.pdf:pdf},
number = {Spring},
pages = {1--7},
title = {{References for STA 251 ( Spring 2019 )}},
volume = {251},
year = {2019}
}
@article{Wolfe,
abstract = {We propose a nonparametric framework for the analysis of networks , based on a natural limit object termed a graphon. We prove consistency of graphon estimation under general conditions, giving rates which include the important practical setting of sparse networks. Our results cover dense and sparse stochastic blockmodels with a growing number of classes, under model misspecification. We use profile likelihood methods, and connect our results to approximation theory, nonparametric function estimation, and the theory of graph limits.},
archivePrefix = {arXiv},
arxivId = {1309.5936v1},
author = {Wolfe, Patrick J. and Olhede, Sofia C.},
eprint = {1309.5936v1},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Wolfe, Olhede - Unknown - Nonparametric graphon estimation.pdf:pdf},
keywords = {05C80,62G05,62G20,graph limits,nonparametric regression,sparse random graphs,statistical network analysis,stochastic blockmodels},
month = {sep},
title = {{Nonparametric graphon estimation}},
url = {http://arxiv.org/abs/1309.5936},
year = {2013}
}
@article{Kass2018,
abstract = {Mathematical and statistical models have played important roles in neuroscience, especially by describing the electrical activity of neurons recorded individually, or collectively across large networks. As the field moves forward rapidly, new challenges are emerging. For maximal effectiveness , those working to advance computational neuroscience will need to appreciate and exploit the complementary strengths of mechanistic theory and the statistical paradigm.},
author = {Kass, Robert E and Amari, Shun-Ichi and Arai, Kensuke and Brown, Emery N and Diekman, Casey O and Diesmann, Markus and Doiron, Brent and Eden, Uri T and Fairhall, Adrienne L and Fiddyment, Grant M and Fukai, Tomoki and Gr{\"{u}}nGr, Sonja and Harrison, Matthew T and Helias, Moritz and Nakahara, Hiroyuki and Teramae, Jun-nosuke and Thomas, Peter J and Reimers, Mark and Rodu, Jordan and Rotstein, Horacio G and Shea-Brown, Eric and Shimazaki, Hideaki and Shinomoto, Shigeru and Yu, Byron M and Kramer, Mark A},
doi = {10.1146/annurev-statistics},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Kass et al. - 2018 - Annual Review of Statistics and Its Application Computational Neuroscience Mathematical and Statistical Perspective.pdf:pdf},
keywords = {neural data analysis,neural modeling,neural networks,theoretical neuroscience},
title = {{Annual Review of Statistics and Its Application Computational Neuroscience: Mathematical and Statistical Perspectives}},
url = {https://doi.org/10.1146/annurev-statistics-},
year = {2018}
}
@article{Liu2018,
abstract = {Community detection is challenging when the network structure is estimated with uncertainty. Dynamic networks present additional challenges but also add information across time periods. We propose a global community detection method, persistent communities by eigenvector smoothing (PisCES), that combines information across a series of networks, longitudinally, to strengthen the inference for each period. Our method is derived from evolutionary spectral clustering and degree correction methods. Data-driven solutions to the problem of tuning parameter selection are provided. In simulations we find that PisCES performs better than competing methods designed for a low signal-to-noise ratio. Recently obtained gene expression data from rhesus monkey brains provide samples from finely partitioned brain regions over a broad time span including pre- and postnatal periods. Of interest is how gene communities develop over space and time; however, once the data are divided into homogeneous spatial and temporal periods, sample sizes are very small, making inference quite challenging. Applying PisCES to medial prefrontal cortex in monkey rhesus brains from near conception to adulthood reveals dense communities that persist, merge, and diverge over time and others that are loosely organized and short lived, illustrating how dynamic community detection can yield interesting insights into processes such as brain development.},
author = {Liu, Fuchen and Choi, David and Xie, Lu and Roeder, Kathryn},
doi = {10.1073/pnas.1718449115},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Liu et al. - 2018 - Global spectral clustering in dynamic networks.pdf:pdf},
issn = {10916490},
journal = {Proc. Natl. Acad. Sci. U. S. A.},
keywords = {Community detection,Dynamic networks,Gene expression networks},
month = {jan},
number = {5},
pages = {927--932},
publisher = {National Academy of Sciences},
title = {{Global spectral clustering in dynamic networks}},
volume = {115},
year = {2018}
}
@article{Bigot2013a,
abstract = {In this paper, we consider the problem of estimating nonpara-metrically a mean pattern intensity $\lambda$ from the observation of n independent and non-homogeneous Poisson processes N 1 ,. .. , N n on the interval [0, 1]. This problem arises when data (counts) are collected independently from n individuals according to similar Poisson processes. We show that estimating this intensity is a deconvolution problem for which the density of the random shifts plays the role of the convolution operator. In an asymptotic setting where the number n of observed trajectories tends to infinity, we derive upper and lower bounds for the minimax quadratic risk over Besov balls. Non-linear thresholding in a Meyer wavelet basis is used to derive an adaptive estimator of the intensity. The proposed estimator is shown to achieve a near-minimax rate of convergence. This rate depends both on the smoothness of the intensity function and the density of the random shifts, which makes a connection between the classical deconvolution problem in nonparametric statistics and the estimation of a mean intensity from the observations of independent Poisson processes.},
annote = {They assume the density of the random shifts is known.},
author = {Bigot, J{\'{e}}r{\'{e}}mie and Gadat, S{\'{e}}bastien and Klein, Thierry and Marteau, Cl{\'{e}}ment},
doi = {10.1214/13-EJS794},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Bigot et al. - 2013 - Intensity estimation of non-homogeneous Poisson processes from shifted trajectories.pdf:pdf},
issn = {1935-7524},
journal = {Electron. J. Stat.},
keywords = {42C40Poisson processes,62G08,Besov space,Meyer wavelets,adaptive estimation,deconvolution,intensity estimation,minimax rate,random shifts},
pages = {881--931},
title = {{Intensity estimation of non-homogeneous Poisson processes from shifted trajectories}},
volume = {7},
year = {2013}
}
@article{Wolfe2013a,
abstract = {We propose a nonparametric framework for the analysis of networks, based on a natural limit object termed a graphon. We prove consistency of graphon estimation under general conditions, giving rates which include the important practical setting of sparse networks. Our results cover dense and sparse stochastic blockmodels with a growing number of classes, under model misspecification. We use profile likelihood methods, and connect our results to approximation theory, nonparametric function estimation, and the theory of graph limits.},
archivePrefix = {arXiv},
arxivId = {1309.5936},
author = {Wolfe, Patrick J. and Olhede, Sofia C.},
eprint = {1309.5936},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Wolfe, Olhede - 2013 - Nonparametric graphon estimation.pdf:pdf},
month = {sep},
title = {{Nonparametric graphon estimation}},
url = {http://arxiv.org/abs/1309.5936},
year = {2013}
}
@techreport{Handcock2007,
abstract = {Network models are widely used to represent relations between interacting units or actors. Network data often exhibit transitivity, meaning that two actors that have ties to a third actor are more likely to be tied than actors that do not, homophily by attributes of the actors or dyads, and clustering. Interest often focuses on finding clusters of actors or ties, and the number of groups in the data is typically unknown. We propose a new model, the latent position cluster model , under which the probability of a tie between two actors depends on the distance between them in an unobserved Euclidean 'social space', and the actors' locations in the latent social space arise from a mixture of distributions, each corresponding to a cluster. We propose two estimation methods: a two-stage maximum likelihood method and a fully Bayesian method that uses Markov chain Monte Carlo sampling. The former is quicker and simpler, but the latter performs better. We also propose a Bayesian way of determining the number of clusters that are present by using approximate conditional Bayes factors. Our model represents transitivity, homophily by attributes and clustering simultaneously and does not require the number of clusters to be known. The model makes it easy to simulate realistic networks with clustering, which are potentially useful as inputs to models of more complex systems of which the network is part, such as epidemic models of infectious disease. We apply the model to two networks of social relations. A free software package in the R statistical language, latentnet, is available to analyse data by using the model.},
author = {Handcock, Mark S and Raftery, Adrian E and Tantrum, Jeremy M},
booktitle = {J. R. Stat. Soc. A},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Handcock, Raftery, Tantrum - 2007 - Model-based clustering for social networks.pdf:pdf},
keywords = {Bayes factor,Dyad,Latent space,Markov chain Monte Carlo methods,Mixture model,Transitivity},
number = {2},
pages = {301--354},
title = {{Model-based clustering for social networks}},
volume = {170},
year = {2007}
}
@article{Himelboim2019,
abstract = {{\textless}p{\textgreater}The diffusion of social networking platforms ushered in a new age of peer-to-peer distributed online advertising content, widely referred to as viral advertising. The current study proposes a social networks approach to the study of viral advertising and identifying influencers. Expanding beyond the conventional retweets metrics to include Twitter mentions as connection in the network, this study identifies three groups of influencers, based on their connectivity in their networks: Hubs, or highly retweeted users, are Primary Influencers; Bridges, or highly mentioned users who associate connect users who would otherwise be disconnected, are Contextual Influencers, and Isolates are the Low Influence users. Each of these users' roles in viral advertising is discussed and illustrated through the Heineken's Worlds Apart campaign as a case study. Providing a unique examination of viral advertising from a network paradigm, our study advances scholarship on social media influencers and their contribution to content virality on digital platforms.{\textless}/p{\textgreater}},
author = {Himelboim, Itai and Golan, Guy J.},
doi = {10.1177/2056305119847516},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Himelboim, Golan - 2019 - A Social Networks Approach to Viral Advertising The Role of Primary, Contextual, and Low Influencers.pdf:pdf},
issn = {2056-3051},
journal = {Soc. Media + Soc.},
keywords = {Twitter,social media influencers,social networks,viral advertising,viral marketing},
month = {jul},
number = {3},
pages = {205630511984751},
publisher = {SAGE Publications Ltd},
title = {{A Social Networks Approach to Viral Advertising: The Role of Primary, Contextual, and Low Influencers}},
url = {http://journals.sagepub.com/doi/10.1177/2056305119847516},
volume = {5},
year = {2019}
}
@article{Pollard1981a,
annote = {Conditions are found that ensure the almost sure convergence, as the sample size increases, of the set of means of the k clusters.

Results can be generalized to any metric space for which all the closed balls are compact would do.},
author = {Pollard, David},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Pollard - 1981 - Strong Consistency of K-Means Clustering.pdf:pdf},
journal = {Source Ann. Stat.},
number = {1},
pages = {135--140},
title = {{Strong Consistency of K-Means Clustering}},
volume = {9},
year = {1981}
}
@article{Matrix2019,
author = {Matrix, Incomplete},
file = {:Users/bgemily/Documents/Academic/SC/graphon/Weekly{\_}Report/09192019{\_}simulation.pdf:pdf},
pages = {1--8},
title = {{Generating the Incomplete Matrix}},
year = {2019}
}
@book{Daley,
author = {Daley, D J and Springer, Vere-Jones},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Daley, Springer - Unknown - An Introduction to the Theory of Point Processes Volume I Elementary Theory and Methods, Second Edition(2).pdf:pdf},
title = {{An Introduction to the Theory of Point Processes: Volume I: Elementary Theory and Methods, Second Edition}}
}
@article{Zhaoa,
abstract = {We study the estimation of low rank matrices via nonconvex optimization. Compared with convex relaxation, nonconvex optimization exhibits superior empirical performance for large scale instances of low rank matrix estimation. However, the understanding of its theoretical guarantees are limited. In this paper, we define the notion of projected oracle divergence based on which we establish sufficient conditions for the success of nonconvex optimization. We illustrate the consequences of this general framework for matrix sensing. In particular, we prove that a broad class of nonconvex optimization algorithms, including alternating minimization and gradient-type methods, geometrically converge to the global optimum and exactly recover the true low rank matrices under standard conditions.},
author = {Zhao, Tuo and Wang, Zhaoran and Liu, Han},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhao, Wang, Liu - Unknown - A Nonconvex Optimization Framework for Low Rank Matrix Estimation ⇤.pdf:pdf},
title = {{A Nonconvex Optimization Framework for Low Rank Matrix Estimation ⇤}}
}
@article{Chi2018,
abstract = {Substantial progress has been made recently on developing provably accurate and efficient algorithms for low-rank matrix factorization via nonconvex optimization. While conventional wisdom often takes a dim view of nonconvex optimization algorithms due to their susceptibility to spurious local minima, simple iterative methods such as gradient descent have been remarkably successful in practice. The theoretical footings, however, had been largely lacking until recently. In this tutorial-style overview, we highlight the important role of statistical models in enabling efficient nonconvex optimization with performance guarantees. We review two contrasting approaches: (1) two-stage algorithms, which consist of a tailored initialization step followed by successive refinement; and (2) global landscape analysis and initialization-free algorithms. Several canonical matrix factorization problems are discussed, including but not limited to matrix sensing, phase retrieval, matrix completion, blind deconvolution, robust principal component analysis, phase synchronization, and joint alignment. Special care is taken to illustrate the key technical insights underlying their analyses. This article serves as a testament that the integrated thinking of optimization and statistics leads to fruitful research findings.},
archivePrefix = {arXiv},
arxivId = {1809.09573},
author = {Chi, Yuejie and Lu, Yue M. and Chen, Yuxin},
eprint = {1809.09573},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Chi, Lu, Chen - 2018 - Nonconvex Optimization Meets Low-Rank Matrix Factorization An Overview.pdf:pdf},
month = {sep},
title = {{Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview}},
url = {http://arxiv.org/abs/1809.09573},
year = {2018}
}
@techreport{Erd&,
author = {Erd{\&}, P and Rbnyi, A},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Erd{\&}, Rbnyi - Unknown - ON THE EVOLUTION OF RANDOM GRAPHS.pdf:pdf},
title = {{ON THE EVOLUTION OF RANDOM GRAPHS}}
}
@article{Zhang2019,
annote = {Node features are incorporated by a linear transformation (then composed with a nonlinear function) into the connecting probability between nodes.
MLE is used to estimate the parameters.},
author = {Zhang, Yun and Chen, Kehui and Sampson, Allan and Hwang, Kai and Luna, Beatriz},
doi = {10.1080/10618600.2018.1530117},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Node Features Adjusted Stochastic Block Model.pdf:pdf},
issn = {1061-8600},
journal = {J. Comput. Graph. Stat.},
month = {apr},
number = {2},
pages = {362--373},
title = {{Node Features Adjusted Stochastic Block Model}},
url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2018.1530117},
volume = {28},
year = {2019}
}
@article{Bachem2017,
abstract = {Uniform deviation bounds limit the difference between a model's expected loss and its loss on a random sample uniformly for all models in a learning problem. In this paper, we provide a novel framework to obtain uniform deviation bounds for unbounded loss functions. As a result, we obtain competitive uniform deviation bounds for k-Means clustering under weak assumptions on the underlying distribution. If the fourth moment is bounded, we prove a rate of O ⇣ m 1 2 ⌘ compared to the previously known O ⇣ m 1 4 ⌘ rate. We further show that this rate also depends on the kurtosis-the normalized fourth moment which measures the "tailedness" of the distribution. We also provide improved rates under progressively stronger assumptions, namely, bounded higher moments, subgaussianity and bounded support of the underlying distribution.},
annote = {Provides a sample size with which the empirical quantization error is close to the expected quantization error with high probability and uniformly holds for all possible centers.},
author = {Bachem, Olivier and Lucic, Mario and {Hamed Hassani}, S and Krause, Andreas},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Bachem et al. - 2017 - Uniform Deviation Bounds for k-Means Clustering.pdf:pdf},
title = {{Uniform Deviation Bounds for k-Means Clustering}},
year = {2017}
}
@article{Pensky2019,
abstract = {In the present paper, we have studied a Dynamic Stochastic Block Model (DSBM) under the assumptions that the connection probabilities , as functions of time, are smooth and that at most s nodes can switch their class memberships between two consecutive time points. We estimate the edge probability tensor by a kernel-type procedure and extract the group memberships of the nodes by spectral clustering. The procedure is computationally viable, adaptive to the unknown smoothness of the functional connection probabilities, to the rate s of membership switching, and to the unknown number of clusters. In addition, it is accompanied by non-asymptotic guarantees for the precision of estimation and clustering. MSC 2010 subject classifications: Primary 62F12, 05C80; secondary 62H30.},
annote = {Assume neither connection probabilities, nor class memberships change drastically from one time instant to another.

1. Extract group memberships at every timepoint by using a spectral cluastering procedure;
2. the clustering technique is applied to kernel-type estimators of the edge probability matrices
3. Using Lepskii's method, adapt the method to the unknown temporal smoothness.
4. By setting a threshold on the ratio of the eigenvalues of the estimated probability matrix, they find the estimated number of clusters.},
author = {Pensky, Marianna and Zhang, Teng},
doi = {10.1214/19-EJS1533},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Pensky, Zhang - 2019 - Spectral clustering in the dynamic stochastic block model.pdf:pdf},
issn = {1935-7524},
journal = {Electron. J. Stat.},
keywords = {05C80,62F12,62H30Time-varying network,adaptive estimation,dynamic stochastic block model,spectral clustering},
pages = {678--709},
title = {{Spectral clustering in the dynamic stochastic block model}},
url = {https://doi.org/10.1214/19-EJS1533},
volume = {13},
year = {2019}
}
@article{Keshavan2009a,
abstract = {Let M be a random (alpha n) x n matrix of rank r{\textless}{\textless}n, and assume that a uniformly random subset E of its entries is observed. We describe an efficient algorithm that reconstructs M from |E| = O(rn) observed entries with relative root mean square error RMSE {\textless}= C(rn/|E|){\^{}}0.5 . Further, if r=O(1), M can be reconstructed exactly from |E| = O(n log(n)) entries. These results apply beyond random matrices to general low-rank incoherent matrices. This settles (in the case of bounded rank) a question left open by Candes and Recht and improves over the guarantees for their reconstruction algorithm. The complexity of our algorithm is O(|E|r log(n)), which opens the way to its use for massive data sets. In the process of proving these statements, we obtain a generalization of a celebrated result by Friedman-Kahn-Szemeredi and Feige-Ofek on the spectrum of sparse random matrices.},
archivePrefix = {arXiv},
arxivId = {0901.3150},
author = {Keshavan, Raghunandan H. and Montanari, Andrea and Oh, Sewoong},
eprint = {0901.3150},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Keshavan, Montanari, Oh - 2009 - Matrix Completion from a Few Entries.pdf:pdf},
month = {jan},
title = {{Matrix Completion from a Few Entries}},
url = {http://arxiv.org/abs/0901.3150},
year = {2009}
}
@article{Banerjee2007,
abstract = {We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse. Our approach is to solve a maximum likelihood problem with an added l{\_}1-norm penalty term. The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes. We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case. Our first algorithm uses block coordinate descent, and can be interpreted as recursive l{\_}1-norm penalized regression. Our second algorithm, based on Nesterov's first order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods. Using a log determinant relaxation of the log partition function (Wainwright {\&} Jordan (2006)), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case. We test our algorithms on synthetic data, as well as on gene expression and senate voting records data.},
archivePrefix = {arXiv},
arxivId = {0707.0704},
author = {Banerjee, Onureena and Ghaoui, Laurent El and D'Aspremont, Alexandre},
eprint = {0707.0704},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Banerjee, Ghaoui, d'Aspremont - 2007 - Model Selection Through Sparse Maximum Likelihood Estimation.pdf:pdf},
month = {jul},
title = {{Model Selection Through Sparse Maximum Likelihood Estimation}},
url = {http://arxiv.org/abs/0707.0704},
year = {2007}
}
@article{Gao2016,
abstract = {Biclustering structures in data matrices were first formalized in a seminal paper by John Hartigan (Hartigan, 1972) where one seeks to cluster cases and variables simultaneously. Such structures are also prevalent in block modeling of networks. In this paper, we develop a theory for the estimation and completion of matrices with biclustering structures, where the data is a partially observed and noise contaminated matrix with a certain underlying biclustering structure. In particular, we show that a constrained least squares estimator achieves minimax rate-optimal performance in several of the most important scenarios. To this end, we derive unified high probability upper bounds for all sub-Gaussian data and also provide matching minimax lower bounds in both Gaussian and binary cases. Due to the close connection of graphon to stochastic block models, an immediate consequence of our general results is a minimax rate-optimal estimator for sparse graphons.},
author = {Gao, Chao and Lu, Yu and Ma, Zongming and Zhou, Harrison H},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2016 - Optimal Estimation and Completion of Matrices with Biclustering Structures.pdf:pdf},
journal = {J. Mach. Learn. Res.},
keywords = {Biclustering,graphon,matrix completion,missing data,sparse network,stochastic block models},
pages = {1--29},
title = {{Optimal Estimation and Completion of Matrices with Biclustering Structures}},
volume = {17},
year = {2016}
}
@article{Cho2013,
abstract = {We propose a latent self-exciting point process model that describes geographically distributed interactions between pairs of entities. In contrast to most existing approaches that assume fully observable interactions, here we consider a scenario where certain interaction events lack information about participants. Instead, this information needs to be inferred from the available observations. We develop an efficient approximate algorithm based on variational expectation-maximization to infer unknown participants in an event given the location and the time of the event. We validate the model on synthetic as well as real-world data, and obtain very promising results on the identity-inference task. We also use our model to predict the timing and participants of future events, and demonstrate that it compares favorably with baseline approaches.},
archivePrefix = {arXiv},
arxivId = {1302.2671},
author = {Cho, Yoon-Sik and Galstyan, Aram and Brantingham, P. Jeffrey and Tita, George},
doi = {10.3934/dcdsb.2014.19.1335},
eprint = {1302.2671},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Cho et al. - 2013 - Latent Self-Exciting Point Process Model for Spatial-Temporal Networks.pdf:pdf},
month = {feb},
title = {{Latent Self-Exciting Point Process Model for Spatial-Temporal Networks}},
url = {http://arxiv.org/abs/1302.2671 http://dx.doi.org/10.3934/dcdsb.2014.19.1335},
year = {2013}
}
@article{Chan2014,
archivePrefix = {arXiv},
arxivId = {1402.1888},
author = {Chan, Stanley H. and Airoldi, Edoardo M.},
eprint = {1402.1888},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Chan, Airoldi - 2014 - A Consistent Histogram Estimator for Exchangeable Graph Models.pdf:pdf},
month = {feb},
title = {{A Consistent Histogram Estimator for Exchangeable Graph Models}},
year = {2014}
}
@article{Hoff2002a,
abstract = {Network models are widely used to represent relational information among interacting units. In studies of social networks, recent emphasis has been placed on random graph models where the nodes usually represent individual social actors and the edges represent the presence of a specii ed relation between actors. We develop a class of models where the probability of a relation between actors depends on the positions of individuals in an unobserved "social space." We make inference for the social space within maximum likelihood and Bayesian frameworks, and propose Markov chain Monte Carlo procedures for making inference on latent positions and the effects of observed covariates. We present analyses of three standard datasets from the social networks literature, and compare the method to an alternative stochastic blockmodeling approach. In addition to improving on model t for these datasets, our method provides a visual and interpretable model-based spatial representation of social relationships and improves on existing methods by allowing the statistical uncertainty in the social space to be quantii ed and graphically represented.},
annote = {From Duplicate 1 (Latent space approaches to social network analysis - Hoff, Peter D.; Raftery, Adrian E.; Handcock, Mark S.)

Each node is associated with a point in a latent space and probability of connection is higher for nodes whose latent points are closer.},
author = {Hoff, Peter D. and Raftery, Adrian E. and Handcock, Mark S.},
doi = {10.1198/016214502388618906},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Hoff, Raftery, Handcock - 2002 - Latent space approaches to social network analysis.pdf:pdf;:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Hoff, Raftery, Handcock - 2002 - Latent Space Approaches to Social Network Analysis(2).pdf:pdf},
issn = {01621459},
journal = {J. Am. Stat. Assoc.},
keywords = {Conditional independence model,Latent position model,Network data,Random graph,Visualization},
month = {dec},
number = {460},
pages = {1090--1098},
title = {{Latent Space Approaches to Social Network Analysis}},
volume = {97},
year = {2002}
}
@article{Ginestet2017,
abstract = {In recent years, it has become common practice in neuroscience to use networks to summarize relational information in a set of measurements, typically assumed to be reflective of either functional or structural relationships between regions of interest in the brain. One of the most basic tasks of interest in the analysis of such data is the testing of hypotheses, in answer to questions such as "Is there a difference between the networks of these two groups of subjects?" In the classical setting, where the unit of interest is a scalar or a vector, such questions are answered through the use of familiar two-sample testing strategies. Networks, however, are not Euclidean objects, and hence classical methods do not directly apply. We address this challenge by drawing on concepts and techniques from geometry and high-dimensional statistical inference. Our work is based on a precise geometric characterization of the space of graph Laplacian matrices and a nonparametric notion of averaging due to Fr{\'{e}}chet. We motivate and illustrate our resulting method-ologies for testing in the context of networks derived from functional neu-roimaging data on human subjects from the 1000 Functional Connectomes Project. In particular, we show that this global test is more statistically powerful than a mass-univariate approach. In addition, we have also provided a method for visualizing the individual contribution of each edge to the overall test statistic.},
author = {Ginestet, Cedric E and Li, Jun and Balachandran, Prakash and Rosenberg, Steven and {Kolaczyk †}, Eric D},
doi = {10.1214/16-AOAS1015},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Ginestet et al. - 2017 - HYPOTHESIS TESTING FOR NETWORK DATA IN FUNCTIONAL NEUROIMAGING.pdf:pdf},
journal = {Ann. Appl. Stat.},
keywords = {Frechet mean,fMRI,graph Laplacian,hypothesis testing,matrix manifold,network data,object data},
number = {2},
pages = {725--750},
title = {{HYPOTHESIS TESTING FOR NETWORK DATA IN FUNCTIONAL NEUROIMAGING}},
volume = {11},
year = {2017}
}
@article{Klopp2015,
abstract = {The objective of the present paper is to develop a minimax theory for  the varying coefficient model in a nonasymptotic setting. We consider a high-dimensional sparse varying coefficient model where only few of the covariates are present and only some of those covariates are time dependent. Our analysis allows the time-dependent covariates to have different degrees of smoothness and to be spatially inhomogeneous. We develop the minimax lower bounds for the quadratic risk and construct an adaptive estimator which attains those lower bounds within a constant (if all time-dependent covariates are spatially homogeneous) or logarithmic factor of the number of observations.},
author = {Klopp, Olga and Pensky, Marianna},
doi = {10.1214/15-aos1309},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Klopp, Pensky - 2015 - Sparse high-dimensional varying coefficient model Nonasymptotic minimax study.pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
month = {jun},
number = {3},
pages = {1273--1299},
publisher = {Institute of Mathematical Statistics},
title = {{Sparse high-dimensional varying coefficient model: Nonasymptotic minimax study}},
volume = {43},
year = {2015}
}
@article{Johnson2016,
abstract = {We propose a general modeling and inference framework that composes probabilistic graphical models with deep learning methods and combines their respective strengths. Our model family augments graphical structure in latent variables with neural network observation models. For inference, we extend variational autoencoders to use graphical model approximating distributions with recognition networks that output conjugate potentials. All components of these models are learned simultaneously with a single objective, giving a scalable algorithm that leverages stochastic variational inference, natural gradients, graphical model message passing, and the reparameterization trick. We illustrate this framework with several example models and an application to mouse behavioral phenotyping.},
archivePrefix = {arXiv},
arxivId = {1603.06277},
author = {Johnson, Matthew J. and Duvenaud, David and Wiltschko, Alexander B. and Datta, Sandeep R. and Adams, Ryan P.},
eprint = {1603.06277},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Johnson et al. - 2016 - Composing graphical models with neural networks for structured representations and fast inference.pdf:pdf},
month = {mar},
title = {{Composing graphical models with neural networks for structured representations and fast inference}},
url = {http://arxiv.org/abs/1603.06277},
year = {2016}
}
@article{Neuristique,
abstract = {This paper studies the convergence properties of the well known K-Means clustering algorithm. The K-Means algorithm can be described either as a gradient descent algorithm or by slightly extending the mathematics of the EM algorithm to this hard threshold case. We show that the K-Means algorithm actually minimizes the quantization error using the very fast Newton algorithm.},
author = {Neuristique, Leon Bottou and Bengio, Yoshua},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Neuristique, Bengio - Unknown - Convergence Properties of the K-Means Algorithms.pdf:pdf},
title = {{Convergence Properties of the K-Means Algorithms}}
}
@article{Selection2019,
author = {Selection, Step Size},
file = {:Users/bgemily/Documents/Academic/SC/graphon/Weekly{\_}Report/09252019{\_}Simulation2.pdf:pdf},
pages = {1--5},
title = {{1 GD on Manifold}},
year = {2019}
}
@article{Gamboa2007,
abstract = {We observe a large number of functions differing from each other only by a translation parameter. While the main pattern is unknown, we propose to estimate the shift parameters using M-estimators. Fourier transform enables to transform this statistical problem into a semi-parametric framework. We study the convergence of the estimator and provide its asymptotic behavior. Moreover, we use the method in the applied case of velocity curve forecasting.},
annote = {M-estimator: DFT =={\textgreater} coefficients =={\textgreater} find theta's so that the coefficients are similar

Krylov method (the conjugate gradient method)},
archivePrefix = {arXiv},
arxivId = {0712.1936v1},
author = {Gamboa, Fabrice and Loubes, Jean-Michel and Maza, Elie},
doi = {10.1214/07-EJS026},
eprint = {0712.1936v1},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gamboa, Loubes, Maza - 2007 - Semi-parametric estimation of shifts.pdf:pdf},
journal = {Electron. J. Stat.},
keywords = {AMS 2000 subject classifications: Primary 60G17; s,Empirical process,Fourier transform,M-estimation},
pages = {616--640},
title = {{Semi-parametric estimation of shifts}},
volume = {1},
year = {2007}
}
@article{KaAlbert,
abstract = {Complex networks describe a wide range of systems in nature and society. Frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the Internet, a network of routers and computers connected by physical links. While traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. This article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. After reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network's robustness against failures and attacks. CONTENTS},
author = {ka Albert, R{\'{e}} and szl{\'{o}} Barab{\'{a}} si, Albert-L{\'{a}}},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/ka Albert, szl{\'{o}} Barab{\'{a}} si - Unknown - Statistical mechanics of complex networks.pdf:pdf},
title = {{Statistical mechanics of complex networks}}
}
@article{Samelson1971,
abstract = {In this note we describe those additive mappings from a second symmetric product space to another, over a field of characteristic not 2 or 3, which preserve decomposable elements of the form ??u ??? u where u is a vector and ?? is a scalar. This leads to the corresponding result concerning additive mappings from one vector space of symmetric matrices to another which preserve rank less than or equal to one. We also discuss some consequences of this characterization theorem. ?? 2005 Elsevier Inc. All rights reserved.},
author = {Samelson, H. and Hobby, C. R. and Dugundji, J. and Arens, Richard},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/pjm-v16-n1-p01-p.pdf:pdf},
issn = {00308730},
journal = {Pacific J. Math.},
number = {3},
pages = {1},
title = {{Pacific journal of mathematics}},
volume = {37},
year = {1971}
}
@article{Diaconis2007,
abstract = {We develop a clear connection between deFinetti's theorem for exchangeable arrays (work of Aldous--Hoover--Kallenberg) and the emerging area of graph limits (work of Lovasz and many coauthors). Along the way, we translate the graph theory into more classical probability.},
archivePrefix = {arXiv},
arxivId = {0712.2749},
author = {Diaconis, Persi and Janson, Svante},
eprint = {0712.2749},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Diaconis, Janson - 2007 - Graph limits and exchangeable random graphs.pdf:pdf},
month = {dec},
title = {{Graph limits and exchangeable random graphs}},
url = {http://arxiv.org/abs/0712.2749},
year = {2007}
}
@article{SOBEL2007,
author = {SOBEL, MICHAEL E.},
doi = {10.1093/biomet/82.4.700},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/SOBEL - 2007 - Causal diagrams for empirical research.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
month = {jan},
number = {4},
pages = {700--702},
publisher = {Oxford University Press (OUP)},
title = {{Causal diagrams for empirical research}},
volume = {82},
year = {2007}
}
@article{Greene2010,
author = {Greene, Derek and Doyle, D{\'{o}}nal and Cunningham, P{\'{a}}draig},
doi = {10.1109/ASONAM.2010.17},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Greene, Doyle, Cunningham - 2010 - Tracking the Evolution of Communities in Dynamic Social Networks.pdf:pdf},
isbn = {978-1-4244-7787-6},
journal = {2010 Int. Conf. Adv. Soc. Networks Anal. Min.},
month = {aug},
pages = {176--183},
publisher = {IEEE},
title = {{Tracking the Evolution of Communities in Dynamic Social Networks}},
url = {http://ieeexplore.ieee.org/document/5562773/},
year = {2010}
}
@article{Lee2019,
abstract = {There have been rapid developments in model-based clustering of graphs, also known as block modelling, over the last ten years or so. We review different approaches and extensions proposed for different aspects in this area, such as the type of the graph, the clustering approach, the inference approach, and whether the number of groups is selected or estimated. We also review models that combine block modelling with topic modelling and/or longitudinal modelling, regarding how these models deal with multiple types of data. How different approaches cope with various issues will be summarised and compared, to facilitate the demand of practitioners for a concise overview of the current status of these areas of literature.},
archivePrefix = {arXiv},
arxivId = {1903.00114v2},
author = {Lee, Clement and Wilkinson, Darren J},
eprint = {1903.00114v2},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Lee, Wilkinson - 2019 - A Review of Stochastic Block Models and Extensions for Graph Clustering.pdf:pdf},
keywords = {Longitudinal modelling,Mixed member-ship models,Model-based clustering,Statistical inference,Stochastic block models,Topic modelling},
title = {{A Review of Stochastic Block Models and Extensions for Graph Clustering}},
year = {2019}
}
@article{Tsybakov2009,
address = {New York, NY},
author = {Tsybakov, Alexandre B.},
doi = {10.1007/b13794},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Tsybakov - 2009 - Introduction to Nonparametric Estimation.pdf:pdf},
isbn = {978-0-387-79051-0},
publisher = {Springer New York},
series = {Springer Series in Statistics},
title = {{Introduction to Nonparametric Estimation}},
url = {http://link.springer.com/10.1007/b13794},
year = {2009}
}
@article{Lei2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1802.09684v1},
author = {Lei, Jing},
eprint = {arXiv:1802.09684v1},
file = {:Users/bgemily/Documents/Academic/SC/Stage2/Theory/1802.09684.pdf:pdf},
pages = {1--35},
title = {{Network Representation Using Graph Root Distributions}},
year = {2018}
}
@article{Qiao2019,
abstract = {Graphical models have attracted increasing attention in recent years, especially in settings involving high-dimensional data. In particular, Gaussian graphical models are used to model the conditional dependence structure among multiple Gaussian random variables. As a result of its computational efficiency, the graph-ical lasso (glasso) has become one of the most popular approaches for fitting high-dimensional graphical models. In this paper, we extend the graphical models concept to model the conditional dependence structure among p random functions. In this setting, not only is p large, but each function is itself a high-dimensional object, posing an additional level of statistical and computational complexity. We develop an extension of the glasso criterion (fglasso), which estimates the functional graphical model by imposing a block sparsity constraint on the precision matrix, via a group lasso penalty. The fglasso criterion can be optimized using an efficient block coordinate descent algorithm. We establish the concentration inequalities of the estimates, which guarantee the desirable graph support recovery property, that is, with probability tending to one, the fglasso will correctly identify the true conditional dependence structure. Finally, we show that the fglasso significantly outperforms possible competing methods through both simulations and an analysis of a real-world electroencephalography dataset comparing alcoholic and nonalcoholic patients.},
author = {Qiao, Xinghao and Guo, Shaojun and James, Gareth M},
doi = {10.1080/01621459.2017.1390466},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Qiao, Guo, James - 2019 - Functional Graphical Models.pdf:pdf},
issn = {0162-1459},
journal = {J. Am. Stat. Assoc.},
keywords = {Block coordinate descent algorithm,Block sparse precision matrix,Functional data,Functional principal component analysis,Graphical models},
pages = {211--222},
title = {{Functional Graphical Models}},
url = {https://amstat.tandfonline.com/action/journalInformation?journalCode=uasa20https://doi.org/./..},
volume = {114},
year = {2019}
}
@article{Sun2016a,
archivePrefix = {arXiv},
arxivId = {arXiv:1411.8003v3},
author = {Sun, Ruoyu and Luo, Zhi-quan},
eprint = {arXiv:1411.8003v3},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/1411.8003.pdf:pdf},
number = {2},
title = {{Guaranteed Matrix Completion via Non-convex Factorization}},
year = {2016}
}
@article{Keshavan2009,
abstract = {Given a matrix M of low-rank, we consider the problem of reconstructing it from noisy observations of a small, random subset of its entries. The problem arises in a variety of applications, from collaborative filtering (the `Netflix problem') to structure-from-motion and positioning. We study a low complexity algorithm introduced by Keshavan et al.(2009), based on a combination of spectral techniques and manifold optimization, that we call here OptSpace. We prove performance guarantees that are order-optimal in a number of circumstances.},
archivePrefix = {arXiv},
arxivId = {0906.2027},
author = {Keshavan, Raghunandan H. and Montanari, Andrea and Oh, Sewoong},
eprint = {0906.2027},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Keshavan, Montanari, Oh - 2009 - Matrix Completion from Noisy Entries.pdf:pdf},
month = {jun},
title = {{Matrix Completion from Noisy Entries}},
url = {http://arxiv.org/abs/0906.2027},
year = {2009}
}
@article{Bontemps2014,
abstract = {In this paper, we consider the so-called Shape Invariant Model that is used to model a function f 0 submitted to a random translation of law g 0 in a white noise. This model is of interest when the law of the deformations is unknown. Our objective is to recover the law of the process P f 0 ,g 0 as well as f 0 and g 0. To do this, we adopt a Bayesian point of view and find priors on f and g so that the posterior distribution concentrates at a polynomial rate around P f 0 ,g 0 when n goes to +∞. We then derive results on the identifiability of the SIM, as well as results on the functional objects themselves. We intensively use Bayesian non-parametric tools coupled with mixture models, which may be of independent interest in model selection from a frequentist point of view.},
author = {Bontemps, Dominique and Gadat, S{\'{e}}bastien},
doi = {10.1214/14-EJS933},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Bontemps, Gadat - 2014 - Bayesian methods for the Shape Invariant Model.pdf:pdf},
issn = {1935-7524},
journal = {Electron. J. Stat.},
keywords = {62F15,62G05,62G20Grenander's pattern theory,Bayesian methods,Shape Invariant Model,convergence rate of posterior distribution,non-parametric estimation},
pages = {1522--1568},
title = {{Bayesian methods for the Shape Invariant Model}},
volume = {8},
year = {2014}
}
@article{Hainmueller2018,
author = {Hainmueller, Thomas and Bartos, Marlene},
file = {:Users/bgemily/Documents/Academic/SC/Stage1/s41586-018-0191-2.pdf:pdf},
title = {{Letter}},
year = {2018}
}
@article{Ling2019,
abstract = {Spectral clustering has become one of the most widely used clustering techniques when the structure of the individual clusters is non-convex or highly anisotropic. Yet, despite its immense popularity, there exists fairly little theory about performance guarantees for spectral clustering. This issue is partly due to the fact that spectral clustering typically involves two steps which complicated its theoretical analysis: first, the eigenvectors of the associated graph Laplacian are used to embed the dataset, and second, k-means clustering algorithm is applied to the embedded dataset to get the labels. This paper is devoted to the theoretical foundations of spectral clustering and graph cuts. We consider a convex relaxation of graph cuts, namely ratio cuts and normalized cuts, that makes the usual two-step approach of spectral clustering obsolete and at the same time gives rise to a rigorous theoretical analysis of graph cuts and spectral clustering. We derive deterministic bounds for successful spectral clustering via a spectral proximity condition that naturally depends on the algebraic connectivity of each cluster and the inter-cluster connectivity. Moreover, we demonstrate by means of some popular examples that our bounds can achieve near-optimality. Our findings are also fundamental to the theoretical understanding of kernel k-means. Numerical simulations confirm and complement our analysis.},
archivePrefix = {arXiv},
arxivId = {1806.11429v3},
author = {Ling, Shuyang and Strohmer, Thomas},
eprint = {1806.11429v3},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Ling, Strohmer - 2019 - Certifying Global Optimality of Graph Cuts via Semidefinite Relaxation A Performance Guarantee for Spectral Clus.pdf:pdf},
title = {{Certifying Global Optimality of Graph Cuts via Semidefinite Relaxation: A Performance Guarantee for Spectral Clustering}},
year = {2019}
}
@article{Chandrasekaran2011,
abstract = {Suppose we are given a matrix that is formed by adding an unknown sparse matrix to an unknown low-rank matrix. Our goal is to decompose the given matrix into its sparse and low-rank components. Such a problem arises in a number of applications in model and system identification, and is NP-hard in general. In this paper we consider a convex optimization formulation to splitting the specified matrix into its components, by minimizing a linear combination of the {\$}\backslashell{\_}1{\$} norm and the nuclear norm of the components. We develop a notion of $\backslash$emph{\{}rank-sparsity incoherence{\}}, expressed as an uncertainty principle between the sparsity pattern of a matrix and its row and column spaces, and use it to characterize both fundamental identifiability as well as (deterministic) sufficient conditions for exact recovery. Our analysis is geometric in nature, with the tangent spaces to the algebraic varieties of sparse and low-rank matrices playing a prominent role. When the sparse and low-rank matrices are drawn from certain natural random ensembles, we show that the sufficient conditions for exact recovery are satisfied with high probability. We conclude with simulation results on synthetic matrix decomposition problems.},
author = {Chandrasekaran, Venkat and Sanghavi, Sujay and Parrilo, Pablo A. and Willsky, Alan S.},
doi = {10.1137/090761793},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Chandrasekaran et al. - 2011 - Rank-sparsity incoherence for matrix decomposition.pdf:pdf},
issn = {10526234},
journal = {SIAM J. Optim.},
keywords = {Convex relaxation,L1 norm minimization,Matrix decomposition,Nuclear norm minimization,Rank,Semidefinite programming,Sparsity,Uncertainty principle},
number = {2},
pages = {572--596},
title = {{Rank-sparsity incoherence for matrix decomposition}},
volume = {21},
year = {2011}
}
@article{Ngo2012,
abstract = {This paper describes gradient methods based on a scaled metric on the Grassmann manifold for low-rank matrix completion. The proposed methods significantly improve canonical gradient methods, especially on ill-conditioned matrices, while maintaining established global convegence and exact recovery guarantees. A connection between a form of subspace iteration for matrix completion and the scaled gradient descent procedure is also established. The proposed conjugate gradient method based on the scaled gradient outperforms several existing algorithms for matrix completion and is competitive with recently proposed methods.},
author = {Ngo, Thanh T. and Saad, Yousef},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/ys-2012-5.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Adv. Neural Inf. Process. Syst.},
pages = {1412--1420},
title = {{Scaled gradients on Grassmann manifolds for matrix completion}},
volume = {2},
year = {2012}
}
@article{Kneip1995,
abstract = {Given data from a sample of noisy curves, we consider a nonlinear parametric regression model with unknown model function. An iterative algorithm for estimating individual parameters as well as the model function is introduced under the assumption of a certain shape invariance: the individual regression curves are obtained from a common shape function by linear transformations of the axes. Our algorithm is based on least-squares methods for parameter estimation and on nonparametric kernel methods for curve estimation. Asymptotic distributions are derived for the individual parameter estimators as well as for the estimator of the shape function. An application to human growth data illustrates the method.},
author = {Kneip, Alois and Engel, Joachim},
doi = {10.1214/aos/1176324535},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Kneip, Engel - 1995 - Model Estimation in Nonlinear Regression Under Shape Invariance.pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
month = {apr},
number = {2},
pages = {551--570},
publisher = {Institute of Mathematical Statistics},
title = {{Model Estimation in Nonlinear Regression Under Shape Invariance}},
volume = {23},
year = {1995}
}
@misc{Goldenberg2009a,
abstract = {Networks are ubiquitous in science and have become a focal point for discussion in everyday life. Formal statistical models for the analysis of network data have emerged as a major topic of interest in diverse areas of study, and most of these involve a form of graphical representation. Probability models on graphs date back to 1959. Along with empirical studies in social psychology and sociology from the 1960s, these early works generated an active "network community" and a substantial literature in the 1970s. This effort moved into the statistical literature in the late 1970s and 1980s, and the past decade has seen a burgeoning network literature in statistical physics and computer science. The growth of the World Wide Web and the emergence of online "networking communities" such as Facebook, MySpace, and LinkedIn, and a host of more specialized professional network communities has intensified interest in the study of networks and network data. Our goal in this review is to provide the reader with an entry point to this burgeoning literature. We begin with an overview of the historical development of statistical network modeling and then we introduce a number of examples that have been studied in the network literature. Our subsequent discussion focuses on a number of prominent static and dynamic network models and their interconnections. We emphasize formal model descriptions, and pay special attention to the interpretation of parameters and their estimation. We end with a description of some open problems and challenges for machine learning and statistics. {\textcopyright} 2010 A. Goldenberg, A. X. Zheng, S. E. Fienberg and E. M. Airoldi.},
archivePrefix = {arXiv},
arxivId = {0912.5410},
author = {Goldenberg, Anna and Zheng, Alice X. and Fienberg, Stephen E. and Airoldi, Edoardo M.},
booktitle = {Found. Trends Mach. Learn.},
doi = {10.1561/2200000005},
eprint = {0912.5410},
file = {:Users/bgemily/Downloads/0912.5410.pdf:pdf},
issn = {19358237},
number = {2},
pages = {129--233},
title = {{A survey of statistical network models}},
url = {http://www.nowpublishers.com/article/Details/MAL-005},
volume = {2},
year = {2009}
}
@article{Goldenberg2009,
abstract = {Networks are ubiquitous in science and have become a focal point for discussion in everyday life. Formal statistical models for the analysis of network data have emerged as a major topic of interest in diverse areas of study, and most of these involve a form of graphical representation. Probability models on graphs date back to 1959. Along with empirical studies in social psychology and sociology from the 1960s, these early works generated an active network community and a substantial literature in the 1970s. This effort moved into the statistical literature in the late 1970s and 1980s, and the past decade has seen a burgeoning network literature in statistical physics and computer science. The growth of the World Wide Web and the emergence of online networking communities such as Facebook, MySpace, and LinkedIn, and a host of more specialized professional network communities has intensified interest in the study of networks and network data. Our goal in this review is to provide the reader with an entry point to this burgeoning literature. We begin with an overview of the historical development of statistical network modeling and then we introduce a number of examples that have been studied in the network literature. Our subsequent discussion focuses on a number of prominent static and dynamic network models and their interconnections. We emphasize formal model descriptions, and pay special attention to the interpretation of parameters and their estimation. We end with a description of some open problems and challenges for machine learning and statistics.},
author = {Goldenberg, Anna},
doi = {10.1561/2200000008},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Goldenberg - 2009 - A Survey of Statistical Network Models.pdf:pdf},
issn = {1935-8237},
journal = {Found. Trends{\textregistered} Mach. Learn.},
number = {3},
pages = {235--274},
publisher = {Now Publishers},
title = {{A Survey of Statistical Network Models}},
volume = {2},
year = {2009}
}
@article{Karlsson2010,
author = {Karlsson, Mattias P and Frank, Loren M},
doi = {10.1038/nn.2344.Awake},
file = {:Users/bgemily/Documents/Academic/SC/Stage1/nihms113938.pdf:pdf},
number = {7},
pages = {913--918},
title = {{Awake replay of remote experiences in the hippocampus}},
volume = {12},
year = {2010}
}
@misc{Fortunato2010,
abstract = {The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks. {\textcopyright} 2009 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {0906.0612},
author = {Fortunato, Santo},
booktitle = {Phys. Rep.},
doi = {10.1016/j.physrep.2009.11.002},
eprint = {0906.0612},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Fortunato - 2010 - Community detection in graphs.pdf:pdf},
issn = {03701573},
keywords = {Clusters,Graphs,Statistical physics},
month = {feb},
number = {3-5},
pages = {75--174},
title = {{Community detection in graphs}},
volume = {486},
year = {2010}
}
@article{Chi2007,
abstract = {Evolutionary clustering is an emerging research area essential to important applications such as clustering dynamic Web and blog contents and clustering data streams. In evolutionary clustering, a good clustering result should fit the current data well, while simultaneously not deviate too dramatically from the recent history. To fulfill this dual purpose , a measure of temporal smoothness is integrated in the overall measure of clustering quality. In this paper, we propose two frameworks that incorporate temporal smoothness in evolutionary spectral clustering. For both frameworks, we start with intuitions gained from the well-known k-means clustering problem, and then propose and solve corresponding cost functions for the evolutionary spectral clustering problems. Our solutions to the evolutionary spectral clustering problems provide more stable and consistent clustering results that are less sensitive to short-term noises while at the same time are adaptive to long-term cluster drifts. Furthermore, we demonstrate that our methods provide the optimal solutions to the relaxed versions of the corresponding evolutionary k-means clustering problems. Performance experiments over a number of real and synthetic data sets illustrate our evolutionary spectral clustering methods provide more robust clustering results that are not sensitive to noise and can adapt to data drifts.},
annote = {Make no assumption on the mechanism that governs changes in the cluster memberships.

Propose three measurement of cluster quality:
1. K-means
2. Negated average association (within group)
3. Graph cut

Introduce two cost functions: 
1. the snapshot cost associated with the error of current clustering, 
2. and the temporal cost that measures how the clustering preserves continuity in terms of cluster memberships,},
author = {Chi, Yun and Song, Xiaodan and Zhou, Dengyong and Hino, Koji and Tseng, Belle L},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Chi et al. - 2007 - Evolutionary Spectral Clustering by Incorporating Temporal Smoothness †.pdf:pdf},
isbn = {9781595936097},
keywords = {Experimentation,H28 [Database Management]: Database Applications-D,Measurement,Mining Data Streams,Preserving Cluster Membership,Preserving Cluster Quality,Temporal Smoothness,Theory * Keywords Evolutionary Spectral Clustering},
title = {{Evolutionary Spectral Clustering by Incorporating Temporal Smoothness †}},
year = {2007}
}
@article{Paninski2004,
abstract = {Recent work has examined the estimation of models of stimulus-driven neural activity in which some linear filtering process is followed by a nonlinear, probabilistic spiking stage. We analyze the estimation of one such model for which this nonlinear step is implemented by a known parametric function; the assumption that this function is known speeds the estimation process considerably. We investigate the shape of the likelihood function for this type of model, give a simple condition on the nonlinearity ensuring that no non-global local maxima exist in the likelihood-leading, in turn, to efficient algorithms for the computation of the maximum likelihood estimator-and discuss the implications for the form of the allowed nonlinearities. Finally, we note some interesting connections between the likelihood-based estimators and the classical spike-triggered average estimator, discuss some useful extensions of the basic model structure, and provide two novel applications to physiological data.},
author = {Paninski, Liam},
doi = {10.1088/0954-898X_15_4_002},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Paninski - 2004 - Maximum likelihood estimation of cascade point-process neural encoding models.pdf:pdf},
issn = {0954898X},
journal = {Netw. Comput. Neural Syst.},
number = {4},
pages = {243--262},
publisher = {Institute of Physics Publishing},
title = {{Maximum likelihood estimation of cascade point-process neural encoding models}},
volume = {15},
year = {2004}
}
@article{Candes2009,
abstract = {This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible; but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful. This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank r by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr polylog(n).},
archivePrefix = {arXiv},
arxivId = {0903.1476},
author = {Candes, Emmanuel J. and Tao, Terence},
eprint = {0903.1476},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Candes, Tao - 2009 - The Power of Convex Relaxation Near-Optimal Matrix Completion.pdf:pdf},
month = {mar},
title = {{The Power of Convex Relaxation: Near-Optimal Matrix Completion}},
url = {http://arxiv.org/abs/0903.1476},
year = {2009}
}
@article{Airoldi2013a,
abstract = {Non-parametric approaches for analyzing network data based on exchangeable graph models (ExGM) have recently gained interest. The key object that defines an ExGM is often referred to as a graphon. This non-parametric perspective on network modeling poses challenging questions on how to make inference on the graphon underlying observed network data. In this paper, we propose a computationally efficient procedure to estimate a graphon from a set of observed networks generated from it. This procedure is based on a stochastic blockmodel approximation (SBA) of the graphon. We show that, by approximating the graphon with a stochastic block model, the graphon can be consistently estimated, that is, the estimation error vanishes as the size of the graph approaches infinity.},
archivePrefix = {arXiv},
arxivId = {1311.1731},
author = {Airoldi, Edoardo M and Costa, Thiago B and Chan, Stanley H},
eprint = {1311.1731},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Airoldi, Costa, Chan - 2013 - Stochastic blockmodel approximation of a graphon Theory and consistent estimation.pdf:pdf},
month = {nov},
title = {{Stochastic blockmodel approximation of a graphon: Theory and consistent estimation}},
url = {http://arxiv.org/abs/1311.1731},
year = {2013}
}
@article{Butts2008,
author = {Butts, Carter T.},
doi = {10.1111/j.1467-9531.2008.00203.x},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Butts - 2008 - 4. A Relational Event Framework for Social Action.pdf:pdf},
issn = {0081-1750},
journal = {Sociol. Methodol.},
month = {aug},
number = {1},
pages = {155--200},
title = {{A Relational Event Framework for Social Action}},
url = {http://journals.sagepub.com/doi/10.1111/j.1467-9531.2008.00203.x},
volume = {38},
year = {2008}
}
@article{Statistics2010,
archivePrefix = {arXiv},
arxivId = {arXiv:0812.3502v3},
author = {Statistics, Mathematical and Annals, The},
doi = {10.1214/10-AOS800},
eprint = {arXiv:0812.3502v3},
file = {:Users/bgemily/Documents/Academic/SC/Stage2/Theory/0812.3502.pdf:pdf},
number = {4},
pages = {2422--2464},
title = {{A DECONVOLUTION APPROACH TO ESTIMATION OF}},
volume = {38},
year = {2010}
}
@article{Newman2018,
abstract = {Most empirical studies of networks assume that the network data we are given represent a complete and accurate picture of the nodes and edges in the system of interest, but in real-world situations this is rarely the case. More often the data only specify the network structure imperfectly -- like data in essentially every other area of empirical science, network data are prone to measurement error and noise. At the same time, the data may be richer than simple network measurements, incorporating multiple measurements, weights, lengths or strengths of edges, node or edge labels, or annotations of various kinds. Here we develop a general method for making estimates of network structure and properties using any form of network data, simple or complex, when the data are unreliable, and give example applications to a selection of social and biological networks.},
author = {Newman, M. E.J.},
doi = {10.1103/PhysRevE.98.062321},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Newman - 2018 - Estimating network structure from unreliable measurements.pdf:pdf},
issn = {24700053},
journal = {Phys. Rev. E},
month = {dec},
number = {6},
publisher = {American Physical Society},
title = {{Estimating network structure from unreliable measurements}},
volume = {98},
year = {2018}
}
@techreport{Girvan,
abstract = {A number of recent studies have focused on the statistical properties of networked systems such as social networks and the Worldwide Web. Researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. We propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well known-a collaboration network and a food web-and find that it detects significant and informative community divisions in both cases.},
author = {Girvan, M and Newman, M E J},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Girvan, Newman - Unknown - Community structure in social and biological networks.pdf:pdf},
title = {{Community structure in social and biological networks}},
url = {www.pnas.orgcgidoi10.1073pnas.122653799}
}
@article{Lawton1972,
abstract = {The paper is concerned with parametric models for populations of curves; i.e. models of the form yi(Z) = f($\theta$i; x) + error, i = I, 2, {\ldots}, n. The shape invariant model f($\theta$i; x) = $\theta$0i + $\theta$1ig([x – $\theta$2i/$\theta$3i) is introduced. If the function g(x) is known, then the $\theta$i may be estimated by nonlinear regression. If g(x) is unknown, then the authors propose an iterative technique for simultaneous determination of the best g(x) and $\theta$i. Generalizations of the shape invariant model to curve resolution are also discussed. Several applications of the method are also presented. {\textcopyright} 1972 Taylor and Francis Group, LLC.},
author = {Lawton, W. H. and Sylvestre, E. A. and Maggio, M. S.},
doi = {10.1080/00401706.1972.10488942},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Lawton, Sylvestre, Maggio - 1972 - Self Modeling Nonlinear Regression.pdf:pdf},
issn = {15372723},
journal = {Technometrics},
keywords = {Curve Resolution,Least Square Splines,Mathematical Modeling,Nonlinear Regression},
number = {3},
pages = {513--532},
title = {{Self Modeling Nonlinear Regression}},
volume = {14},
year = {1972}
}
@article{Zhang2016,
abstract = {Recently, network analysis has gained more and more attention in statistics , as well as in computer science, probability and applied mathematics. Community detection for the stochastic block model (SBM) is probably the most studied topic in network analysis. Many methodologies have been proposed. Some beautiful and significant phase transition results are obtained in various settings. In this paper, we provide a general minimax theory for community detection. It gives minimax rates of the mis-match ratio for a wide rage of settings including homogeneous and inhomogeneous SBMs, dense and sparse networks, finite and growing number of communities. The minimax rates are exponential, different from polynomial rates we often see in statistical literature. An immediate consequence of the result is to establish threshold phenomenon for strong consistency (exact recovery) as well as weak consistency (partial recovery). We obtain the upper bound by a range of penalized likelihood-type approaches. The lower bound is achieved by a novel reduction from a global mis-match ratio to a local clustering problem for one node through an exchangeability property.},
author = {Zhang, Anderson Y and Zhou, Harrison H},
doi = {10.1214/15-AOS1428},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhang, Zhou - 2016 - MINIMAX RATES OF COMMUNITY DETECTION IN STOCHASTIC BLOCK MODELS.pdf:pdf},
journal = {Ann. Stat.},
keywords = {60G05,Network,community detection,minimax rate,stochastic block model},
number = {5},
pages = {2252--2280},
title = {{MINIMAX RATES OF COMMUNITY DETECTION IN STOCHASTIC BLOCK MODELS}},
volume = {44},
year = {2016}
}
@article{Gomez-Rodriguez2012,
abstract = {Information diffusion and virus propagation are fundamental processes taking place in networks. While it is often possible to directly observe when nodes become infected with a virus or adopt the information, observing individual transmissions (i.e., who infects whom, or who influences whom) is typically very difficult. Furthermore, in many applications, the underlying network over which the diffusions and propagations spread is actually unobserved. We tackle these challenges by developing a method for tracing paths of diffusion and influence through networks and inferring the networks over which contagions propagate. Given the times when nodes adopt pieces of information or become infected, we identify the optimal network that best explains the observed infection times. Since the optimization problem is NP-hard to solve exactly, we develop an efficient approximation algorithm that scales to large datasets and finds provably near-optimal networks. We demonstrate the effectiveness of our approach by tracing information diffusion in a set of 170 million blogs and news articles over a one year period to infer how information flows through the online media space. We find that the diffusion network of news for the top 1,000 media sites and blogs tends to have a core-periphery structure with a small set of core media sites that diffuse information to the rest of the Web. These sites tend to have stable circles of influence with more general news media sites acting as connectors between them.},
author = {Gomez-Rodriguez, Manuel and Leskovec, Jure and Krause, Andreas},
doi = {10.1145/2086737.2086741},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gomez-Rodriguez, Leskovec, Krause - 2012 - Inferring Networks of Diffusion and Influence.pdf:pdf},
issn = {15564681},
journal = {ACM Trans. Knowl. Discov. Data},
month = {feb},
number = {4},
pages = {1--37},
title = {{Inferring Networks of Diffusion and Influence}},
url = {http://dl.acm.org/citation.cfm?doid=2086737.2086741},
volume = {5},
year = {2012}
}
@article{Gao2015a,
abstract = {Network analysis is becoming one of the most active research areas in statistics. Significant advances have been made recently on developing theories, methodologies and algorithms for analyzing networks. However, there has been little fundamental study on optimal estimation. In this paper, we establish optimal rate of convergence for graphon estimation. For the stochastic block model with k clusters , we show that the optimal rate under the mean squared error is n −1 log k + k 2 /n 2. The minimax upper bound improves the existing results in literature through a technique of solving a quadratic equation. When k ≤ √ n log n, as the number of the cluster k grows, the minimax rate grows slowly with only a logarithmic order n −1 log k. A key step to establish the lower bound is to construct a novel subset of the parameter space and then apply Fano's lemma, from which we see a clear distinction of the nonparametric graphon estimation problem from classical nonparametric regression, due to the lack of identifia-bility of the order of nodes in exchangeable random graph models. As an immediate application, we consider nonparametric graphon estimation in a H{\"{o}}lder class with smoothness $\alpha$. When the smoothness $\alpha$ ≥ 1, the optimal rate of convergence is n −1 log n, independent of $\alpha$, while for $\alpha$ ∈ (0, 1), the rate is n −2$\alpha$/($\alpha$+1) , which is, to our surprise, identical to the classical nonparametric rate.},
annote = {From Duplicate 2 (Rate-optimal graphon estimation - Gao, Chao; Lu, Yu; Zhou, Harrison H.)

Developed upper and minimax lower bounds for the risk of estimation of the matrix of connection probabilities.},
archivePrefix = {arXiv},
arxivId = {1410.5837v3},
author = {Gao, Chao and Lu, Yu and Zhou, Harrison H.},
doi = {10.1214/15-AOS1354},
eprint = {1410.5837v3},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gao, Lu, Zhou - 2015 - RATE-OPTIMAL GRAPHON ESTIMATION(3).pdf:pdf},
issn = {00905364},
journal = {Ann. Stat.},
keywords = {60G05,Graphon,Minimax rate,Network,Nonparametric regression,Stochastic block model,graphon,minimax rate,nonparametric regression,stochastic block model},
month = {dec},
number = {6},
pages = {2624--2652},
publisher = {Institute of Mathematical Statistics},
title = {{Rate-optimal graphon estimation}},
volume = {43},
year = {2015}
}
@article{Dubois2013,
abstract = {Several approaches have recently been proposed for modeling of continuous-time network data via dyadic event rates conditioned on the observed history of events and nodal or dyadic covariates. In many cases, however, interaction propensities-and even the underlying mechanisms of interaction vary systematically across subgroups whose identities are unobserved. For static networks such heterogeneity has been treated via methods such as stochastic block-modeling, which operate by assuming latent groups of individuals with similar tendencies in their group-wise interactions. Here we combine ideas from stochastic blockmod-eling and continuous-time network models by positing a latent partition of the node set such that event dynamics within and between subsets evolve in potentially distinct ways. We illustrate the use of our model family by application to several forms of dyadic interaction data, including email communication and Twitter direct messages. Parameter estimates from the fitted models clearly reveal heterogeneity in the dynamics among groups of individuals. We also find that the fitted models have better predictive accuracy than both baseline models and relational event models that lack latent structure.},
author = {Dubois, Christopher and Butts, Carter T and Smyth, Padhraic},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Dubois, Butts, Smyth - 2013 - Stochastic blockmodeling of relational event dynamics.pdf:pdf},
title = {{Stochastic blockmodeling of relational event dynamics}},
volume = {31},
year = {2013}
}
@article{Friedman2008,
abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm that is remarkably fast: in the worst cases, it solves a 1000 node problem ({\~{}}500,000 parameters) in about a minute, and is 50 to 2000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinhausen and Buhlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
doi = {10.1093/biostatistics/kxm045},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Friedman, Hastie, Tibshirani - 2008 - Sparse inverse covariance estimation with the graphical lasso.pdf:pdf},
issn = {14654644},
journal = {Biostatistics},
keywords = {Gaussian covariance,Graphical model,L1,Lasso},
month = {jul},
number = {3},
pages = {432--441},
title = {{Sparse inverse covariance estimation with the graphical lasso}},
volume = {9},
year = {2008}
}
@techreport{Loupos,
abstract = {The last decade has seen a rapid emergence of non-contractual networked services. The standard approach in predicting future customer behavior in those services involves collecting data on a user's past purchase behavior, and building statistical models to extrapolate a user's actions into the future. However, this method fails in the case of newly acquired customers where you have little or no transactional data. In this work, we study the extent to which knowledge of a customer's social network can solve this cold-start problem and predict the following aspects of customer behavior: (1) activity, (2) transaction levels and (3) membership to the group of most frequent customers. We conduct a dynamic analysis on approximately one million users from the most popular peer-to-peer payment application, Venmo. Our models produce high quality forecasts and demonstrate that social networks lead to a significant boost in predictive performance primarily during the first month of a customer's lifetime. Finally, we characterize significant structural network differences between the top 10{\%} and bottom 90{\%} of most frequent customers immediately after joining the service.},
author = {Loupos, Pantelis and Nathan, Alexandros and Cerf, Moran},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Loupos, Nathan, Cerf - Unknown - Starting Cold The Power of Social Networks in Predicting Non-Contractual Customer Behavior.pdf:pdf},
keywords = {Cold-Start,Customer Behavior,Dynamic Social Networks,Non-Contractual Settings,Predictive Analytics},
title = {{Starting Cold: The Power of Social Networks in Predicting Non-Contractual Customer Behavior}}
}
@article{Rossetti2018,
abstract = {Several research studies have shown that complex networks modeling real-world phenomena are characterized by striking properties: (i) they are organized according to community structure, and (ii) their structure evolves with time. Many researchers have worked on methods that can efficiently unveil substructures in complex networks, giving birth to the field of community discovery. A novel and fascinating problem started capturing researcher interest recently: the identification of evolving communities. Dynamic networks can be used to model the evolution of a system: nodes and edges are mutable, and their presence, or absence, deeply impacts the community structure that composes them. This survey aims to present the distinctive features and challenges of dynamic community discovery and propose a classification of published approaches. As a “user manual,” this work organizes state-of-the-art methodologies into a taxonomy, based on their rationale, and their specific instantiation. Given a definition of network dynamics, desired community characteristics, and analytical needs, this survey will support researchers to identify the set of approaches that best fit their needs. The proposed classification could also help researchers choose in which direction to orient their future research.},
archivePrefix = {arXiv},
arxivId = {1707.03186},
author = {Rossetti, Giulio and Cazabet, R{\'{e}}my},
doi = {10.1145/3172867},
eprint = {1707.03186},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Rossetti, Cazabet - 2018 - Community discovery in dynamic networks A survey.pdf:pdf},
issn = {15577341},
journal = {ACM Comput. Surv.},
keywords = {Community discovery,Dynamic networks,Temporal networks},
month = {feb},
number = {2},
publisher = {Association for Computing Machinery},
title = {{Community discovery in dynamic networks: A survey}},
volume = {51},
year = {2018}
}
@article{Xu2014a,
abstract = {Significant efforts have gone into the development of statistical models for analyzing data in the form of networks, such as social networks. Most existing work has focused on modeling static networks, which represent either a single time snapshot or an aggregate view over time. There has been recent interest in statistical modeling of dynamic networks, which are observed at multiple points in time and offer a richer representation of many complex phenomena. In this paper, we present a state-space model for dynamic networks that extends the well-known stochastic blockmodel for static networks to the dynamic setting. We fit the model in a near-optimal manner using an extended Kalman filter (EKF) augmented with a local search. We demonstrate that the EKF-based algorithm performs competitively with a state-of-the-art algorithm based on Markov chain Monte Carlo sampling but is significantly less computationally demanding.},
author = {Xu, Kevin S. and Hero, Alfred O.},
doi = {10.1109/JSTSP.2014.2310294},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Xu, Hero - 2014 - Dynamic stochastic blockmodels for time-evolving social networks.pdf:pdf},
issn = {19324553},
journal = {IEEE J. Sel. Top. Signal Process.},
keywords = {State-space social network model,dynamic network,extended Kalman filter,on-line estimation},
number = {4},
pages = {552--562},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Dynamic stochastic blockmodels for time-evolving social networks}},
volume = {8},
year = {2014}
}
@article{Amini2018,
abstract = {The stochastic block model (SBM) is a popular tool for community detection in networks, but fitting it by maximum likelihood (MLE) involves a computationally infeasible optimization problem. We propose a new semidef-inite programming (SDP) solution to the problem of fitting the SBM, derived as a relaxation of the MLE. We put ours and previously proposed SDPs in a unified framework, as relaxations of the MLE over various subclasses of the SBM, which also reveals a connection to the well-known problem of sparse PCA. Our main relaxation, which we call SDP-1, is tighter than other recently proposed SDP relaxations, and thus previously established theoretical guarantees carry over. However, we show that SDP-1 exactly recovers true communities over a wider class of SBMs than those covered by current results. In particular, the assumption of strong assortativity of the SBM, implicit in consistency conditions for previously proposed SDPs, can be relaxed to weak assortativity for our approach, thus significantly broadening the class of SBMs covered by the consistency results. We also show that strong as-sortativity is indeed a necessary condition for exact recovery for previously proposed SDP approaches and not an artifact of the proofs. Our analysis of SDPs is based on primal-dual witness constructions, which provides some insight into the nature of the solutions of various SDPs. In particular, we show how to combine features from SDP-1 and already available SDPs to achieve the most flexibility in terms of both assortativity and block-size constraints, as our relaxation has the tendency to produce communities of similar sizes. This tendency makes it the ideal tool for fitting network histograms, a method gaining popularity in the graphon estimation literature, as we illustrate on an example of a social networks of dolphins. We also provide empirical evidence that SDPs outperform spectral methods for fitting SBMs with a large number of blocks.},
author = {Amini, Arash A and Levina, Elizaveta},
doi = {10.1214/17-AOS1545},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Amini, Levina - 2018 - ON SEMIDEFINITE RELAXATIONS FOR THE BLOCK MODEL.pdf:pdf},
journal = {Ann. Stat.},
keywords = {62G20,62H99,90C22,Community detection,network,semidefinite programming,stochastic block model},
number = {1},
pages = {149--179},
title = {{On semidefinite relaxations for the block model}},
url = {https://doi.org/10.1214/17-AOS1545},
volume = {46},
year = {2018}
}
@article{Simma2012,
abstract = {We present a probabilistic model of events in continuous time in which each event triggers a Poisson process of successor events. The ensemble of observed events is thereby modeled as a superposition of Poisson processes. Efficient inference is feasible under this model with an EM algorithm. Moreover, the EM algorithm can be implemented as a distributed algorithm, permitting the model to be applied to very large datasets. We apply these techniques to the modeling of Twitter messages and the revision history of Wikipedia.},
archivePrefix = {arXiv},
arxivId = {1203.3516},
author = {Simma, Aleksandr and Jordan, Michael I.},
eprint = {1203.3516},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Simma, Jordan - 2012 - Modeling Events with Cascades of Poisson Processes.pdf:pdf},
month = {mar},
title = {{Modeling Events with Cascades of Poisson Processes}},
url = {http://arxiv.org/abs/1203.3516},
year = {2012}
}
@article{Klopp2013,
author = {Klopp, Olga},
doi = {10.1214/13-EJS778},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/euclid.ejs.1360764852.pdf:pdf},
keywords = {62J99, 62H12, 60G57Varying coefficient model, low,and phrases,low rank matrix es-,received november 2012,statistical learning,timation,varying coefficient model},
pages = {454--479},
title = {{Non-asymptotic approach to varying coefficient model}},
volume = {7},
year = {2013}
}
@article{Hoff2002latent,
abstract = {Network models are widely used to represent relational information among interacting units. In studies of social networks, recent emphasis has been placed on random graph models where the nodes usually represent individual social actors and the edges represent the presence of a specified relation between actors. We develop a class of models where the probability of a relation between actors depends on the positions of individuals in an unobserved "social space." We make inference for the social space within maximum likelihood and Bayesian frameworks, and propose Markov chain Monte Carlo procedures for making inference on latent positions and the effects of observed covariates. We present analyses of three standard datasets from the social networks literature, and compare the method to an alternative stochastic blockmodeling approach. In addition to improving on model fit for these datasets, our method provides a visual and interpretable model-based spatial representation of social relationships and improves on existing methods by allowing the statistical uncertainty in the social space to be quantified and graphically represented.},
author = {Hoff, Peter D. and Raftery, Adrian E. and Handcock, Mark S.},
doi = {10.1198/016214502388618906},
issn = {01621459},
journal = {J. Am. Stat. Assoc.},
keywords = {Conditional independence model,Latent position model,Latent space,Network data,Random graph,Visualization},
mendeley-tags = {Latent space},
month = {dec},
number = {460},
pages = {1090--1098},
publisher = {Taylor {\&} Francis},
title = {{Latent space approaches to social network analysis}},
volume = {97},
year = {2002}
}
@article{Gervini2005,
abstract = {A random sample of curves can be usually thought of as noisy realisations of a compound stochastic process X(t) = Z{\{}W(t){\}}, where Z(t) produces random amplitude variation and W(t) produces random dynamic or phase variation. In most applications it is more important to estimate the so-called structural mean $\mu$(t) = E{\{}Z(t){\}} than the crosssectional mean E{\{}X(t){\}}, but this estimation problem is difficult because the process Z(t) is not directly observable. In this paper we propose a nonparametric maximum likelihood estimator of $\mu$(t). This estimator is shown to be √n-consistent and asymptotically normal under the assumed model and robust to model misspecification. Simulations and a realdata example show that the proposed estimator is competitive with landmark registration, often considered the benchmark, and has the advantage of avoiding time-consuming and often infeasible individual landmark identification. {\textcopyright} 2005 Biometrika Trust.},
annote = {The idea of estimate the common shape by maximum likelihood is appealing because it avoids individual identification of landmarks.

Estimate the common shape curve by maximum likelihood.},
author = {Gervini, Daniel and Gasser, Theo},
doi = {10.1093/biomet/92.4.801},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gervini, Gasser - 2005 - Nonparametric maximum likelihood estimation of the structural mean of a sample of curves.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {Curve registration,Functional data,Longitudinal data,Phase variation,Time warping},
month = {dec},
number = {4},
pages = {801--820},
title = {{Nonparametric maximum likelihood estimation of the structural mean of a sample of curves}},
volume = {92},
year = {2005}
}
@article{Xu2012,
abstract = {This paper introduces an algorithm for the nonnegative matrix factorization-and-completion problem, which aims to find nonnegative low-rank matrices X and Y so that the product XY approximates a nonnegative data matrix M whose elements are partially known (to a certain accuracy). This problem aggregates two existing problems: (i) nonnegative matrix factorization where all entries of M are given, and (ii) low-rank matrix completion where nonnegativity is not required. By taking the advantages of both nonnegativity and low-rankness, one can generally obtain superior results than those of just using one of the two properties. We propose to solve the non-convex constrained least-squares problem using an algorithm based on the classic alternating direction augmented Lagrangian method. Preliminary convergence properties of the algorithm and numerical simulation results are presented. Compared to a recent algorithm for nonnegative matrix factorization, the proposed algorithm produces factorizations of similar quality using only about half of the matrix entries. On tasks of recovering incomplete grayscale and hyperspectral images, the proposed algorithm yields overall better qualities than those produced by two recent matrix-completion algorithms that do not exploit nonnegativity.},
author = {Xu, Yangyang and Yin, Wotao and Wen, Zaiwen and Zhang, Yin},
doi = {10.1007/s11464-012-0194-5},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Xu et al. - 2012 - An alternating direction algorithm for matrix completion with nonnegative factors.pdf:pdf},
issn = {16733452},
journal = {Front. Math. China},
keywords = {alternating direction method,hyperspectral unmixing,matrix completion,nonnegative matrix factorization},
month = {apr},
number = {2},
pages = {365--384},
title = {{An alternating direction algorithm for matrix completion with nonnegative factors}},
volume = {7},
year = {2012}
}
@article{Yuan2007,
abstract = {We propose penalized likelihood methods for estimating the concentration matrix in the Gaussian graphical model. The methods lead to a sparse and shrinkage estimator of the concentration matrix that is positive definite, and thus conduct model selection and estimation simultaneously. The implementation of the methods is nontrivial because of the positive definite constraint on the concentration matrix, but we show that the computation can be done effectively by taking advantage of the efficient maxdet algorithm developed in convex optimization. We propose a BIC-type criterion for the selection of the tuning parameter in the penalized likelihood methods. The connection between our methods and existing methods is illustrated. Simulations and real examples demonstrate the competitive performance of the new methods.},
author = {Yuan, Ming and Lin, Yi},
doi = {10.1093/biomet/asm018},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Yuan, Lin - 2007 - Model selection and estimation in the Gaussian graphical model.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {Covariance selection,Lasso,Maxdet algorithm,Nonnegative garrote,Penalized likelihood},
month = {mar},
number = {1},
pages = {19--35},
title = {{Model selection and estimation in the Gaussian graphical model}},
volume = {94},
year = {2007}
}
@article{Lloyd1982,
abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quantization schemes for 2b quanta, b = 1,2, {\textperiodcentered}{\textperiodcentered}{\textperiodcentered}, 7, are given numerically for Gaussian and for Laplacian distribution of signal amplitudes. {\textcopyright}1982 IEEE},
author = {Lloyd, Stuart P.},
doi = {10.1109/TIT.1982.1056489},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Lloyd - 1982 - Least Squares Quantization in PCM.pdf:pdf},
issn = {15579654},
journal = {IEEE Trans. Inf. Theory},
number = {2},
pages = {129--137},
title = {{Least Squares Quantization in PCM}},
volume = {28},
year = {1982}
}
@article{Edelman1998,
abstract = {In this paper we develop new Newton and conjugate gradient algorithms on the Grassmann and Stiefel manifolds. These manifolds represent the constraints that arise in such areas as the symmetric eigenvalue problem, nonlinear eigenvalue problems, electronic structures computations, and signal processing. In addition to the new algorithms, we show how the geometrical framework gives penetrating new insights allowing us to create, understand, and compare algorithms. The theory proposed here provides a taxonomy for numerical linear algebra algorithms that provide a top level mathematical view of previously unrelated algorithms. It is our hope that developers of new algorithms and perturbation theories will benefit from the theory, methods, and examples in this paper.},
author = {Edelman, Alan and Arias, TOM{\'{A}}S A. and Smith, Steven T.},
doi = {10.1137/S0895479895290954},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/edelman98.pdf:pdf},
issn = {08954798},
journal = {SIAM J. Matrix Anal. Appl.},
keywords = {Conjugate gradient,Eigenvalue optimization,Eigenvalues and eigenvectors,Grassmann manifold,Invariant subspace,Newton's method,Orthogonality constraints,Rayleigh quotient iteration,Sequential quadratic programming,Stiefel manifold},
number = {2},
pages = {303--353},
publisher = {Society for Industrial and Applied Mathematics Publications},
title = {{The geometry of algorithms with orthogonality constraints}},
volume = {20},
year = {1998}
}
@article{Xu2012a,
abstract = {In many cases it makes sense to model a relationship symmetrically, not implying any particular directionality. Consider the classical example of a recommendation system where the rating of an item by a user should symmetrically be dependent on the attributes of both the user and the item. The attributes of the (known) relationships are also relevant for predicting attributes of entities and for predicting attributes of new relations. In recommendation systems, the exploitation of relational attributes is often referred to as collaborative filtering. Again, in many applications one might prefer to model the collaborative effect in a symmetrical way. In this paper we present a relational model, which is completely symmetrical. The key innovation is that we introduce for each entity (or object) an infinite-dimensional latent variable as part of a Dirichlet process (DP) model. We discuss inference in the model, which is based on a DP Gibbs sampler, i.e., the Chinese restaurant process. We extend the Chinese restaurant process to be applicable to relational modeling. Our approach is evaluated in three applications. One is a recommendation system based on the MovieLens data set. The second application concerns the prediction of the function of yeast genes/proteins on the data set of KDD Cup 2001 using a multi-relational model. The third application involves a relational medical domain. The experimental results show that our model gives significantly improved estimates of attributes describing relationships or entities in complex relational models.},
archivePrefix = {arXiv},
arxivId = {1206.6864},
author = {Xu, Zhao and Tresp, Volker and Yu, Kai and Kriegel, Hans-Peter},
eprint = {1206.6864},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Xu et al. - 2012 - Infinite Hidden Relational Models.pdf:pdf},
month = {jun},
title = {{Infinite Hidden Relational Models}},
url = {http://arxiv.org/abs/1206.6864},
year = {2012}
}
@article{Olhede2014,
abstract = {In this article we introduce the network histogram: a statistical summary of network interactions, to be used as a tool for exploratory data analysis. A network histogram is obtained by fitting a stochastic blockmodel to a single observation of a network dataset. Blocks of edges play the role of histogram bins, and community sizes that of histogram bandwidths or bin sizes. Just as standard histograms allow for varying bandwidths, different blockmodel estimates can all be considered valid representations of an underlying probability model, subject to bandwidth constraints. Here we provide methods for automatic bandwidth selection, by which the network histogram approximates the generating mechanism that gives rise to exchangeable random graphs. This makes the blockmodel a universal network representation for unlabeled graphs. With this insight, we discuss the interpretation of network communities in light of the fact that many different community assignments can all give an equally valid representation of such a network. To demonstrate the fidelity-versus-interpretability tradeoff inherent in considering different numbers and sizes of communities, we analyze two publicly available networks - political weblogs and student friendships - and discuss how to interpret the network histogram when additional information related to node and edge labeling is present.},
author = {Olhede, S. C. and Wolfe, P. J.},
doi = {10.1073/pnas.1400374111},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Olhede, Wolfe - 2014 - Network histograms and universality of blockmodel approximation.pdf:pdf},
issn = {0027-8424},
journal = {Proc. Natl. Acad. Sci.},
month = {oct},
number = {41},
pages = {14722--14727},
publisher = {Proceedings of the National Academy of Sciences},
title = {{Network histograms and universality of blockmodel approximation}},
volume = {111},
year = {2014}
}
@article{Airoldi2013b,
abstract = {Non-parametric approaches for analyzing network data based on exchangeable graph models (ExGM) have recently gained interest. The key object that defines an ExGM is often referred to as a graphon. This non-parametric perspective on network modeling poses challenging questions on how to make inference on the graphon underlying observed network data. In this paper, we propose a computationally efficient procedure to estimate a graphon from a set of observed networks generated from it. This procedure is based on a stochastic blockmodel approximation (SBA) of the graphon. We show that, by approximating the graphon with a stochastic block model, the graphon can be consistently estimated, that is, the estimation error vanishes as the size of the graph approaches infinity.},
archivePrefix = {arXiv},
arxivId = {1311.1731},
author = {Airoldi, Edoardo M and Costa, Thiago B and Chan, Stanley H},
eprint = {1311.1731},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Airoldi, Costa, Chan - 2013 - Stochastic blockmodel approximation of a graphon Theory and consistent estimation.pdf:pdf},
month = {nov},
title = {{Stochastic blockmodel approximation of a graphon: Theory and consistent estimation}},
url = {http://arxiv.org/abs/1311.1731},
year = {2013}
}
@article{Sarkar2005,
abstract = {This paper explores two aspects of social network modeling. First, we generalize a successful static model of relationships into a dynamic model that accounts for friendships drifting over time. Second, we show how to make it tractable to learn such models from data, even as the number of entities n gets large. The generalized model associates each entity with a point in p-dimensional Euclidean latent space. The points can move as time progresses but large moves in latent space are improbable. Observed links between entities are more likely if the entities are close in latent space. We show how to make such a model tractable (sub-quadratic in the number of entities) by the use of appropriate kernel functions for similarity in latent space; the use of low dimensional KD-trees; a new efficient dynamic adaptation of multidimensional scaling for a first pass of approximate projection of entities into latent space; and an efficient conjugate gradient update rule for non-linear local optimization in which amortized time per entity during an update is O(log n). We use both synthetic and real-world data on up to 11,000 entities which indicate near-linear scaling in computation time and improved performance over four alternative approaches. We also illustrate the system operating on twelve years of NIPS co-authorship data.},
annote = {A dynamic version of the latent space model.

The latent points follow a (continuous state space) Markov chain, with transition kernel given by a Gaussian perturbation on the current position with zero mean and small variance.},
author = {Sarkar, Purnamrita and Moore, Andrew W.},
doi = {10.1145/1117454.1117459},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Sarkar, Moore - 2005 - Dynamic social network analysis using latent space models.pdf:pdf},
issn = {19310145},
journal = {ACM SIGKDD Explor. Newsl.},
month = {dec},
number = {2},
pages = {31--40},
title = {{Dynamic social network analysis using latent space models}},
url = {http://portal.acm.org/citation.cfm?doid=1117454.1117459},
volume = {7},
year = {2005}
}
@article{Xu2015,
abstract = {There has been great interest in recent years on statistical models for dynamic networks. In this paper, I propose a stochastic block transition model (SBTM) for dynamic networks that is inspired by the well-known stochastic block model (SBM) for static networks and previous dynamic extensions of the SBM. Unlike most existing dynamic network models, it does not make a hidden Markov assumption on the edge-level dynamics, allowing the presence or absence of edges to directly influence future edge probabilities while retaining the interpretability of the SBM. I derive an approximate inference procedure for the SBTM and demonstrate that it is significantly better at reproducing durations of edges in real social network data.},
annote = {From Duplicate 2 (Stochastic Block Transition Models for Dynamic Networks - Xu, Kevin S)

All edges in a block at time t-1 are equally likely to re-appear at time t, and non-edges in a block at time t-1 are equally likely to appear at time t.},
archivePrefix = {arXiv},
arxivId = {1411.5404},
author = {Xu, Kevin S.},
eprint = {1411.5404},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Xu - 2015 - Stochastic Block Transition Models for Dynamic Networks.pdf:pdf},
issn = {15337928},
journal = {J. Mach. Learn. Res.},
pages = {1079--1087},
publisher = {Microtome Publishing},
title = {{Stochastic block transition models for dynamic networks}},
volume = {38},
year = {2015}
}
@article{Wan2019,
abstract = {Graphical Abstract Highlights d Neurons are tracked from birth to entire circuit at cell-type and functional levels d Neurogenesis and emergence of coordinated activity is analyzed at a single-cell level d Motoneurons, active first, form ensembles that synchronize globally, based on size d Neuron maturation is stereotyped, based on birth time and anatomical origin In Brief Wan et al. reconstruct neurogenesis and the emergence of coordinated neuronal activity at the single-cell level in the zebrafish spinal cord by tracking neuron lineages, movements, molecular identities, and activity in the entire developing circuit. They find that functional maturation of neurons is stereotyped, based on birth time and anatomical origin, and that early motoneuron activity leads ensembles that synchronize globally, based on network size.},
author = {Wan, Yinan and Wei, Ziqiang and Looger, Loren L. and Koyama, Minoru and Druckmann, Shaul and {Keller Correspondence}, Philipp J and Keller, Philipp J.},
doi = {10.1016/j.cell.2019.08.039},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/WanKeller2019.pdf:pdf},
issn = {00928674},
journal = {Cell},
keywords = {calcium imaging,circuit development,computational data analysis,embryonic development,light-sheet microscopy,population activity,spinal cord,zebrafish},
month = {sep},
title = {{Single-Cell Reconstruction of Emerging Population Activity in an Entire Developing Circuit}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867419309584 https://doi.org/10.1016/j.cell.2019.08.039},
volume = {179},
year = {2019}
}
@article{Pollard1981,
abstract = {A random sample is divided into the k clusters that minimise the within cluster sum of squares. Conditions are found that ensure the almost sure convergence, as the sample size increases, of the set of means of the k clusters. The result is proved for a more general clustering criterion.},
author = {Pollard, David},
doi = {10.1214/aos/1176345339},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Pollard - 1981 - Strong Consistency of {\$}K{\$}-Means Clustering.pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
month = {jan},
number = {1},
pages = {135--140},
publisher = {Institute of Mathematical Statistics},
title = {{Strong Consistency of {\$}K{\$}-Means Clustering}},
volume = {9},
year = {1981}
}
@article{Kumar2009,
author = {Kumar, Amit and Sabharwal, Yogish and Sen, Sandeep},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/jacm2.pdf:pdf},
pages = {1--30},
title = {{Linear-Time Approximation Schemes for Clustering Problems in}},
volume = {2},
year = {2009}
}
@article{Matias2016b,
author = {Matias, C and Rebafka, T and Villers, F},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Matias, Rebafka, Villers - 2016 - Supplementary material for A semiparametric extension of the stochastic block model for longitudinal n.pdf:pdf},
journal = {Adv. Access Publ.},
number = {1},
pages = {1--25},
title = {{Supplementary material for: A semiparametric extension of the stochastic block model for longitudinal networks}},
volume = {1},
year = {2016}
}
@article{JeremieBigot2010,
abstract = {This paper considers the problem of adaptive estimation of a mean pattern in a randomly shifted curve model. We show that this problem can be transformed into a linear inverse problem, where the density of the random shifts plays the role of a convolution operator. An adaptive estimator of the mean pattern, based on wavelet thresholding is proposed. We study its consistency for the quadratic risk as the number of observed curves tends to infinity , and this estimator is shown to achieve a near-minimax rate of convergence over a large class of Besov balls. This rate depends both on the smoothness of the common shape of the curves and on the decay of the Fourier coefficients of the density of the random shifts. Hence, this paper makes a connection between mean pattern estimation and the statistical analysis of linear inverse problems, which is a new point of view on curve registration and image warping problems. We also provide a new method to estimate the unknown random shifts between curves. Some numerical experiments are given to illustrate the performances of our approach and to compare them with another algorithm existing in the literature.},
annote = {An adaptive estimator of the mean pattern based on wavelet thresholding is proposed.},
author = {{J{\'{e}}r{\'{e}}mie Bigot}, BY and Gadat, S{\'{e}}bastien},
doi = {10.1214/10-AOS800},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/J{\'{e}}r{\'{e}}mie Bigot, Gadat - 2010 - A DECONVOLUTION APPROACH TO ESTIMATION OF A COMMON SHAPE IN A SHIFTED CURVES MODEL.pdf:pdf},
journal = {Ann. Stat.},
keywords = {42C40,62G08,Besov space,Mean pattern estimation,Meyer wavelets,adaptive estimation,curve registration,deconvolution,inverse problem,minimax rate},
number = {4},
pages = {2422--2464},
title = {{A deconvolution approach to estimation of a common shape in a shifted curves model}},
volume = {38},
year = {2010}
}
@article{Toyoda2003,
abstract = {Recent advances in storage technology make it possible to store a series of large Web archives. It is now an exciting challenge for us to observe evolution of the Web. In this paper, we propose a method for observing evolution of web communities. A web community is a set of web pages created by individuals or associations with a common interest on a topic. So far, various link analysis techniques have been developed to extract web communities. We analyze evolution of web communities by comparing four Japanese web archives crawled from 1999 to 2002. Statistics of these archives and community evolution are examined, and the global behavior of evolution is described. Several metrics are introduced to measure the degree of web community evolution , such as growth rate, novelty, and stability. We developed a system for extracting detailed evolution of communities using these metrics. It allows us to understand when and how communities emerged and evolved. Some evolution examples are shown using our system.},
annote = {Proposed different types of community changes, such as emerge, dissolve, grow, and shrink, as well as a set of metrics to quantify such changes for community evolution analysis.},
author = {Toyoda, Masashi and Kitsuregawa, Masaru},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Toyoda, Kitsuregawa - 2003 - Extracting Evolution of Web Communities from a Series of Web Archives.pdf:pdf},
keywords = {Algorithms Keywords Web,H54 [Information Interfaces and Presentation]: Hy-,Link analysis,Measurement,evolution,web community},
title = {{Extracting Evolution of Web Communities from a Series of Web Archives}},
year = {2003}
}
@article{Absil2009,
abstract = {Many problems in the sciences and engineering can be rephrased as optimization problems on matrix search spaces endowed with a so-called manifold structure. This book shows how to exploit the special structure of such problems to develop efficient numerical algorithms. It places careful emphasis on both the numerical formulation of the algorithm and its differential geometric abstraction--illustrating how good algorithms draw equally from the insights of differential geometry, optimization, and numerical analysis. Two more theoretical chapters provide readers with the background in differential geometry necessary to algorithmic development. In the other chapters, several well-known optimization methods such as steepest descent and conjugate gradients are generalized to abstract manifolds. The book provides a generic development of each of these methods, building upon the material of the geometric chapters. It then guides readers through the calculations that turn these geometrically formulated methods into concrete numerical algorithms. The state-of-the-art algorithms given as examples are competitive with the best existing algorithms for a selection of eigenspace problems in numerical linear algebra. Optimization Algorithms on Matrix Manifoldsoffers techniques with broad applications in linear algebra, signal processing, data mining, computer vision, and statistical analysis. It can serve as a graduate-level textbook and will be of interest to applied mathematicians, engineers, and computer scientists. {\textcopyright} 2008 by Princeton University Press. All Rights Reserved.},
author = {Absil, P. A. and Mahony, R. and Sepulchre, R.},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/Optimization{\_}Algorithms{\_}on{\_}Matrix{\_}Manifolds.pdf:pdf},
isbn = {9780691132983},
journal = {Optim. Algorithms Matrix Manifolds},
title = {{Optimization algorithms on matrix manifolds}},
year = {2009}
}
@techreport{Kempb,
abstract = {Relationships between concepts account for a large proportion of semantic knowledge. We present a nonpara-metric Bayesian model that discovers systems of related concepts. Given data involving several sets of entities, our model discovers the kinds of entities in each set and the relations between kinds that are possible or likely. We apply our approach to four problems: clustering objects and features, learning ontologies, discovering kin-ship systems, and discovering structure in political data. Philosophers, psychologists and computer scientists have proposed that semantic knowledge is best understood as a system of relations. Two questions immediately arise: how can these systems be represented, and how are these representations acquired? Researchers who start with the first question often devise complex representational schemes (e.g. Minsky's (1975) classic work on frames), but explaining how these representations are learned is a challenging problem. We take the opposite approach. We consider only simple relational systems, but show how these systems can be acquired by unsupervised learning. The systems we wish to discover are simple versions of the "domain theories" discussed by cognitive scientists and AI researchers (Davis 1990). Suppose that a domain includes several types, or sets of entities. One role of a domain theory is to specify the kinds of entities that exist in each set, and the possible or likely relationships between those kinds. Consider the domain of medicine, and a single type defined as the set of terms that might appear on a medical chart. A theory of this domain might specify that cancer and diabetes are both disorders, asbestos and arsenic are both chemicals, and that chemicals can cause disorders. Our model assumes that each entity belongs to exactly one kind, or cluster, and simultaneously discovers the clusters and the relationships between clusters that are best supported by the data. A key feature of our approach is that it does not require the number of clusters to be fixed in advance. The number of clusters used by a theory should be able to grow as more and more data are encountered, but a theory-learner should introduce no more clusters than are necessary to explain the data. Our approach automatically chooses an appropriate number of clusters using a prior that favors small numbers of clusters , but has access to a countably infinite collection of clusters. We therefore call our approach the infinite relational model (IRM). Previous infinite models (Rasmussen 2000; Antoniak 1974) have focused on feature data, and the IRM extends these approaches to work with arbitrary systems of relational data. Our framework can discover structure in relational data sets that appear quite different on the surface. We demonstrate its range by applying it to four problems. First we suggest that object-feature data can be profitably viewed as a relation between two sets of entities-the objects and the features-and show how the IRM simultaneously clusters both. We then use the IRM to learn a biomedical on-tology. Ontologies are classic examples of the theories we have described, since they group entities into higher-level concepts and specify how these high-level concepts relate to each other. Next we show that the IRM discovers aspects of the kinship structure of an Australian tribe. Our final example considers a political data set, and we discover a system with clusters of countries, clusters of interactions between countries, and clusters of country features. The Infinite Relational Model Suppose we are given one or more relations involving one or more types. The goal of the IRM is to partition each type into clusters, where a good set of partitions allows relationships between entities to be predicted by their cluster assignments. For example, we may have a single type people and a single relation likes(i, j) which indicates whether person i likes person j. Our goal is to organize the entities into clusters that relate to each other in predictable ways (Fig-ure 1a). We also allow predicate types: if there are multiple relations defined over the same domain, we will group them into a type and refer to them as predicates. For instance, we may have several social predicates defined over the domain people × people: likes({\textperiodcentered}, {\textperiodcentered}), admires({\textperiodcentered}, {\textperiodcentered}), respects({\textperiodcentered}, {\textperiodcentered}), and hates({\textperiodcentered}, {\textperiodcentered}). We can introduce a type for these social predicates , and define a ternary relation applies(i, j, p) which is true if predicate p applies to the pair (i, j). Our goal is now to simultaneously cluster the people and the predicates (Figure 1c). The IRM can handle arbitrarily complex systems of attributes, entities and relations: if we include demographic attributes for the people, for example, we can},
author = {Kemp, Charles and Tenenbaum, Joshua B and Griffiths, Thomas L and Yamada, Takeshi and Ueda, Naonori},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Kemp et al. - Unknown - Learning Systems of Concepts with an Infinite Relational Model.pdf:pdf},
title = {{Learning Systems of Concepts with an Infinite Relational Model}},
url = {www.aaai.org}
}
@article{Diaconis2007a,
abstract = {We develop a clear connection between deFinetti's theorem for exchangeable arrays (work of Aldous--Hoover--Kallenberg) and the emerging area of graph limits (work of Lovasz and many coauthors). Along the way, we translate the graph theory into more classical probability.},
archivePrefix = {arXiv},
arxivId = {0712.2749},
author = {Diaconis, Persi and Janson, Svante},
eprint = {0712.2749},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Diaconis, Janson - 2007 - Graph limits and exchangeable random graphs.pdf:pdf},
month = {dec},
title = {{Graph limits and exchangeable random graphs}},
url = {http://arxiv.org/abs/0712.2749},
year = {2007}
}
@article{Borgs,
abstract = {We design algorithms for fitting a high-dimensional statistical model to a large, sparse network without revealing sensitive information of individual members. Given a sparse input graph G, our algorithms output a node-differentially private nonparametric block model approximation. By node-differentially private, we mean that our output hides the insertion or removal of a vertex and all its adjacent edges. If G is an instance of the network obtained from a generative nonparametric model defined in terms of a graphon W , our model guarantees consistency: as the number of vertices tends to infinity, the output of our algorithm converges to W in an appropriate version of the L 2 norm. In particular, this means we can estimate the sizes of all multi-way cuts in G. Our results hold as long as W is bounded, the average degree of G grows at least like the log of the number of vertices, and the number of blocks goes to infinity at an appropriate rate. We give explicit error bounds in terms of the parameters of the model; in several settings, our bounds improve on or match known nonprivate results.},
author = {Borgs, Christian and Chayes, Jennifer T and Smith, Adam},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Borgs, Chayes, Smith - Unknown - Private Graphon Estimation for Sparse Graphs.pdf:pdf},
title = {{Private Graphon Estimation for Sparse Graphs *}},
url = {http://arxiv.org/abs/1506.06162}
}
@article{Le2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.00669v2},
author = {Le, C A N M and Levina, Elizaveta and Vershynin, Roman},
eprint = {arXiv:1506.00669v2},
file = {:Users/bgemily/Documents/Academic/SC/Stage2/Theory/1506.00669.pdf:pdf},
pages = {1--21},
title = {{CONCENTRATION AND REGULARIZATION OF RANDOM GRAPHS}},
year = {2016}
}
@article{Baraud2009,
abstract = {The purpose of this paper is to estimate the intensity of some random measure N on a set X by a piecewise constant function on a finite partition of X. Given a (possibly large) family M of candidate partitions, we build a piecewise constant estimator (histogram) on each of them and then use the data to select one estimator in the family. Choosing the square of a Hellinger-type distance as our loss function, we show that each estimator built on a given partition satisfies an analogue of the classical squared bias plus variance risk bound. Moreover, the selection procedure leads to a final estimator satisfying some oracle-type inequality, with, as usual, a possible loss corresponding to the complexity of the family M. When this complexity is not too high, the selected estimator has a risk bounded, up to a universal constant, by the smallest risk bound obtained for the estimators in the family. For suitable choices of the family of partitions, we deduce uniform risk bounds over various classes of intensities. Our approach applies to the estimation of the intensity of an inhomogenous Poisson process, among other counting processes, or the estimation of the mean of a random vector with nonnegative components.},
author = {Baraud, Yannick and Birg{\'{e}}, Lucien and Baraud, Yannick and Birg{\'{e}}, Lucien},
doi = {10.1007/s00440-007-0126-6},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Baraud et al. - 2009 - Estimating the intensity of a random measure by histogram type estimators.pdf:pdf},
issn = {01788051},
journal = {Probab. Theory Relat. Fields},
keywords = {Adaptive estimation,Classification (2000) 62G05,Discrete data,Discrete data {\textperiodcentered},Histogram,Histogram {\textperiodcentered},Intensity estimation,Intensity estimation {\textperiodcentered},Mathematics,Model selection,Model selection {\textperiodcentered},Poisson process,Poisson process {\textperiodcentered},Subject},
month = {jan},
number = {1-2},
pages = {239--284},
title = {{Estimating the intensity of a random measure by histogram type estimators}},
volume = {143},
year = {2009}
}
@article{Krampe2019,
abstract = {This paper focuses on modeling the dynamic attributes of a dynamic network with a fixed number of vertices. These attributes are considered as time series which dependency structure is influenced by the underlying network. They are modeled by a multivariate doubly stochastic time series framework, that is we assume linear processes for which the coefficient matrices are stochastic processes themselves. We explicitly allow for dependence in the dynamics of the coefficient matrices as well as between these two stochastic processes. This framework allows for a separate modeling of the attributes and the underlying network. In this setting, we define network autoregressive models and discuss their stationarity conditions. Furthermore, an estimation approach is discussed in a low- and high-dimensional setting and how this can be applied to forecasting. The finite sample behavior of the forecast approach is investigated. This approach is applied to real data whereby the goal is to forecast the GDP of 33 economies.},
archivePrefix = {arXiv},
arxivId = {1807.01133},
author = {Krampe, Jonas},
doi = {10.1214/19-EJS1642},
eprint = {1807.01133},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Krampe - 2018 - Time Series Modeling on Dynamic Networks.pdf:pdf},
issn = {1935-7524},
journal = {Electron. J. Stat.},
month = {jul},
number = {2},
pages = {4945--4976},
title = {{Time series modeling on dynamic networks}},
url = {http://arxiv.org/abs/1807.01133 https://projecteuclid.org/euclid.ejs/1575946867},
volume = {13},
year = {2019}
}
@article{Peng2005,
abstract = {One of the fundamental clustering problems is to assign n points into k clusters based on the minimal sum-of-squares(MSSC), which is known to be NP-hard. In this paper, by using matrix arguments, we first model MSSC as a so-called 0-1 semidefinite programming (SDP). We show that our 0-1 SDP model provides an unified framework for several clustering approaches such as normalized k-cut and spectral clustering. Moreover, the 0-1 SDP model allows us to solve the underlying problem approximately via the relaxed linear and semidefinite programming. Secondly, we consider the issue of how to extract a feasible solution of the original 0-1 SDP model from the approximate solution of the relaxed SDP problem. By using principal component analysis, we develop a rounding procedure to construct a feasible partitioning from a solution of the relaxed problem. In our rounding procedure, we need to solve a K-means clustering problem in k−1 , which can be solved in O(n k 2 −2k+2) time. In case of bi-clustering, the running time of our rounding procedure can be reduced to O(n log n). We show that our algorithm can provide a 2-approximate solution to the original problem. Promising numerical results for bi-clustering based on our new method are reported.},
annote = {Observe that the k-means objective function can be written as the inner product between a projection matrix and a distance matrix constructed from the data, and the combinatorial constraints of the projection matrix can be convexified.},
author = {Peng, Jiming and Wei, Yu},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Peng, Wei - 2005 - Approximating K-means-type clustering via semidefinite programming.pdf:pdf},
keywords = {0-1 SDP,Approximation,K-means clustering,Principal component analysis,Semi-definite programming},
title = {{Approximating K-means-type clustering via semidefinite programming}},
year = {2005}
}
@inproceedings{Iwata2013,
abstract = {Моделирование событий в непрерывном времени. Событие (t,u) - в момент t пользователь u принял элемент i},
author = {Iwata, Tomoharu and Shah, Amar and Ghahramani, Zoubin},
doi = {10.1145/2487575.2487624},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Iwata, Shah, Ghahramani - 2013 - Discovering latent influence in online social activities via shared cascade poisson processes.pdf:pdf},
month = {aug},
pages = {266},
publisher = {Association for Computing Machinery (ACM)},
title = {{Discovering latent influence in online social activities via shared cascade poisson processes}},
year = {2013}
}
@techreport{Holland1983,
abstract = {A stochastic model is proposed for social networks in which the actors in a network are partItIoned mto subgroups called blocks. The model provides a stochastrc generalization of the blockmodel. Estimation techniques are developed for the special case of a single relation social network, with blocks specified D prrorr. An extension of the model allows for tendencies toward reciprocation of ties beyond those explained by the partition. The extended model prowdes a one degree-of-freedom test of the model. A numerical example from the social network hterature 1s used to illustrate the methods.},
author = {Holland, Paul W and Blackmond, Kathryn and Leinhardt, Samuel},
booktitle = {Soc. Networks},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Holland, Blackmond, Leinhardt - 1983 - STOCHASTIC BLOCKMODELS FIRST STEPS Educational Testing Seroice.pdf:pdf},
pages = {9--137},
title = {{Stochastic blockmodels: first steps}},
volume = {5},
year = {1983}
}
@article{Matias2016a,
author = {Matias, C and Rebafka, T and Villers, F},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Matias, Rebafka, Villers - 2016 - Supplementary material for A semiparametric extension of the stochastic block model for longitudina(2).pdf:pdf},
journal = {Adv. Access Publ.},
number = {1},
pages = {1--25},
title = {{Supplementary material for: A semiparametric extension of the stochastic block model for longitudinal networks}},
volume = {1},
year = {2016}
}
@article{Churchland2010,
author = {Churchland, Mark M and Yu, Byron M and Cunningham, John P and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew A and Kohn, Adam and Movshon, J Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V},
doi = {10.1038/nn.2501},
file = {:Users/bgemily/Documents/Academic/SC/Stage1/nn.2501.pdf:pdf},
issn = {1097-6256},
journal = {Nat. Publ. Gr.},
number = {3},
pages = {369--378},
publisher = {Nature Publishing Group},
title = {{Stimulus onset quenches neural variability : a widespread cortical phenomenon}},
url = {http://dx.doi.org/10.1038/nn.2501},
volume = {13},
year = {2010}
}
@article{Zhang2017,
abstract = {{\textless}p{\textgreater}The estimation of probabilities of network edges from the observed adjacency matrix has important applications to the prediction of missing links and to network denoising. It is usually addressed by estimating the graphon, a function that determines the matrix of edge probabilities, but this is ill-defined without strong assumptions on the network structure. Here we propose a novel computationally efficient method, based on neighbourhood smoothing, to estimate the expectation of the adjacency matrix directly, without making the structural assumptions that graphon estimation requires. The neighbourhood smoothing method requires little tuning, has a competitive mean squared error rate and outperforms many benchmark methods for link prediction in simulated and real networks.{\textless}/p{\textgreater}},
author = {Zhang, Yuan and Levina, Elizaveta and Zhu, Ji},
doi = {10.1093/biomet/asx042},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhang, Levina, Zhu - 2017 - Estimating network edge probabilities by neighbourhood smoothing.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
month = {dec},
number = {4},
pages = {771--783},
title = {{Estimating network edge probabilities by neighbourhood smoothing}},
url = {https://academic.oup.com/biomet/article/104/4/771/4158787},
volume = {104},
year = {2017}
}
@article{Airoldi2007,
abstract = {Observations consisting of measurements on relationships for pairs of objects arise in many settings, such as protein interaction and gene regulatory networks, collections of author-recipient email, and social networks. Analyzing such data with probabilisic models can be delicate because the simple exchangeability assumptions underlying many boilerplate models no longer hold. In this paper, we describe a latent variable model of such data called the mixed membership stochastic blockmodel. This model extends blockmodels for relational data to ones which capture mixed membership latent relational structure, thus providing an object-specific low-dimensional representation. We develop a general variational inference algorithm for fast approximate posterior inference. We explore applications to social and protein interaction networks.},
archivePrefix = {arXiv},
arxivId = {0705.4485},
author = {Airoldi, Edoardo M and Blei, David M and Fienberg, Stephen E and Xing, Eric P},
eprint = {0705.4485},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Airoldi et al. - 2007 - Mixed membership stochastic blockmodels.pdf:pdf},
month = {may},
title = {{Mixed membership stochastic blockmodels}},
url = {http://arxiv.org/abs/0705.4485},
year = {2007}
}
@article{Meinshausen2006,
abstract = {The pattern of zero entries in the inverse covariance matrix of a multivariate normal distribution corresponds to conditional independence restrictions between variables. Covariance selection aims at estimating those structural zeros from data. We show that neighborhood selection with the Lasso is a computationally attractive alternative to standard covariance selection for sparse high-dimensional graphs. Neighborhood selection estimates the conditional independence restrictions separately for each node in the graph and is hence equivalent to variable selection for Gaussian linear models. We show that the proposed neighborhood selection scheme is consistent for sparse high-dimensional graphs. Consistency hinges on the choice of the penalty parameter. The oracle value for optimal prediction does not lead to a consistent neighborhood estimate. Controlling instead the probability of falsely joining some distinct connectivity components of the graph, consistent estimation for sparse graphs is achieved (with exponential rates), even when the number of variables grows as the number of observations raised to an arbitrary power.},
author = {Meinshausen, Nicolai and B{\"{u}}hlmann, Peter},
doi = {10.1214/009053606000000281},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Meinshausen, B{\"{u}}hlmann - 2006 - High-dimensional graphs and variable selection with the Lasso.pdf:pdf},
issn = {00905364},
journal = {Ann. Stat.},
keywords = {Covariance selection,Gaussian graphical models,Linear regression,Penalized regression},
month = {jun},
number = {3},
pages = {1436--1462},
title = {{High-dimensional graphs and variable selection with the Lasso}},
volume = {34},
year = {2006}
}
@article{Loupos2017,
author = {Loupos, Pantelis and Nathan, Alexandros and Cerf, Moran},
doi = {10.2139/ssrn.3001978},
journal = {SSRN Electron. J.},
keywords = {Cold-Start,Customer Behavior,Dynamic Social Networks,Non-Contractual Settings,Predictive Analytics},
month = {sep},
publisher = {Elsevier BV},
title = {{The Power of Social Networks in Predicting Non-Contractual Customer Activity: Evidence from Venmo}},
year = {2017}
}
@article{Xu2014,
abstract = {Significant efforts have gone into the development of statistical models for analyzing data in the form of networks, such as social networks. Most existing work has focused on modeling static networks, which represent either a single time snapshot or an aggregate view over time. There has been recent interest in statistical modeling of dynamic networks, which are observed at multiple points in time and offer a richer representation of many complex phenomena. In this paper, we present a state-space model for dynamic networks that extends the well-known stochastic blockmodel for static networks to the dynamic setting. We fit the model in a near-optimal manner using an extended Kalman filter (EKF) augmented with a local search. We demonstrate that the EKF-based algorithm performs competitively with a state-of-the-art algorithm based on Markov chain Monte Carlo sampling but is significantly less computationally demanding. {\textcopyright} 2007-2012 IEEE.},
annote = {introduce a state-space model through time on (the logit transform of) the probability of connection between groups

both group membership and connectivity parameters across groups may vary through time.

Their (online) iterative estimation procedure is based on alternating two steps: a label-switching method that optimizes the posterior state density, and the (extended) Kalman filter when the groups memberships are known},
archivePrefix = {arXiv},
arxivId = {1403.0921},
author = {Xu, Kevin S. and Hero, Alfred O.},
doi = {10.1109/JSTSP.2014.2310294},
eprint = {1403.0921},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Xu, Hero - 2014 - Dynamic stochastic blockmodels for time-evolving social networks(2).pdf:pdf},
issn = {19324553},
journal = {IEEE J. Sel. Top. Signal Process.},
keywords = {State-space social network model,dynamic network,extended Kalman filter,on-line estimation},
number = {4},
pages = {552--562},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Dynamic stochastic blockmodels for time-evolving social networks}},
volume = {8},
year = {2014}
}
@article{Vu,
abstract = {The development of statistical models for continuous-time longitudinal network data is of increasing interest in machine learning and social science. Leveraging ideas from survival and event history analysis, we introduce a continuous-time regression modeling framework for network event data that can incorporate both time-varying network statistics and time-varying regression coefficients. We also develop an efficient inference scheme that allows our approach to scale to large networks. On synthetic and real-world data, empirical results demonstrate that the proposed inference approach can accurately estimate the coefficients of the regression model, which is useful for interpreting the evolution of the network; furthermore, the learned model has systematically better predictive performance compared to standard baseline methods.},
author = {Vu, Duy Q and Asuncion, Arthur U and Hunter, David R and Smyth, Padhraic},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Vu et al. - Unknown - Continuous-Time Regression Models for Longitudinal Networks.pdf:pdf},
title = {{Continuous-Time Regression Models for Longitudinal Networks}}
}
@article{Johnson2016a,
archivePrefix = {arXiv},
arxivId = {arXiv:1603.06277v5},
author = {Johnson, Matthew James and Duvenaud, David and Adams, Ryan P and Wiltschko, Alexander B},
eprint = {arXiv:1603.06277v5},
file = {:Users/bgemily/Documents/Academic/SC/Stage1/1603.06277.pdf:pdf},
number = {Nips},
title = {{Composing graphical models with neural networks for structured representations and fast inference}},
year = {2016}
}
@article{Kim2018,
abstract = {We present a selective review of statistical modeling of dynamic networks. We focus on models with latent variables, specifically, the latent space models and the latent class models (or stochastic blockmodels), which investigate both the observed features and the unobserved structure of networks. We begin with an overview of the static models, and then we introduce the dynamic extensions. For each dynamic model, we also discuss its applications that have been studied in the literature, with the data source listed in Appendix. Based on the review, we summarize a list of open problems and challenges in dynamic network modeling with latent variables. MSC 2010 subject classifications: Primary 62-02, 62-07; secondary 05C90.},
annote = {A review of invariant models based on latent space model and stochastic block model.},
author = {Kim, Bomin and Lee, Kevin H and Xue, Lingzhou and Niu, Xiaoyue},
doi = {10.1214/18-SS121},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Kim et al. - 2018 - A review of dynamic network models with latent variables.pdf:pdf},
issn = {1935-7516},
journal = {Stat. Surv.},
keywords = {Dynamic networks,latent space model,latent variable model,social network analysis,stochastic blockmodel},
pages = {105--135},
title = {{A review of dynamic network models with latent variables}},
url = {https://doi.org/10.1214/18-SS121},
volume = {12},
year = {2018}
}
@article{Handel2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.05200v1},
author = {Handel, Ramon Van},
eprint = {arXiv:1610.05200v1},
file = {:Users/bgemily/Documents/Academic/SC/Stage2/Theory/1610.05200.pdf:pdf},
pages = {1--46},
title = {{Structured Random Matrices}},
year = {2016}
}
