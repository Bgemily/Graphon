
@article{Abbe2016,
  ids = {abbeExactRecoveryStochastic2016a},
  title = {Exact Recovery in the Stochastic Block Model},
  author = {Abbe, Emmanuel and Bandeira, Afonso S. and Hall, Georgina},
  year = {2016},
  month = jan,
  volume = {62},
  pages = {471--487},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {00189448},
  doi = {10.1109/TIT.2015.2490670},
  abstract = {The stochastic block model with two communities, or equivalently the planted bisection model, is a popular model of random graph exhibiting a cluster behavior. In the symmetric case, the graph has two equally sized clusters and vertices connect with probability p within clusters and q across clusters. In the past two decades, a large body of literature in statistics and computer science has focused on providing lower bounds on the scaling of |p - q| to ensure exact recovery. In this paper, we identify a sharp threshold phenomenon for exact recovery: if {$\alpha$} = pn/log(n) and {$\beta$} = qn/log(n) are constant (with {$\alpha>$} {$\beta$}), recovering the communities with high probability is possible if ({$\alpha$} + {$\beta$}/2) - {$\surd\alpha\beta$} {$>$} 1 and is impossible if ({$\alpha$} + {$\beta$}/2) - {$\surd\alpha\beta$} {$<$} 1. In particular, this improves the existing bounds. This also sets a new line of sight for efficient clustering algorithms. While maximum likelihood (ML) achieves the optimal threshold (by definition), it is in the worst case NP-hard. This paper proposes an efficient algorithm based on a semidefinite programming relaxation of ML, which is proved to succeed in recovering the communities close to the threshold, while numerical experiments suggest that it may achieve the threshold. An efficient algorithm that succeeds all the way down to the threshold is also obtained using a partial recovery algorithm combined with a local improvement procedure.},
  annotation = {\_eprint: 1405.3267},
  journal = {IEEE Transactions on Information Theory},
  keywords = {.Stochastic block model,Clustering algorithms,Communities,Detection algorithms,Network theory (graphs),Statistical learning},
  number = {1}
}

@article{Abbe2018,
  ids = {abbeCommunityDetectionStochastic},
  title = {Community Detection and Stochastic Block Models},
  author = {Abbe, Emmanuel},
  year = {2018},
  volume = {14},
  pages = {1--162},
  issn = {15672328},
  doi = {10.1561/0100000067},
  abstract = {The stochastic block model (SBM) is a random graph model with different group of vertices connecting differently. It is widely employed as a canonical model to study clustering and community detection, and provides a fertile ground to study the information-theoretic and computational tradeoffs that arise in combinatorial statistics and more generally data science. This monograph surveys the recent developments that establish the fundamental limits for community detection in the SBM, both with respect to information-theoretic and computational tradeoffs, and for various recovery requirements such as exact, partial and weak recovery. The main results discussed are the phase transitions for exact recovery at the Chernoff-Hellinger threshold, the phase transition for weak recovery at the Kesten-Stigum threshold, the optimal SNR-mutual information tradeoff for partial recovery, and the gap between information-theoretic and computational thresholds.},
  annotation = {\_eprint: 1703.10146},
  file = {/Users/ztzhang/Zotero/storage/BWSJBVCA/Abbe - 2018 - Community detection and stochastic block models(2).pdf;/Users/ztzhang/Zotero/storage/SGN88C93/Abbe - Community Detection and Stochastic Block Models.pdf},
  journal = {Foundations and Trends in Communications and Information Theory},
  keywords = {.Community detection,.Recovery requirements,.Stochastic block model,.Theory},
  number = {1-2}
}

@article{Absil2009,
  title = {Optimization Algorithms on Matrix Manifolds},
  author = {Absil, P. A. and Mahony, R. and Sepulchre, R.},
  year = {2009},
  abstract = {Many problems in the sciences and engineering can be rephrased as optimization problems on matrix search spaces endowed with a so-called manifold structure. This book shows how to exploit the special structure of such problems to develop efficient numerical algorithms. It places careful emphasis on both the numerical formulation of the algorithm and its differential geometric abstraction\textendash illustrating how good algorithms draw equally from the insights of differential geometry, optimization, and numerical analysis. Two more theoretical chapters provide readers with the background in differential geometry necessary to algorithmic development. In the other chapters, several well-known optimization methods such as steepest descent and conjugate gradients are generalized to abstract manifolds. The book provides a generic development of each of these methods, building upon the material of the geometric chapters. It then guides readers through the calculations that turn these geometrically formulated methods into concrete numerical algorithms. The state-of-the-art algorithms given as examples are competitive with the best existing algorithms for a selection of eigenspace problems in numerical linear algebra. Optimization Algorithms on Matrix Manifoldsoffers techniques with broad applications in linear algebra, signal processing, data mining, computer vision, and statistical analysis. It can serve as a graduate-level textbook and will be of interest to applied mathematicians, engineers, and computer scientists. \textcopyright{} 2008 by Princeton University Press. All Rights Reserved.},
  file = {/Users/ztzhang/Zotero/storage/2R66AQES/Absil, Mahony, Sepulchre - 2009 - Optimization algorithms on matrix manifolds.pdf},
  isbn = {9780691132983},
  journal = {Optimization Algorithms on Matrix Manifolds}
}

@article{Airoldi2007,
  ids = {airoldiMixedMembershipStochastic},
  title = {Mixed Membership Stochastic Blockmodels},
  author = {Airoldi, Edoardo M and Blei, David M and Fienberg, Stephen E and Xing, Eric P},
  year = {2007},
  month = may,
  abstract = {Observations consisting of measurements on relationships for pairs of objects arise in many settings, such as protein interaction and gene regulatory networks, collections of author-recipient email, and social networks. Analyzing such data with probabilisic models can be delicate because the simple exchangeability assumptions underlying many boilerplate models no longer hold. In this paper, we describe a latent variable model of such data called the mixed membership stochastic blockmodel. This model extends blockmodels for relational data to ones which capture mixed membership latent relational structure, thus providing an object-specific low-dimensional representation. We develop a general variational inference algorithm for fast approximate posterior inference. We explore applications to social and protein interaction networks.},
  annotation = {\_eprint: 0705.4485},
  file = {/Users/ztzhang/Zotero/storage/A9YUFBGG/Airoldi et al. - Mixed Membership Stochastic Blockmodels.pdf;/Users/ztzhang/Zotero/storage/DFGGISKN/Airoldi et al. - 2007 - Mixed membership stochastic blockmodels.pdf},
  keywords = {.Stochastic block model}
}

@article{Airoldi2013,
  ids = {airoldiStochasticBlockmodelApproximation},
  title = {Stochastic Blockmodel Approximation of a Graphon: {{Theory}} and Consistent Estimation},
  author = {Airoldi, Edoardo M and Costa, Thiago B and Chan, Stanley H},
  year = {2013},
  month = nov,
  abstract = {Non-parametric approaches for analyzing network data based on exchangeable graph models (ExGM) have recently gained interest. The key object that defines an ExGM is often referred to as a graphon. This non-parametric perspective on network modeling poses challenging questions on how to make inference on the graphon underlying observed network data. In this paper, we propose a computationally efficient procedure to estimate a graphon from a set of observed networks generated from it. This procedure is based on a stochastic blockmodel approximation (SBA) of the graphon. We show that, by approximating the graphon with a stochastic block model, the graphon can be consistently estimated, that is, the estimation error vanishes as the size of the graph approaches infinity.},
  annotation = {\_eprint: 1311.1731},
  file = {/Users/ztzhang/Zotero/storage/5578W65B/Airoldi, Costa, Chan - 2013 - Stochastic blockmodel approximation of a graphon Theory and consistent estimation(2).pdf;/Users/ztzhang/Zotero/storage/9SDY6MYT/Airoldi et al. - Stochastic blockmodel approximation of a graphon .pdf;/Users/ztzhang/Zotero/storage/DBRAP4BP/Airoldi, Costa, Chan - 2013 - Stochastic blockmodel approximation of a graphon Theory and consistent estimation.pdf;/Users/ztzhang/Zotero/storage/R94UTHRP/Airoldi, Costa, Chan - 2013 - Stochastic blockmodel approximation of a graphon Theory and consistent estimation.pdf},
  keywords = {.Stochastic block model}
}

@article{Albert2015,
  title = {Bootstrap and Permutation Tests of Independence for Point Processes},
  author = {Albert, M{\'e}lisande and Bouret, Yann and Fromont, Magalie and {Reynaud-Bouret}, Patricia},
  year = {2015},
  month = dec,
  volume = {43},
  pages = {2537--2564},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {00905364},
  doi = {10.1214/15-AOS1351},
  abstract = {Motivated by a neuroscience question about synchrony detection in spike trains analysis, we deal with the independence testing problem for point processes. We introduce non-parametric test statistics, which are rescaled general U-statistics, whose corresponding critical values are constructed from bootstrap and randomisation or permutation approaches, making as few assumptions as possible on the underlying distribution of the point processes. We derive general consistency results for the bootstrap and for the permutation w.r.t. to Wasserstein's metric, which induce weak convergence as well as convergence of second order moments. The obtained bootstrap or permutation independence tests are thus proved to be asymptotically of the prescribed size, and to be consistent against any reasonable alternative, randomisation or permutation independence tests having the further advantage to be exactly (that is non-asymptotically) of the prescribed level, even when Monte Carlo methods are used to approximate the randomised quantiles.},
  file = {/Users/ztzhang/Zotero/storage/8I3B7EJR/Albert et al. - 2015 - Bootstrap and permutation tests of independence for point processes(2).pdf},
  journal = {Annals of Statistics},
  keywords = {.Neuroscience,Bootstrap,Independence test,Permutation,Point processes,Randomization,Spike train analysis,U-statistics},
  number = {6}
}

@article{Ali2021,
  title = {Predicting {{Attributes}} of {{Nodes Using Network Structure}}},
  author = {Ali, Sarwan and Shakeel, Muhammad Haroon and Khan, Imdadullah and Faizullah, Safiullah and Khan, Muhammad Asad},
  year = {2021},
  month = jan,
  abstract = {In many graphs such as social networks, nodes have associated attributes representing their behavior. Predicting node attributes in such graphs is an important problem with applications in many domains like recommendation systems, privacy preservation, and targeted advertisement. Attributes values can be predicted by analyzing patterns and correlations among attributes and employing classification/regression algorithms. However, these approaches do not utilize readily available network topology information. In this regard, interconnections between different attributes of nodes can be exploited to improve the prediction accuracy. In this paper, we propose an approach to represent a node by a feature map with respect to an attribute \$a\_i\$ (which is used as input for machine learning algorithms) using all attributes of neighbors to predict attributes values for \$a\_i\$. We perform extensive experimentation on ten real-world datasets and show that the proposed feature map significantly improves the prediction accuracy as compared to baseline approaches on these datasets.},
  archivePrefix = {arXiv},
  eprint = {1912.12264},
  eprinttype = {arxiv},
  journal = {arXiv:1912.12264 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Alvarez-Rodriguez2021,
  title = {Evolutionary Dynamics of Higher-Order Interactions in Social Networks},
  author = {{Alvarez-Rodriguez}, Unai and Battiston, Federico and {de Arruda}, Guilherme Ferraz and Moreno, Yamir and Perc, Matja{\v z} and Latora, Vito},
  year = {2021},
  month = jan,
  pages = {1--10},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-020-01024-1},
  abstract = {We live and cooperate in networks. However, links in networks only allow for pairwise interactions, thus making the framework suitable for dyadic games, but not for games that are played in larger groups. Here, we study the evolutionary dynamics of a public goods game in social systems with higher-order interactions. First, we show that the game on uniform hypergraphs corresponds to the replicator dynamics in the well-mixed limit, providing a formal theoretical foundation to study cooperation in networked groups. Second, we unveil how the presence of hubs and the coexistence of interactions in groups of different sizes affects the evolution of cooperation. Finally, we apply the proposed framework to extract the actual dependence of the synergy factor on the size of a group from real-world collaboration data in science and technology. Our work provides a way to implement informed actions to boost cooperation in social groups.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  journal = {Nature Human Behaviour},
  keywords = {.Hypergraph,.Social networks},
  language = {en}
}

@article{Amini2013,
  title = {Pseudo-Likelihood Methods for Community Detection in Large Sparse Networks},
  author = {Amini, Arash A. and Chen, Aiyou and Bickel, Peter J. and Levina, Elizaveta},
  year = {2013},
  month = aug,
  volume = {41},
  pages = {2097--2122},
  issn = {0090-5364},
  doi = {10.1214/13-AOS1138},
  abstract = {Many algorithms have been proposed for fitting network models with communities, but most of them do not scale well to large networks, and often fail on sparse networks. Here we propose a new fast pseudo-likelihood method for fitting the stochastic block model for networks, as well as a variant that allows for an arbitrary degree distribution by conditioning on degrees. We show that the algorithms perform well under a range of settings, including on very sparse networks, and illustrate on the example of a network of political blogs. We also propose spectral clustering with perturbations, a method of independent interest, which works well on sparse networks where regular spectral clustering fails, and use it to provide an initial value for pseudo-likelihood. We prove that pseudo-likelihood provides consistent estimates of the communities under a mild condition on the starting value, for the case of a block model with two communities.},
  archivePrefix = {arXiv},
  eprint = {1207.2340},
  eprinttype = {arxiv},
  journal = {The Annals of Statistics},
  keywords = {.Stochastic block model},
  number = {4}
}

@article{Amini2018,
  title = {On Semidefinite Relaxations for the Block Model},
  author = {Amini, Arash A and Levina, Elizaveta},
  year = {2018},
  volume = {46},
  pages = {149--179},
  doi = {10.1214/17-AOS1545},
  abstract = {The stochastic block model (SBM) is a popular tool for community detection in networks, but fitting it by maximum likelihood (MLE) involves a computationally infeasible optimization problem. We propose a new semidef-inite programming (SDP) solution to the problem of fitting the SBM, derived as a relaxation of the MLE. We put ours and previously proposed SDPs in a unified framework, as relaxations of the MLE over various subclasses of the SBM, which also reveals a connection to the well-known problem of sparse PCA. Our main relaxation, which we call SDP-1, is tighter than other recently proposed SDP relaxations, and thus previously established theoretical guarantees carry over. However, we show that SDP-1 exactly recovers true communities over a wider class of SBMs than those covered by current results. In particular, the assumption of strong assortativity of the SBM, implicit in consistency conditions for previously proposed SDPs, can be relaxed to weak assortativity for our approach, thus significantly broadening the class of SBMs covered by the consistency results. We also show that strong as-sortativity is indeed a necessary condition for exact recovery for previously proposed SDP approaches and not an artifact of the proofs. Our analysis of SDPs is based on primal-dual witness constructions, which provides some insight into the nature of the solutions of various SDPs. In particular, we show how to combine features from SDP-1 and already available SDPs to achieve the most flexibility in terms of both assortativity and block-size constraints, as our relaxation has the tendency to produce communities of similar sizes. This tendency makes it the ideal tool for fitting network histograms, a method gaining popularity in the graphon estimation literature, as we illustrate on an example of a social networks of dolphins. We also provide empirical evidence that SDPs outperform spectral methods for fitting SBMs with a large number of blocks.},
  file = {/Users/ztzhang/Zotero/storage/ZVJK7TZW/Amini, Levina - 2018 - On semidefinite relaxations for the block model.pdf},
  journal = {The Annals of Statistics},
  keywords = {.Stochastic block model,62G20,62H99,90C22,Community detection,network,semidefinite programming},
  number = {1}
}

@article{Arastuie2019,
  title = {Personalized {{Degrees}}: {{Effects}} on {{Link Formation}} in {{Dynamic Networks}} from an {{Egocentric Perspective}}},
  shorttitle = {Personalized {{Degrees}}},
  author = {Arastuie, Makan and Xu, Kevin S.},
  year = {2019},
  month = may,
  pages = {1039--1046},
  doi = {10.1145/3308560.3316699},
  abstract = {Understanding mechanisms driving link formation in dynamic social networks is a long-standing problem that has implications to understanding social structure as well as link prediction and recommendation. Social networks exhibit a high degree of transitivity, which explains the successes of common neighbor-based methods for link prediction. In this paper, we examine mechanisms behind link formation from the perspective of an ego node. We introduce the notion of personalized degree for each neighbor node of the ego, which is the number of other neighbors a particular neighbor is connected to. From empirical analyses on four on-line social network datasets, we find that neighbors with higher personalized degree are more likely to lead to new link formations when they serve as common neighbors with other nodes, both in undirected and directed settings. This is complementary to the finding of Adamic and Adar that neighbor nodes with higher (global) degree are less likely to lead to new link formations. Furthermore, on directed networks, we find that personalized out-degree has a stronger effect on link formation than personalized in-degree, whereas global in-degree has a stronger effect than global out-degree. We validate our empirical findings through several link recommendation experiments and observe that incorporating both personalized and global degree into link recommendation greatly improves accuracy.},
  archivePrefix = {arXiv},
  eprint = {1712.01796},
  eprinttype = {arxiv},
  journal = {Companion Proceedings of The 2019 World Wide Web Conference},
  keywords = {.Social networks,Computer Science - Social and Information Networks,Physics - Physics and Society}
}

@article{Arastuie2020,
  title = {{{CHIP}}: {{A Hawkes Process Model}} for {{Continuous}}-Time {{Networks}} with {{Scalable}} and {{Consistent Estimation}}},
  shorttitle = {{{CHIP}}},
  author = {Arastuie, Makan and Paul, Subhadeep and Xu, Kevin S.},
  year = {2020},
  month = nov,
  abstract = {In many application settings involving networks, such as messages between users of an on-line social network or transactions between traders in financial markets, the observed data consist of timestamped relational events, which form a continuous-time network. We propose the Community Hawkes Independent Pairs (CHIP) generative model for such networks. We show that applying spectral clustering to an aggregated adjacency matrix constructed from the CHIP model provides consistent community detection for a growing number of nodes and time duration. We also develop consistent and computationally efficient estimators for the model parameters. We demonstrate that our proposed CHIP model and estimation procedure scales to large networks with tens of thousands of nodes and provides superior fits than existing continuous-time network models on several real networks.},
  archivePrefix = {arXiv},
  eprint = {1908.06940},
  eprinttype = {arxiv},
  journal = {arXiv:1908.06940 [physics, stat]},
  keywords = {.Dynamic network,.Hawkes processes,.Time varying networks,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {physics, stat}
}

@article{Armijo1966,
  title = {Minimization of Functions Having Lipschitz Continuous First Partial Derivatives},
  author = {Armijo, Larry},
  year = {1966},
  issn = {00308730},
  doi = {10.2140/pjm.1966.16.1},
  abstract = {Project Euclid - mathematics and statistics online},
  journal = {Pacific Journal of Mathematics}
}

@article{Atashgahi2020,
  title = {Quick and {{Robust Feature Selection}}: The {{Strength}} of {{Energy}}-Efficient {{Sparse Training}} for {{Autoencoders}}},
  shorttitle = {Quick and {{Robust Feature Selection}}},
  author = {Atashgahi, Zahra and Sokar, Ghada and {van der Lee}, Tim and Mocanu, Elena and Mocanu, Decebal Constantin and Veldhuis, Raymond and Pechenizkiy, Mykola},
  year = {2020},
  month = dec,
  abstract = {Major complications arise from the recent increase in the amount of high-dimensional data, including high computational costs and memory requirements. Feature selection, which identifies the most relevant and informative attributes of a dataset, has been introduced as a solution to this problem. Most of the existing feature selection methods are computationally inefficient; inefficient algorithms lead to high energy consumption, which is not desirable for devices with limited computational and energy resources. In this paper, a novel and flexible method for unsupervised feature selection is proposed. This method, named QuickSelection, introduces the strength of the neuron in sparse neural networks as a criterion to measure the feature importance. This criterion, blended with sparsely connected denoising autoencoders trained with the sparse evolutionary training procedure, derives the importance of all input features simultaneously. We implement QuickSelection in a purely sparse manner as opposed to the typical approach of using a binary mask over connections to simulate sparsity. It results in a considerable speed increase and memory reduction. When tested on several benchmark datasets, including five low-dimensional and three high-dimensional datasets, the proposed method is able to achieve the best trade-off of classification and clustering accuracy, running time, and maximum memory usage, among widely used approaches for feature selection. Besides, our proposed method requires the least amount of energy among the state-of-the-art autoencoder-based feature selection methods.},
  archivePrefix = {arXiv},
  eprint = {2012.00560},
  eprinttype = {arxiv},
  journal = {arXiv:2012.00560 [cs, stat]},
  keywords = {.unlabeled,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Bachem2017,
  title = {Uniform {{Deviation Bounds}} for K-{{Means Clustering}}},
  author = {Bachem, Olivier and Lucic, Mario and Hamed Hassani, S and Krause, Andreas},
  year = {2017},
  abstract = {Uniform deviation bounds limit the difference between a model's expected loss and its loss on a random sample uniformly for all models in a learning problem. In this paper, we provide a novel framework to obtain uniform deviation bounds for unbounded loss functions. As a result, we obtain competitive uniform deviation bounds for k-Means clustering under weak assumptions on the underlying distribution. If the fourth moment is bounded, we prove a rate of O {$\downdasharrow$} m 1 2 ⌘ compared to the previously known O {$\downdasharrow$} m 1 4 ⌘ rate. We further show that this rate also depends on the kurtosis-the normalized fourth moment which measures the "tailedness" of the distribution. We also provide improved rates under progressively stronger assumptions, namely, bounded higher moments, subgaussianity and bounded support of the underlying distribution.},
  file = {/Users/ztzhang/Zotero/storage/RLWZQBL3/Bachem et al. - 2017 - Uniform Deviation Bounds for k-Means Clustering.pdf}
}

@article{Banerjee2007,
  title = {Model {{Selection Through Sparse Maximum Likelihood Estimation}}},
  author = {Banerjee, Onureena and Ghaoui, Laurent El and D'Aspremont, Alexandre},
  year = {2007},
  month = jul,
  abstract = {We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse. Our approach is to solve a maximum likelihood problem with an added l\_1-norm penalty term. The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes. We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case. Our first algorithm uses block coordinate descent, and can be interpreted as recursive l\_1-norm penalized regression. Our second algorithm, based on Nesterov's first order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods. Using a log determinant relaxation of the log partition function (Wainwright \& Jordan (2006)), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case. We test our algorithms on synthetic data, as well as on gene expression and senate voting records data.},
  annotation = {\_eprint: 0707.0704},
  file = {/Users/ztzhang/Zotero/storage/WBYA69ZY/Banerjee, Ghaoui, d'Aspremont - 2007 - Model Selection Through Sparse Maximum Likelihood Estimation.pdf}
}

@article{Baraud2009,
  title = {Estimating the Intensity of a Random Measure by Histogram Type Estimators},
  author = {Baraud, Yannick and Birg{\'e}, Lucien and Baraud, Yannick and Birg{\'e}, Lucien},
  year = {2009},
  month = jan,
  volume = {143},
  pages = {239--284},
  issn = {01788051},
  doi = {10.1007/s00440-007-0126-6},
  abstract = {The purpose of this paper is to estimate the intensity of some random measure N on a set X by a piecewise constant function on a finite partition of X. Given a (possibly large) family M of candidate partitions, we build a piecewise constant estimator (histogram) on each of them and then use the data to select one estimator in the family. Choosing the square of a Hellinger-type distance as our loss function, we show that each estimator built on a given partition satisfies an analogue of the classical squared bias plus variance risk bound. Moreover, the selection procedure leads to a final estimator satisfying some oracle-type inequality, with, as usual, a possible loss corresponding to the complexity of the family M. When this complexity is not too high, the selected estimator has a risk bounded, up to a universal constant, by the smallest risk bound obtained for the estimators in the family. For suitable choices of the family of partitions, we deduce uniform risk bounds over various classes of intensities. Our approach applies to the estimation of the intensity of an inhomogenous Poisson process, among other counting processes, or the estimation of the mean of a random vector with nonnegative components.},
  file = {/Users/ztzhang/Zotero/storage/VMYLVGVW/Baraud et al. - 2009 - Estimating the intensity of a random measure by histogram type estimators.pdf},
  journal = {Probability Theory and Related Fields},
  keywords = {Adaptive estimation,Classification (2000) 62G05,Discrete data,Discrete data ·,Histogram,Histogram ·,Intensity estimation,Intensity estimation ·,Mathematics,Model selection,Model selection ·,Poisson process,Poisson process ·,Subject},
  number = {1-2}
}

@incollection{Bercu2015,
  title = {Concentration Inequalities for Martingales},
  booktitle = {Concentration {{Inequalities}} for {{Sums}} and {{Martingales}}},
  author = {Bercu, Bernard and Delyon, Bernard and Rio, Emmanuel},
  editor = {Bercu, Bernard and Delyon, Bernard and Rio, Emmanuel},
  year = {2015},
  pages = {61--98},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-22099-4_3},
  abstract = {This chapter is devoted to concentration inequalities for martingales such as Azuma-Hoeffding, Freedman, and De la Pena inequalities. Several extensions will also be provided. In particular, we will focus our attention on improved versions of Azuma-Hoeffding and Freedman's type inequalities.},
  isbn = {978-3-319-22099-4},
  keywords = {.Inequality,.Martingale,.Stochastic process,Azuma Hoeffding,Concentration Inequalities,Exponential Inequalities,Self-Normalized Processes,Total Quadratic Variation},
  language = {en},
  series = {{{SpringerBriefs}} in {{Mathematics}}}
}

@article{Berlingerio2012,
  title = {{{NetSimile}}: {{A Scalable Approach}} to {{Size}}-{{Independent Network Similarity}}},
  shorttitle = {{{NetSimile}}},
  author = {Berlingerio, Michele and Koutra, Danai and {Eliassi-Rad}, Tina and Faloutsos, Christos},
  year = {2012},
  month = sep,
  abstract = {Given a set of k networks, possibly with different sizes and no overlaps in nodes or edges, how can we quickly assess similarity between them, without solving the node-correspondence problem? Analogously, how can we extract a small number of descriptive, numerical features from each graph that effectively serve as the graph's "signature"? Having such features will enable a wealth of graph mining tasks, including clustering, outlier detection, visualization, etc. We propose NetSimile -- a novel, effective, and scalable method for solving the aforementioned problem. NetSimile has the following desirable properties: (a) It gives similarity scores that are size-invariant. (b) It is scalable, being linear on the number of edges for "signature" vector extraction. (c) It does not need to solve the node-correspondence problem. We present extensive experiments on numerous synthetic and real graphs from disparate domains, and show NetSimile's superiority over baseline competitors. We also show how NetSimile enables several mining tasks such as clustering, visualization, discontinuity detection, network transfer learning, and re-identification across networks.},
  archivePrefix = {arXiv},
  eprint = {1209.2684},
  eprinttype = {arxiv},
  journal = {arXiv:1209.2684 [physics, stat]},
  keywords = {.Network similarity,Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Applications},
  primaryClass = {physics, stat}
}

@article{Betancourt2017,
  title = {Bayesian {{Fused Lasso Regression}} for {{Dynamic Binary Networks}}},
  author = {Betancourt, Brenda and Rodr{\'i}guez, Abel and Boyd, Naomi},
  year = {2017},
  month = oct,
  volume = {26},
  pages = {840--850},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1080/10618600.2017.1341323},
  abstract = {We propose a multinomial logistic regression model for link prediction in a time series of directed binary networks. To account for the dynamic nature of the data, we employ a dynamic model for the model parameters that is strongly connected with the fused lasso penalty. In addition to promoting sparseness, this prior allows us to explore the presence of change points in the structure of the network. We introduce fast computational algorithms for estimation and prediction using both optimization and Bayesian approaches. The performance of the model is illustrated using simulated data and data from a financial trading network in the NYMEX natural gas futures market. Supplementary material containing the trading network dataset and code to implement the algorithms is available online.},
  annotation = {\_eprint: https://doi.org/10.1080/10618600.2017.1341323},
  journal = {Journal of Computational and Graphical Statistics},
  keywords = {.Fused lasso,.Time varying networks,Multinomial logistic regression,Network link prediction,Pólya-Gamma latent variables,Split Bregman method},
  number = {4}
}

@article{Bigot2013,
  title = {Intensity Estimation of Non-Homogeneous {{Poisson}} Processes from Shifted Trajectories},
  author = {Bigot, J{\'e}r{\'e}mie and Gadat, S{\'e}bastien and Klein, Thierry and Marteau, Cl{\'e}ment},
  year = {2013},
  volume = {7},
  pages = {881--931},
  issn = {1935-7524},
  doi = {10.1214/13-EJS794},
  abstract = {In this paper, we consider the problem of estimating nonpara-metrically a mean pattern intensity {$\lambda$} from the observation of n independent and non-homogeneous Poisson processes N 1 ,. .. , N n on the interval [0, 1]. This problem arises when data (counts) are collected independently from n individuals according to similar Poisson processes. We show that estimating this intensity is a deconvolution problem for which the density of the random shifts plays the role of the convolution operator. In an asymptotic setting where the number n of observed trajectories tends to infinity, we derive upper and lower bounds for the minimax quadratic risk over Besov balls. Non-linear thresholding in a Meyer wavelet basis is used to derive an adaptive estimator of the intensity. The proposed estimator is shown to achieve a near-minimax rate of convergence. This rate depends both on the smoothness of the intensity function and the density of the random shifts, which makes a connection between the classical deconvolution problem in nonparametric statistics and the estimation of a mean intensity from the observations of independent Poisson processes.},
  file = {/Users/ztzhang/Zotero/storage/ZG2LIMBF/Bigot et al. - 2013 - Intensity estimation of non-homogeneous Poisson processes from shifted trajectories.pdf},
  journal = {Electronic Journal of Statistics},
  keywords = {42C40Poisson processes,62G08,adaptive estimation,Besov space,deconvolution,intensity estimation,Meyer wavelets,minimax rate,random shifts}
}

@article{Bigot2013a,
  title = {Minimax Properties of {{Fr\'echet}} Means of Discretely Sampled Curves},
  author = {Bigot, J{\'e}r{\'e}mie and Gendre, Xavier},
  year = {2013},
  volume = {41},
  pages = {923--956},
  doi = {10.1214/13-AOS1104},
  abstract = {We study the problem of estimating a mean pattern from a set of similar curves in the setting where the variability in the data is due to random geometric deformations and additive noise. We propose an estimator based on the notion of Fr\'echet mean that is a generalization of the standard notion of averaging to non-Euclidean spaces. We derive a minimax rate for this estimation problem, and we show that our estimator achieves this optimal rate under the asymptotics where both the number of curves and the number of sampling points go to infinity.},
  journal = {The Annals of Statistics},
  keywords = {62G08,62G20,curve registration,deformable models,Fréchet mean,functional data analysis,lie group action,minimax rate of convergence,non-Euclidean metric,Sobolev balls},
  number = {2}
}

@techreport{Biometrika,
  title = {Network Cross-Validation by Edge Sampling},
  author = {Biometrika, (xxx) and Xx, Xxx},
  pages = {1--52},
  abstract = {While many statistical models and methods are now available for network analysis, resampling network data remains a challenging problem. Cross-validation is a useful general tool for model selection and parameter tuning, but is not directly applicable to networks since splitting network nodes into groups requires deleting edges and destroys some of the network structure. Here we propose a new network resampling strategy based on splitting node pairs rather than nodes applicable to cross-validation for a wide range of network model selection tasks. We provide a theoretical justification for our method in a general setting and examples of how our method can be used in specific network model selection and parameter tuning tasks. Numerical results on simulated networks and on a citation network of statisticians show that this cross-validation approach works well for model selection.},
  annotation = {\_eprint: 1612.04717v7},
  file = {/Users/ztzhang/Zotero/storage/4F7WKCC4/Biometrika, Xx - Unknown - Network cross-validation by edge sampling.pdf},
  keywords = {model selection,parameter tuning,random networks,Some key words: cross-validation}
}

@article{Blondel2008,
  title = {Fast Unfolding of Communities in Large Networks},
  author = {Blondel, Vincent D. and Guillaume, Jean Loup and Lambiotte, Renaud and Lefebvre, Etienne},
  year = {2008},
  month = oct,
  volume = {2008},
  issn = {17425468},
  doi = {10.1088/1742-5468/2008/10/P10008},
  abstract = {We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection methods in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2 million customers and by analysing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad hoc modular networks. \textcopyright{} 2008 IOP Publishing Ltd.},
  annotation = {\_eprint: 0803.0476},
  file = {/Users/ztzhang/Zotero/storage/MI55I4BD/Blondel et al. - 2008 - Fast unfolding of communities in large networks.pdf},
  journal = {Journal of Statistical Mechanics: Theory and Experiment},
  keywords = {Networks,New applications of statistical mechanics,Random graphs},
  number = {10}
}

@article{Blundell2012,
  title = {Modelling Reciprocating Relationships with {{Hawkes}} Processes},
  author = {Blundell, Charles and Beck, Jeff and Heller, Katherine A.},
  year = {2012},
  volume = {25},
  pages = {2600--2608},
  journal = {Advances in Neural Information Processing Systems},
  keywords = {.Hawkes processes,.Point processes,.Social networks}
}

@article{Bobkov2010,
  ids = {bobkovConcentrationEmpiricalDistribution2010a},
  title = {Concentration of Empirical Distribution Functions with Applications to Non-i.i.d. Models},
  author = {Bobkov, S. G. and G{\"o}tze, F.},
  year = {2010},
  month = nov,
  volume = {16},
  pages = {1385--1414},
  publisher = {{Bernoulli Society for Mathematical Statistics and Probability}},
  issn = {13507265},
  doi = {10.3150/10-BEJ254},
  abstract = {The concentration of empirical measures is studied for dependent data, whose joint distribution satisfies Poincar\'e-type or logarithmic Sobolev inequalities. The general concentration results are then applied to spectral empirical distribution functions associated with high-dimensional random matrices.},
  archivePrefix = {arXiv},
  eprint = {1011.6165},
  eprinttype = {arxiv},
  journal = {Bernoulli},
  keywords = {.Concentration theory,.Empirical measures,.Empirical processes,Empirical measures,Logarithmic Sobolev inequalities,Mathematics - Statistics Theory,Poincaré-type inequalities,Random matrices,Spectral distributions},
  number = {4}
}

@article{Boguna2003,
  title = {Emergence of Clustering, Correlations, and Communities in a Social Network Model},
  author = {Boguna, Marian and {Pastor-Satorras}, Romualdo and {Diaz-Guilera}, Albert and Arenas, Alex},
  year = {2003},
  month = oct,
  abstract = {We propose a simple model of social network formation that parameterizes the tendency to establish acquaintances by the relative distance in a representative social space. By means of analytical calculations and numerical simulations, we show that the model reproduces the main characteristics of real social networks: non- vanishing clustering coefficient, assortative degree correlations, and the emergence of a hierarchy of communities. Our results highlight the importance of communities in the understanding of the structure of social networks.},
  archivePrefix = {arXiv},
  eprint = {cond-mat/0309263},
  eprinttype = {arxiv},
  journal = {arXiv:cond-mat/0309263},
  keywords = {.Social networks,Condensed Matter - Disordered Systems and Neural Networks,Condensed Matter - Statistical Mechanics}
}

@article{Bontemps2014,
  title = {Bayesian Methods for the {{Shape Invariant Model}}},
  author = {Bontemps, Dominique and Gadat, S{\'e}bastien},
  year = {2014},
  volume = {8},
  pages = {1522--1568},
  issn = {1935-7524},
  doi = {10.1214/14-EJS933},
  abstract = {In this paper, we consider the so-called Shape Invariant Model that is used to model a function f 0 submitted to a random translation of law g 0 in a white noise. This model is of interest when the law of the deformations is unknown. Our objective is to recover the law of the process P f 0 ,g 0 as well as f 0 and g 0. To do this, we adopt a Bayesian point of view and find priors on f and g so that the posterior distribution concentrates at a polynomial rate around P f 0 ,g 0 when n goes to +{$\infty$}. We then derive results on the identifiability of the SIM, as well as results on the functional objects themselves. We intensively use Bayesian non-parametric tools coupled with mixture models, which may be of independent interest in model selection from a frequentist point of view.},
  file = {/Users/ztzhang/Zotero/storage/PQBHQW95/Bontemps, Gadat - 2014 - Bayesian methods for the Shape Invariant Model.pdf},
  journal = {Electronic Journal of Statistics},
  keywords = {62F15,62G05,Bayesian methods,convergence rate of posterior distribution,non-parametric estimation,Shape Invariant Model}
}

@article{Borgs,
  title = {Private {{Graphon Estimation}} for {{Sparse Graphs}} *},
  author = {Borgs, Christian and Chayes, Jennifer T and Smith, Adam},
  abstract = {We design algorithms for fitting a high-dimensional statistical model to a large, sparse network without revealing sensitive information of individual members. Given a sparse input graph G, our algorithms output a node-differentially private nonparametric block model approximation. By node-differentially private, we mean that our output hides the insertion or removal of a vertex and all its adjacent edges. If G is an instance of the network obtained from a generative nonparametric model defined in terms of a graphon W , our model guarantees consistency: as the number of vertices tends to infinity, the output of our algorithm converges to W in an appropriate version of the L 2 norm. In particular, this means we can estimate the sizes of all multi-way cuts in G. Our results hold as long as W is bounded, the average degree of G grows at least like the log of the number of vertices, and the number of blocks goes to infinity at an appropriate rate. We give explicit error bounds in terms of the parameters of the model; in several settings, our bounds improve on or match known nonprivate results.},
  file = {/Users/ztzhang/Zotero/storage/Z7KKFFKJ/Borgs, Chayes, Smith - Unknown - Private Graphon Estimation for Sparse Graphs.pdf}
}

@inproceedings{Bottou2010,
  title = {Large-{{Scale Machine Learning}} with {{Stochastic Gradient Descent}}},
  booktitle = {Proceedings of {{COMPSTAT}}'2010},
  author = {Bottou, L{\'e}on},
  editor = {Lechevallier, Yves and Saporta, Gilbert},
  year = {2010},
  pages = {177--186},
  publisher = {{Physica-Verlag HD}},
  address = {{Heidelberg}},
  doi = {10.1007/978-3-7908-2604-3_16},
  abstract = {During the last decade, the data sizes have grown faster than the speed of processors. In this context, the capabilities of statistical machine learning methods is limited by the computing time rather than the sample size. A more precise analysis uncovers qualitatively different tradeoffs for the case of small-scale and large-scale learning problems. The large-scale case involves the computational complexity of the underlying optimization algorithm in non-trivial ways. Unlikely optimization algorithms such as stochastic gradient descent show amazing performance for large-scale problems. In particular, second order stochastic gradient and averaged stochastic gradient are asymptotically efficient after a single pass on the training set.},
  isbn = {978-3-7908-2604-3},
  keywords = {.Stochastic gradient descent,.Theory,efficiency,online learning,stochastic gradient descent},
  language = {en}
}

@article{Boyd2010,
  title = {Distributed {{Optimization}} and {{Statistical Learning}} via the {{Alternating Direction Method}} of {{Multipliers}}},
  author = {Boyd, S and Parikh, N and Chu, E and Eckstein, J and Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  year = {2010},
  volume = {3},
  pages = {1--122},
  doi = {10.1561/2200000016},
  file = {/Users/ztzhang/Zotero/storage/5EZR388J/Boyd et al. - 2010 - Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.pdf},
  journal = {Foundations and Trends R in Machine Learning},
  number = {1}
}

@article{Butts2008,
  ids = {buttsRelationalEventFramework2008a},
  title = {A {{Relational Event Framework}} for {{Social Action}}},
  author = {Butts, Carter T.},
  year = {2008},
  month = aug,
  volume = {38},
  pages = {155--200},
  issn = {0081-1750},
  doi = {10.1111/j.1467-9531.2008.00203.x},
  file = {/Users/ztzhang/Zotero/storage/Y3AU4FNE/Butts - 2008 - A Relational Event Framework for Social Action.pdf},
  journal = {Sociological Methodology},
  keywords = {.Relational event data},
  number = {1}
}

@article{Cai2021,
  title = {Latent {{Network Structure Learning}} from {{High Dimensional Multivariate Point Processes}}},
  author = {Cai, Biao and Zhang, Jingfei and Guan, Yongtao},
  year = {2021},
  month = jan,
  abstract = {Learning the latent network structure from large scale multivariate point process data is an important task in a wide range of scientific and business applications. For instance, we might wish to estimate the neuronal functional connectivity network based on spiking times recorded from a collection of neurons. To characterize the complex processes underlying the observed data, we propose a new and flexible class of nonstationary Hawkes processes that allow both excitatory and inhibitory effects. We estimate the latent network structure using an efficient sparse least squares estimation approach. Using a thinning representation, we establish concentration inequalities for the first and second order statistics of the proposed Hawkes process. Such theoretical results enable us to establish the non-asymptotic error bound and the selection consistency of the estimated parameters. Furthermore, we describe a least squares loss based statistic for testing if the background intensity is constant in time. We demonstrate the efficacy of our proposed method through simulation studies and an application to a neuron spike train data set.},
  archivePrefix = {arXiv},
  eprint = {2004.03569},
  eprinttype = {arxiv},
  journal = {arXiv:2004.03569 [stat]},
  keywords = {.Hawkes processes,.Point processes,.Time varying networks,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {stat}
}

@article{Candelaria2020,
  title = {Identification and {{Inference}} of {{Network Formation Games}} with {{Misclassified Links}}},
  author = {Candelaria, Luis E. and Ura, Takuya},
  year = {2020},
  month = dec,
  abstract = {This paper considers a network formation model when links are potentially measured with error. We focus on a game-theoretical model of strategic network formation with incomplete information, in which the linking decisions depend on agents' exogenous attributes and endogenous network characteristics. In the presence of link misclassification, we derive moment conditions that characterize the identified set for the preference parameters associated with homophily and network externalities. Based on the moment equality conditions, we provide an inference method that is asymptotically valid when a single network of many agents is observed. Finally, we apply our proposed method to study trust networks in rural villages in southern India.},
  archivePrefix = {arXiv},
  eprint = {1804.10118},
  eprinttype = {arxiv},
  journal = {arXiv:1804.10118 [stat]},
  keywords = {.unlabeled,Statistics - Methodology},
  primaryClass = {stat}
}

@article{Candes2009,
  title = {The {{Power}} of {{Convex Relaxation}}: {{Near}}-{{Optimal Matrix Completion}}},
  author = {Candes, Emmanuel J. and Tao, Terence},
  year = {2009},
  month = mar,
  abstract = {This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible; but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful. This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank r by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr polylog(n).},
  annotation = {\_eprint: 0903.1476},
  file = {/Users/ztzhang/Zotero/storage/9DB4R8SD/Candes, Tao - 2009 - The Power of Convex Relaxation Near-Optimal Matrix Completion.pdf}
}

@article{Candes2009a,
  title = {Exact {{Matrix Completion}} via {{Convex Optimization}}},
  author = {Cand{\`e}s, Emmanuel J. and Recht, Benjamin},
  year = {2009},
  month = dec,
  volume = {9},
  pages = {717--772},
  issn = {1615-3375},
  doi = {10.1007/s10208-009-9045-5},
  journal = {Foundations of Computational Mathematics},
  number = {6}
}

@article{Chabert-Liddell2021,
  title = {A {{Stochastic Block Model Approach}} for the {{Analysis}} of {{Multilevel Networks}}: An {{Application}} to the {{Sociology}} of {{Organizations}}},
  shorttitle = {A {{Stochastic Block Model Approach}} for the {{Analysis}} of {{Multilevel Networks}}},
  author = {{Chabert-Liddell}, Saint-Clair and Barbillon, Pierre and Donnet, Sophie and Lazega, Emmanuel},
  year = {2021},
  month = jun,
  volume = {158},
  pages = {107179},
  issn = {01679473},
  doi = {10.1016/j.csda.2021.107179},
  abstract = {A multilevel network is defined as the junction of two interaction networks, one level representing the interactions between individuals and the other the interactions between organizations. The levels are linked by an affiliation relationship, each individual belonging to a unique organization. A new Stochastic Block Model is proposed as a unified probalistic framework tailored for multilevel networks. This model contains latent blocks accounting for heterogeneity in the patterns of connection within each level and introducing dependencies between the levels. The sought connection patterns are not specified a priori which makes this approach flexible. Variational methods are used for the model inference and an Integrated Classified Likelihood criterion is developed for choosing the number of blocks and also for deciding whether the two levels are dependent or not. A comprehensive simulation study exhibits the benefit of considering this approach, illustrates the robustness of the clustering and highlights the reliability of the criterion used for model selection. This approach is applied on a sociological dataset collected during a television program trade fair, the inter-organizational level being the economic network between companies and the inter-individual level being the informal network between their representatives. It brings a synthetic representation of the two networks unraveling their intertwined structure and confirms the coopetition at stake.},
  archivePrefix = {arXiv},
  eprint = {1910.10512},
  eprinttype = {arxiv},
  journal = {Computational Statistics \& Data Analysis},
  keywords = {Statistics - Applications,Statistics - Methodology}
}

@article{Chacon2020,
  title = {Minimum Adjusted {{Rand}} Index for Two Clusterings of a given Size},
  author = {Chac{\'o}n, Jos{\'e} E. and Rastrojo, Ana I.},
  year = {2020},
  month = dec,
  abstract = {The adjusted Rand index (ARI) is commonly used in cluster analysis to measure the degree of agreement between two data partitions. Since its introduction, exploring the situations of extreme agreement and disagreement under different circumstances has been a subject of interest, in order to achieve a better understanding of this index. Here, an explicit formula for the lowest possible value of the ARI for two clusterings of given sizes is shown, and moreover a specific pair of clusterings achieving such a bound is provided.},
  archivePrefix = {arXiv},
  eprint = {2002.03677},
  eprinttype = {arxiv},
  journal = {arXiv:2002.03677 [cs, stat]},
  keywords = {.unlabeled,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Chan2014,
  title = {A {{Consistent Histogram Estimator}} for {{Exchangeable Graph Models}}},
  author = {Chan, Stanley H. and Airoldi, Edoardo M.},
  year = {2014},
  month = feb,
  annotation = {\_eprint: 1402.1888}
}

@article{Chandrasekaran2011,
  title = {Rank-Sparsity Incoherence for Matrix Decomposition},
  author = {Chandrasekaran, Venkat and Sanghavi, Sujay and Parrilo, Pablo A. and Willsky, Alan S.},
  year = {2011},
  volume = {21},
  pages = {572--596},
  issn = {10526234},
  doi = {10.1137/090761793},
  abstract = {Suppose we are given a matrix that is formed by adding an unknown sparse matrix to an unknown low-rank matrix. Our goal is to decompose the given matrix into its sparse and low-rank components. Such a problem arises in a number of applications in model and system identification, and is NP-hard in general. In this paper we consider a convex optimization formulation to splitting the specified matrix into its components, by minimizing a linear combination of the \$\textbackslash ell\_1\$ norm and the nuclear norm of the components. We develop a notion of \textbackslash emphrank-sparsity incoherence, expressed as an uncertainty principle between the sparsity pattern of a matrix and its row and column spaces, and use it to characterize both fundamental identifiability as well as (deterministic) sufficient conditions for exact recovery. Our analysis is geometric in nature, with the tangent spaces to the algebraic varieties of sparse and low-rank matrices playing a prominent role. When the sparse and low-rank matrices are drawn from certain natural random ensembles, we show that the sufficient conditions for exact recovery are satisfied with high probability. We conclude with simulation results on synthetic matrix decomposition problems.},
  file = {/Users/ztzhang/Zotero/storage/2FUX6SPY/Chandrasekaran et al. - 2011 - Rank-sparsity incoherence for matrix decomposition.pdf},
  journal = {SIAM Journal on Optimization},
  keywords = {Convex relaxation,L1 norm minimization,Matrix decomposition,Nuclear norm minimization,Rank,Semidefinite programming,Sparsity,Uncertainty principle},
  number = {2}
}

@article{Chang2020,
  title = {Discussion of `{{Network}} Cross-Validation by Edge Sampling'},
  author = {Chang, Jinyuan and Kolaczyk, Eric D and Yao, Qiwei},
  year = {2020},
  month = jun,
  volume = {107},
  pages = {277--280},
  issn = {0006-3444},
  doi = {10.1093/biomet/asaa017},
  journal = {Biometrika},
  keywords = {.Network cross-validation},
  number = {2}
}

@article{Charles2018,
  title = {The {{Stochastic Topic Block Model}} for the {{Clustering}} of {{Vertices}} in {{Networks}} with {{Textual Edges}}},
  author = {Charles, Bouveyron and Pierre, Latouche and Rawya, Zreik},
  year = {2018},
  month = jan,
  volume = {28},
  pages = {11--31},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-016-9713-7},
  abstract = {Due to the significant increase of communications between individuals via social media (Facebook, Twitter, Linkedin) or electronic formats (email, web, e-publication) in the past two decades, network analysis has become a unavoidable discipline. Many random graph models have been proposed to extract information from networks based on person-to-person links only, without taking into account information on the contents. This paper introduces the stochastic topic block model (STBM), a probabilistic model for networks with textual edges. We address here the problem of discovering meaningful clusters of vertices that are coherent from both the network interactions and the text contents. A classification variational expectation-maximization (C-VEM) algorithm is proposed to perform inference. Simulated data sets are considered in order to assess the proposed approach and to highlight its main features. Finally, we demonstrate the effectiveness of our methodology on two real-word data sets: a directed communication network and a undirected co-authorship network.},
  archivePrefix = {arXiv},
  eprint = {1610.02427},
  eprinttype = {arxiv},
  journal = {Statistics and Computing},
  keywords = {.Stochastic block model},
  number = {1}
}

@article{Chen2014,
  title = {Improved Graph Clustering},
  author = {Chen, Yudong and Sanghavi, Sujay and Xu, Huan},
  year = {2014},
  month = oct,
  volume = {60},
  pages = {6440--6455},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {00189448},
  doi = {10.1109/TIT.2014.2346205},
  abstract = {Graph clustering involves the task of dividing nodes into clusters, so that the edge density is higher within clusters as opposed to across clusters. A natural, classic, and popular statistical setting for evaluating solutions to this problem is the stochastic block model, also referred to as the planted partition model. In this paper, we present a new algorithm - a convexified version of maximum likelihood - for graph clustering. We show that, in the classic stochastic block model setting, it outperforms existing methods by polynomial factors when the cluster size is allowed to have general scalings. In fact, it is within logarithmic factors of known lower bounds for spectral methods, and there is evidence suggesting that no polynomial time algorithm would do significantly better. We then show that this guarantee carries over to a more general extension of the stochastic block model. Our method can handle the settings of semirandom graphs, heterogeneous degree distributions, unequal cluster sizes, unaffiliated nodes, partially observed graphs, planted clique/coloring, and so on. In particular, our results provide the best exact recovery guarantees to date for the planted partition, planted k-disjoint-cliques and planted noisy coloring models with general cluster sizes; in other settings, we match the best existing results up to logarithmic factors.},
  annotation = {\_eprint: 1210.3335},
  journal = {IEEE Transactions on Information Theory},
  keywords = {.Stochastic block model,convex optimization,Graph clustering,maximum likehood estimator},
  number = {10}
}

@article{Chen2016,
  title = {Statistical-{{Computational Tradeoffs}} in {{Planted Problems}} and {{Submatrix Localization}} with a {{Growing Number}} of {{Clusters}} and {{Submatrices}}},
  author = {Chen, Yudong and Xu, Jiaming},
  year = {2016},
  volume = {17},
  pages = {1--57},
  abstract = {We consider two closely related problems: planted clustering and submatrix localization. In the planted clustering problem, a random graph is generated based on an underlying cluster structure of the nodes; the task is to recover these clusters given the graph. The submatrix localization problem concerns locating hidden submatrices with elevated means inside a large real-valued random matrix. Of particular interest is the setting where the number of clusters/submatrices is allowed to grow unbounded with the problem size. These formulations cover several classical models such as planted clique, planted densest subgraph, planted partition, planted coloring, and the stochas-tic block model, which are widely used for studying community detection, graph clustering and bi-clustering. For both problems, we show that the space of the model parameters (cluster/submatrix size, edge probabilities and the mean of the submatrices) can be partitioned into four disjoint regions corresponding to decreasing statistical and computational complexities: (1) the impossible regime, where all algorithms fail; (2) the hard regime, where the computationally expensive Maximum Likelihood Estimator (MLE) succeeds; (3) the easy regime, where the polynomial-time convexified MLE succeeds; (4) the simple regime, where a local counting/thresholding procedure succeeds. Moreover, we show that each of these algorithms provably fails in the harder regimes. Our results establish the minimax recovery limits, which are tight up to universal constants and hold even with a growing number of clusters/submatrices, and provide order-wise stronger performance guarantees for polynomial-time algorithms than previously known. Our study demonstrates the tradeoffs between statistical and computational considerations, and suggests that the minimax limits may not be achievable by polynomial-time algorithms.},
  file = {/Users/ztzhang/Zotero/storage/77EWK4BH/Chen, Xu - 2016 - Statistical-Computational Tradeoffs in Planted Problems and Submatrix Localization with a Growing Number of Clusters a.pdf},
  journal = {Journal of Machine Learning Research},
  keywords = {bi-clustering,computational hardness,convex relaxation,graph clus-tering,minimax recovery,planted clique,planted coloring,planted partition,submatrix localization}
}

@article{Chen2018,
  ids = {chenNetworkCrossValidationDetermining2017},
  title = {Network {{Cross}}-{{Validation}} for {{Determining}} the {{Number}} of {{Communities}} in {{Network Data}}},
  author = {Chen, Kehui and Lei, Jing},
  year = {2018},
  volume = {113},
  pages = {241--251},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2016.1246365},
  abstract = {The stochastic block model (SBM) and its variants have been a popular tool for analyzing large network data with community structures. In this article, we develop an efficient network cross-validation (NCV) approach to determine the number of communities, as well as to choose between the regular stochastic block model and the degree corrected block model (DCBM). The proposed NCV method is based on a block-wise node-pair splitting technique, combined with an integrated step of community recovery using sub-blocks of the adjacency matrix. We prove that the probability of under-selection vanishes as the number of nodes increases, under mild conditions satisfied by a wide range of popular community recovery algorithms. The solid performance of our method is also demonstrated in extensive simulations and two data examples.},
  journal = {Journal of the American Statistical Association},
  keywords = {.Network cross-validation,.Stochastic block model,Block-wise node-pair splitting,Community recovery,Cross-validation,Model selection}
}

@article{Chen2020,
  title = {Analysis of {{Networks}} via the {{Sparse}} \$\textbackslash beta\$-{{Model}}},
  author = {Chen, Mingli and Kato, Kengo and Leng, Chenlei},
  year = {2020},
  month = dec,
  abstract = {Data in the form of networks are increasingly available in a variety of areas, yet statistical models allowing for parameter estimates with desirable statistical properties for sparse networks remain scarce. To address this, we propose the Sparse \$\textbackslash beta\$-Model (S\$\textbackslash beta\$M), a new network model that interpolates the celebrated Erd\textbackslash H\{o\}s-R\textbackslash 'enyi model and the \$\textbackslash beta\$-model that assigns one different parameter to each node. By a novel reparameterization of the \$\textbackslash beta\$-model to distinguish global and local parameters, our S\$\textbackslash beta\$M can drastically reduce the dimensionality of the \$\textbackslash beta\$-model by requiring some of the local parameters to be zero. We derive the asymptotic distribution of the maximum likelihood estimator of the S\$\textbackslash beta\$M when the support of the parameter vector is known. When the support is unknown, we formulate a penalized likelihood approach with the \$\textbackslash ell\_0\$-penalty. Remarkably, we show via a monotonicity lemma that the seemingly combinatorial computational problem due to the \$\textbackslash ell\_0\$-penalty can be overcome by assigning nonzero parameters to those nodes with the largest degrees. We further show that a \$\textbackslash beta\$-min condition guarantees our method to identify the true model and provide excess risk bounds for the estimated parameters. The estimation procedure enjoys good finite sample properties as shown by simulation studies. The usefulness of the S\$\textbackslash beta\$M is further illustrated via the analysis of a microfinance take-up example.},
  archivePrefix = {arXiv},
  eprint = {1908.03152},
  eprinttype = {arxiv},
  journal = {arXiv:1908.03152 [econ, math, stat]},
  keywords = {.unlabeled,Economics - Econometrics,Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {econ, math, stat}
}

@article{Chen2020a,
  ids = {chenGlobalIndividualizedCommunity2021},
  title = {Global and {{Individualized Community Detection}} in {{Inhomogeneous Multilayer Networks}}},
  author = {Chen, Shuxiao and Liu, Sifan and Ma, Zongming},
  year = {2020},
  month = dec,
  abstract = {In network applications, it has become increasingly common to obtain datasets in the form of multiple networks observed on the same set of subjects, where each network is obtained in a related but different experiment condition or application scenario. Such datasets can be modeled by multilayer networks where each layer is a separate network itself while different layers are associated and share some common information. The present paper studies community detection in a stylized yet informative inhomogeneous multilayer network model. In our model, layers are generated by different stochastic block models, the community structures of which are (random) perturbations of a common global structure while the connecting probabilities in different layers are not related. Focusing on the symmetric two block case, we establish minimax rates for both global estimation of the common structure and individualized estimation of layer-wise community structures. Both minimax rates have sharp exponents. In addition, we provide an efficient algorithm that is simultaneously asymptotic minimax optimal for both estimation tasks under mild conditions. The optimal rates depend on the parity of the number of most informative layers, a phenomenon that is caused by inhomogeneity across layers.},
  annotation = {\_eprint: 2012.00933v1},
  archivePrefix = {arXiv},
  eprint = {2012.00933},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/9BKQVVSN/Chen, Liu, Ma - 2020 - Global and Individualized Community Detection in Inhomogeneous Multilayer Networks.pdf},
  keywords = {.Multilayer networks,.Stochastic block model,integrative data analysis,minimax rate,planted partition model,Rényi divergence,spectral clustering}
}

@article{Chi2007,
  title = {Evolutionary {{Spectral Clustering}} by {{Incorporating Temporal Smoothness}} \textdagger},
  author = {Chi, Yun and Song, Xiaodan and Zhou, Dengyong and Hino, Koji and Tseng, Belle L},
  year = {2007},
  abstract = {Evolutionary clustering is an emerging research area essential to important applications such as clustering dynamic Web and blog contents and clustering data streams. In evolutionary clustering, a good clustering result should fit the current data well, while simultaneously not deviate too dramatically from the recent history. To fulfill this dual purpose , a measure of temporal smoothness is integrated in the overall measure of clustering quality. In this paper, we propose two frameworks that incorporate temporal smoothness in evolutionary spectral clustering. For both frameworks, we start with intuitions gained from the well-known k-means clustering problem, and then propose and solve corresponding cost functions for the evolutionary spectral clustering problems. Our solutions to the evolutionary spectral clustering problems provide more stable and consistent clustering results that are less sensitive to short-term noises while at the same time are adaptive to long-term cluster drifts. Furthermore, we demonstrate that our methods provide the optimal solutions to the relaxed versions of the corresponding evolutionary k-means clustering problems. Performance experiments over a number of real and synthetic data sets illustrate our evolutionary spectral clustering methods provide more robust clustering results that are not sensitive to noise and can adapt to data drifts.},
  file = {/Users/ztzhang/Zotero/storage/XSKN274V/Chi et al. - 2007 - Evolutionary Spectral Clustering by Incorporating Temporal Smoothness †.pdf},
  isbn = {9781595936097},
  keywords = {Experimentation,H28 [Database Management]: Database Applications-D,Measurement,Mining Data Streams,Preserving Cluster Membership,Preserving Cluster Quality,Temporal Smoothness,Theory * Keywords Evolutionary Spectral Clustering}
}

@article{Chi2018,
  title = {Nonconvex {{Optimization Meets Low}}-{{Rank Matrix Factorization}}: {{An Overview}}},
  author = {Chi, Yuejie and Lu, Yue M. and Chen, Yuxin},
  year = {2018},
  month = sep,
  abstract = {Substantial progress has been made recently on developing provably accurate and efficient algorithms for low-rank matrix factorization via nonconvex optimization. While conventional wisdom often takes a dim view of nonconvex optimization algorithms due to their susceptibility to spurious local minima, simple iterative methods such as gradient descent have been remarkably successful in practice. The theoretical footings, however, had been largely lacking until recently. In this tutorial-style overview, we highlight the important role of statistical models in enabling efficient nonconvex optimization with performance guarantees. We review two contrasting approaches: (1) two-stage algorithms, which consist of a tailored initialization step followed by successive refinement; and (2) global landscape analysis and initialization-free algorithms. Several canonical matrix factorization problems are discussed, including but not limited to matrix sensing, phase retrieval, matrix completion, blind deconvolution, robust principal component analysis, phase synchronization, and joint alignment. Special care is taken to illustrate the key technical insights underlying their analyses. This article serves as a testament that the integrated thinking of optimization and statistics leads to fruitful research findings.},
  annotation = {\_eprint: 1809.09573},
  file = {/Users/ztzhang/Zotero/storage/3RRA28LY/Chi, Lu, Chen - 2019 - Nonconvex Optimization Meets Low-Rank Matrix Factorization An Overview.pdf;/Users/ztzhang/Zotero/storage/62KDXZ9Y/Chi, Lu, Chen - 2018 - Nonconvex Optimization Meets Low-Rank Matrix Factorization An Overview.pdf}
}

@article{Cho2013,
  title = {Latent {{Self}}-{{Exciting Point Process Model}} for {{Spatial}}-{{Temporal Networks}}},
  author = {Cho, Yoon-Sik and Galstyan, Aram and Brantingham, P. Jeffrey and Tita, George},
  year = {2013},
  month = feb,
  doi = {10.3934/dcdsb.2014.19.1335},
  abstract = {We propose a latent self-exciting point process model that describes geographically distributed interactions between pairs of entities. In contrast to most existing approaches that assume fully observable interactions, here we consider a scenario where certain interaction events lack information about participants. Instead, this information needs to be inferred from the available observations. We develop an efficient approximate algorithm based on variational expectation-maximization to infer unknown participants in an event given the location and the time of the event. We validate the model on synthetic as well as real-world data, and obtain very promising results on the identity-inference task. We also use our model to predict the timing and participants of future events, and demonstrate that it compares favorably with baseline approaches.},
  annotation = {\_eprint: 1302.2671},
  file = {/Users/ztzhang/Zotero/storage/VMX9SIGS/Cho et al. - 2013 - Latent Self-Exciting Point Process Model for Spatial-Temporal Networks.pdf}
}

@article{Churchland2010,
  title = {Stimulus Onset Quenches Neural Variability : A Widespread Cortical Phenomenon},
  author = {Churchland, Mark M and Yu, Byron M and Cunningham, John P and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew A and Kohn, Adam and Movshon, J Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V},
  year = {2010},
  volume = {13},
  pages = {369--378},
  publisher = {{Nature Publishing Group}},
  issn = {1097-6256},
  doi = {10.1038/nn.2501},
  file = {/Users/ztzhang/Zotero/storage/F64F9AQN/Churchland et al. - 2010 - Stimulus onset quenches neural variability a widespread cortical phenomenon.pdf},
  journal = {Nature Publishing Group},
  number = {3}
}

@book{Daley,
  title = {An {{Introduction}} to the {{Theory}} of {{Point Processes}}: {{Volume I}}: {{Elementary Theory}} and {{Methods}}, {{Second Edition}}},
  author = {Daley, D J and Springer, Vere-Jones},
  file = {/Users/ztzhang/Zotero/storage/IIBJGJMN/Daley, Springer - Unknown - An Introduction to the Theory of Point Processes Volume I Elementary Theory and Methods, Second Edition.pdf;/Users/ztzhang/Zotero/storage/Y2KRAICX/Daley, Springer - Unknown - An Introduction to the Theory of Point Processes Volume I Elementary Theory and Methods, Second Edition(2).pdf}
}

@article{Diaconis2007,
  title = {Graph Limits and Exchangeable Random Graphs},
  author = {Diaconis, Persi and Janson, Svante},
  year = {2007},
  month = dec,
  abstract = {We develop a clear connection between deFinetti's theorem for exchangeable arrays (work of Aldous\textendash Hoover\textendash Kallenberg) and the emerging area of graph limits (work of Lovasz and many coauthors). Along the way, we translate the graph theory into more classical probability.},
  annotation = {\_eprint: 0712.2749},
  file = {/Users/ztzhang/Zotero/storage/B3RSGLBL/Diaconis, Janson - 2007 - Graph limits and exchangeable random graphs.pdf;/Users/ztzhang/Zotero/storage/FRN4RXW3/Diaconis, Janson - 2007 - Graph limits and exchangeable random graphs.pdf}
}

@article{Ding2020,
  title = {Efficient Random Graph Matching via Degree Profiles},
  author = {Ding, Jian and Ma, Zongming and Wu, Yihong and Xu, Jiaming},
  year = {2020},
  month = jul,
  abstract = {Random graph matching refers to recovering the underlying vertex correspondence between two random graphs with correlated edges; a prominent example is when the two random graphs are given by Erd\textbackslash H\{o\}s-R\textbackslash '\{e\}nyi graphs \$G(n,\textbackslash frac\{d\}\{n\})\$. This can be viewed as an average-case and noisy version of the graph isomorphism problem. Under this model, the maximum likelihood estimator is equivalent to solving the intractable quadratic assignment problem. This work develops an \$\textbackslash tilde\{O\}(n d\^2+n\^2)\$-time algorithm which perfectly recovers the true vertex correspondence with high probability, provided that the average degree is at least \$d = \textbackslash Omega(\textbackslash log\^2 n)\$ and the two graphs differ by at most \$\textbackslash delta = O( \textbackslash log\^\{-2\}(n) )\$ fraction of edges. For dense graphs and sparse graphs, this can be improved to \$\textbackslash delta = O( \textbackslash log\^\{-2/3\}(n) )\$ and \$\textbackslash delta = O( \textbackslash log\^\{-2\}(d) )\$ respectively, both in polynomial time. The methodology is based on appropriately chosen distance statistics of the degree profiles (empirical distribution of the degrees of neighbors). Before this work, the best known result achieves \$\textbackslash delta=O(1)\$ and \$n\^\{o(1)\} \textbackslash leq d \textbackslash leq n\^c\$ for some constant \$c\$ with an \$n\^\{O(\textbackslash log n)\}\$-time algorithm \textbackslash cite\{barak2018nearly\} and \$\textbackslash delta=\textbackslash tilde O((d/n)\^4)\$ and \$d = \textbackslash tilde\{\textbackslash Omega\}(n\^\{4/5\})\$ with a polynomial-time algorithm \textbackslash cite\{dai2018performance\}.},
  archivePrefix = {arXiv},
  eprint = {1811.07821},
  eprinttype = {arxiv},
  journal = {arXiv:1811.07821 [cs, math, stat]},
  keywords = {.Graph matching,Computer Science - Data Structures and Algorithms,Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{Dubois2013,
  ids = {duboisStochasticBlockmodelingRelational},
  title = {Stochastic Blockmodeling of Relational Event Dynamics},
  author = {Dubois, Christopher and Butts, Carter T and Smyth, Padhraic},
  year = {2013},
  volume = {31},
  abstract = {Several approaches have recently been proposed for modeling of continuous-time network data via dyadic event rates conditioned on the observed history of events and nodal or dyadic covariates. In many cases, however, interaction propensities-and even the underlying mechanisms of interaction vary systematically across subgroups whose identities are unobserved. For static networks such heterogeneity has been treated via methods such as stochastic block-modeling, which operate by assuming latent groups of individuals with similar tendencies in their group-wise interactions. Here we combine ideas from stochastic blockmod-eling and continuous-time network models by positing a latent partition of the node set such that event dynamics within and between subsets evolve in potentially distinct ways. We illustrate the use of our model family by application to several forms of dyadic interaction data, including email communication and Twitter direct messages. Parameter estimates from the fitted models clearly reveal heterogeneity in the dynamics among groups of individuals. We also find that the fitted models have better predictive accuracy than both baseline models and relational event models that lack latent structure.},
  keywords = {.Relational event data,.Stochastic block model}
}

@article{Durante,
  title = {Bayesian {{Learning}} of {{Dynamic Multilayer Networks}}},
  author = {Durante, Daniele},
  pages = {29},
  abstract = {A plethora of networks is being collected in a growing number of fields, including disease transmission, international relations, social interactions, and others. As data streams continue to grow, the complexity associated with these highly multidimensional connectivity data presents novel challenges. In this paper, we focus on the time-varying interconnections among a set of actors in multiple contexts, called layers. Current literature lacks flexible statistical models for dynamic multilayer networks, which can enhance quality in inference and prediction by efficiently borrowing information within each network, across time, and between layers. Motivated by this gap, we develop a Bayesian nonparametric model leveraging latent space representations. Our formulation characterizes the edge probabilities as a function of shared and layer-specific actors positions in a latent space, with these positions changing in time via Gaussian processes. This representation facilitates dimensionality reduction and incorporates different sources of information in the observed data. In addition, we obtain tractable procedures for posterior computation, inference, and prediction. We provide theoretical results on the flexibility of our model. Our methods are tested on simulations and infection studies monitoring dynamic face-to-face contacts among individuals in multiple days, where we perform better than current methods in inference and prediction.},
  file = {/Users/ztzhang/Zotero/storage/TFW4JV3C/Durante - Bayesian Learning of Dynamic Multilayer Networks.pdf},
  keywords = {.Multilayer networks},
  language = {en}
}

@article{Durrett2010,
  title = {Probability: {{Theory}} and {{Examples Rick Durrett January}} 29, 2010},
  author = {Durrett, Rick},
  year = {2010},
  volume = {49},
  pages = {497},
  issn = {0006341X},
  doi = {10.2307/2532227},
  abstract = {A useful reference for those who apply probability to work, PROBABILITY: THEORY AND EXAMPLES focuses attention on examples and results while developing theory.},
  file = {/Users/ztzhang/Zotero/storage/TXTF7KL4/Durrett - 2010 - Probability Theory and Examples Rick Durrett January 29, 2010.pdf},
  isbn = {0534424414},
  journal = {Biometrics},
  number = {3},
  pmid = {16156020}
}

@article{Economics2019,
  title = {References for {{STA}} 251 ( {{Spring}} 2019 )},
  author = {Economics, Financial and {Associa-}, American Statistical and Sigkdd, A C M and Conference, International and Discovery, Knowledge and Mining, Data},
  year = {2019},
  volume = {251},
  pages = {1--7},
  number = {Spring}
}

@article{Edelman1998,
  title = {The Geometry of Algorithms with Orthogonality Constraints},
  author = {Edelman, Alan and Arias, TOM{\'A}S A. and Smith, Steven T.},
  year = {1998},
  volume = {20},
  pages = {303--353},
  publisher = {{Society for Industrial and Applied Mathematics Publications}},
  issn = {08954798},
  doi = {10.1137/S0895479895290954},
  abstract = {In this paper we develop new Newton and conjugate gradient algorithms on the Grassmann and Stiefel manifolds. These manifolds represent the constraints that arise in such areas as the symmetric eigenvalue problem, nonlinear eigenvalue problems, electronic structures computations, and signal processing. In addition to the new algorithms, we show how the geometrical framework gives penetrating new insights allowing us to create, understand, and compare algorithms. The theory proposed here provides a taxonomy for numerical linear algebra algorithms that provide a top level mathematical view of previously unrelated algorithms. It is our hope that developers of new algorithms and perturbation theories will benefit from the theory, methods, and examples in this paper.},
  file = {/Users/ztzhang/Zotero/storage/A9HXIMLS/Edelman, Arias, Smith - 1998 - The geometry of algorithms with orthogonality constraints.pdf},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  keywords = {Conjugate gradient,Eigenvalue optimization,Eigenvalues and eigenvectors,Grassmann manifold,Invariant subspace,Newton's method,Orthogonality constraints,Rayleigh quotient iteration,Sequential quadratic programming,Stiefel manifold},
  number = {2}
}

@techreport{Erd,
  title = {{{ON THE EVOLUTION OF RANDOM GRAPHS}}},
  author = {Erd\&, P and Rbnyi, A}
}

@article{Fan2012,
  title = {Hoeffding's Inequality for Supermartingales},
  author = {Fan, Xiequan and Grama, Ion and Liu, Quansheng},
  year = {2012},
  month = jul,
  abstract = {We give an extension of Hoeffding's inequality to the case of supermartingales with differences bounded from above. Our inequality strengthens or extends the inequalities of Freedman, Bernstein, Prohorov, Bennett and Nagaev.},
  archivePrefix = {arXiv},
  eprint = {1109.4359},
  eprinttype = {arxiv},
  journal = {arXiv:1109.4359 [math]},
  keywords = {.Inequality,.Martingale,.Point processes,.Stochastic process,60G42; 60G40; 60F10 (Primary) 60E15; 60G50 (Secondary),Mathematics - Probability},
  primaryClass = {math}
}

@article{Fan2015,
  title = {Exponential Inequalities for Martingales with Applications},
  author = {Fan, Xiequan and Grama, Ion and Liu, Quansheng},
  year = {2015},
  volume = {20},
  publisher = {{The Institute of Mathematical Statistics and the Bernoulli Society}},
  issn = {1083-6489},
  doi = {10.1214/EJP.v20-3496},
  abstract = {The paper is devoted to establishing some general exponential inequalities for supermartingales. The inequalities improve or generalize many exponential inequalities of Bennett, Freedman, de la Pe\~na, Pinelis and van de Geer. Moreover, our concentration inequalities also improve some known inequalities for sums of independent random variables. Applications associated with linear regressions, autoregressive processes and branching processes are also provided.},
  journal = {Electronic Journal of Probability},
  keywords = {.Inequality,.Martingale,.Point processes,.Stochastic process,.Super martingale,autoregressive processes,Bernstein's inequality,changes of probability measure,De la Pena's inequality,exponential inequality,Freedman's inequality,linear regressions,martingales,Pinelis' inequality},
  language = {EN},
  mrnumber = {MR3311214},
  zmnumber = {1320.60058}
}

@article{Fan2020,
  title = {{{RANK}}: {{Large}}-{{Scale Inference With Graphical Nonlinear Knockoffs}}},
  shorttitle = {{{RANK}}},
  author = {Fan, Yingying and Demirkaya, Emre and Li, Gaorong and Lv, Jinchi},
  year = {2020},
  month = jan,
  volume = {115},
  pages = {362--379},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2018.1546589},
  abstract = {Power and reproducibility are key to enabling refined scientific discoveries in contemporary big data applications with general high-dimensional nonlinear models. In this article, we provide theoretical foundations on the power and robustness for the model-X knockoffs procedure introduced recently in Cand\`es, Fan, Janson and Lv in high-dimensional setting when the covariate distribution is characterized by Gaussian graphical model. We establish that under mild regularity conditions, the power of the oracle knockoffs procedure with known covariate distribution in high-dimensional linear models is asymptotically one as sample size goes to infinity. When moving away from the ideal case, we suggest the modified model-X knockoffs method called graphical nonlinear knockoffs (RANK) to accommodate the unknown covariate distribution. We provide theoretical justifications on the robustness of our modified procedure by showing that the false discovery rate (FDR) is asymptotically controlled at the target level and the power is asymptotically one with the estimated covariate distribution. To the best of our knowledge, this is the first formal theoretical result on the power for the knockoffs procedure. Simulation results demonstrate that compared to existing approaches, our method performs competitively in both FDR control and power. A real dataset is analyzed to further assess the performance of the suggested knockoffs procedure. Supplementary materials for this article are available online.},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2018.1546589},
  journal = {Journal of the American Statistical Association},
  keywords = {.unlabeled,Big data,Graphical nonlinear knockoffs,High-dimensional nonlinear models,Large-scale inference and FDR,Power,Reproducibility,Robustness},
  number = {529},
  pmid = {32742045}
}

@article{Fienberg2006,
  title = {An {{Exponential Family}} of {{Probability Distributions}} for {{Directed Graphs}}: {{Comment}}},
  author = {Fienberg, Stephen E. and Wasserman, Stanley},
  year = {2006},
  month = may,
  volume = {76},
  pages = {54},
  publisher = {{JSTOR}},
  issn = {01621459},
  doi = {10.2307/2287039},
  file = {/Users/ztzhang/Zotero/storage/QDDIFPD2/Fienberg, Wasserman - 2006 - An Exponential Family of Probability Distributions for Directed Graphs Comment.pdf},
  journal = {Journal of the American Statistical Association},
  number = {373}
}

@book{Fortunato2010,
  title = {Community Detection in Graphs},
  author = {Fortunato, Santo},
  year = {2010},
  month = feb,
  volume = {486},
  issn = {03701573},
  doi = {10.1016/j.physrep.2009.11.002},
  abstract = {The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks. \textcopyright{} 2009 Elsevier B.V.},
  annotation = {\_eprint: 0906.0612},
  file = {/Users/ztzhang/Zotero/storage/6LNKU3TR/Fortunato - 2010 - Community detection in graphs.pdf},
  journal = {Physics Reports},
  keywords = {Clusters,Graphs,Statistical physics}
}

@article{Fox2016,
  title = {Modeling {{E}}-Mail {{Networks}} and {{Inferring Leadership Using Self}}-{{Exciting Point Processes}}},
  author = {Fox, Eric W. and Short, Martin B. and Schoenberg, Frederic P. and Coronges, Kathryn D. and Bertozzi, Andrea L.},
  year = {2016},
  month = apr,
  volume = {111},
  pages = {564--584},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2015.1135802},
  abstract = {We propose various self-exciting point process models for the times when e-mails are sent between individuals in a social network. Using an EM-type approach, we fit these models to an e-mail network dataset from West Point Military Academy and the Enron e-mail dataset. We argue that the self-exciting models adequately capture major temporal clustering features in the data and perform better than traditional stationary Poisson models. We also investigate how accounting for diurnal and weekly trends in e-mail activity improves the overall fit to the observed network data. A motivation and application for fitting these self-exciting models is to use parameter estimates to characterize important e-mail communication behaviors such as the baseline sending rates, average reply rates, and average response times. A primary goal is to use these features, estimated from the self-exciting models, to infer the underlying leadership status of users in the West Point and Enron networks.},
  journal = {Journal of the American Statistical Association},
  keywords = {.Point processes},
  language = {en},
  number = {514}
}

@article{Frank1986,
  title = {Markov Graphs},
  author = {Frank, Ove and Strauss, David},
  year = {1986},
  volume = {81},
  pages = {832--842},
  issn = {1537274X},
  doi = {10.1080/01621459.1986.10478342},
  abstract = {Log-linear statistical models are used to characterize ran- dom graphs with general dependence structure and with Markov dependence. Sufficient statistics for Markov graphs are shown to be given by counts of various triangles and stars. Inparticular, we show under which assumptions the triad counts are sufficient statistics. We discuss inference methodology for some simple Markov graphs.},
  journal = {Journal of the American Statistical Association},
  keywords = {Graph inference,Log-linear network model,Markov field},
  number = {395}
}

@article{Friedman2008,
  title = {Sparse Inverse Covariance Estimation with the Graphical Lasso},
  author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  year = {2008},
  month = jul,
  volume = {9},
  pages = {432--441},
  issn = {14654644},
  doi = {10.1093/biostatistics/kxm045},
  abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm that is remarkably fast: in the worst cases, it solves a 1000 node problem (\$\textbackslash sim\$500,000 parameters) in about a minute, and is 50 to 2000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinhausen and Buhlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
  file = {/Users/ztzhang/Zotero/storage/6CANV8WH/Friedman, Hastie, Tibshirani - 2008 - Sparse inverse covariance estimation with the graphical lasso.pdf},
  journal = {Biostatistics},
  keywords = {Gaussian covariance,Graphical model,L1,Lasso},
  number = {3}
}

@inproceedings{Fu2009,
  title = {Dynamic Mixed Membership Blockmodel for Evolving Networks},
  booktitle = {Proceedings of the 26th {{Annual International Conference}} on {{Machine Learning}}},
  author = {Fu, Wenjie and Song, Le and Xing, Eric P.},
  year = {2009},
  month = jun,
  pages = {329--336},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1553374.1553416},
  abstract = {In a dynamic social or biological environment, interactions between the underlying actors can undergo large and systematic changes. Each actor can assume multiple roles and their degrees of affiliation to these roles can also exhibit rich temporal phenomena. We propose a state space mixed membership stochastic blockmodel which can track across time the evolving roles of the actors. We also derive an efficient variational inference procedure for our model, and apply it to the Enron email networks, and rewiring gene regulatory networks of yeast. In both cases, our model reveals interesting dynamical roles of the actors.},
  isbn = {978-1-60558-516-1},
  keywords = {.Stochastic block model},
  series = {{{ICML}} '09}
}

@article{Gadat2020,
  title = {Asymptotic Study of Stochastic Adaptive Algorithm in Non-Convex Landscape},
  author = {Gadat, S{\'e}bastien and Gavra, Ioana},
  year = {2020},
  month = dec,
  abstract = {This paper studies some asymptotic properties of adaptive algorithms widely used in optimization and machine learning, and among them Adagrad and Rmsprop, which are involved in most of the blackbox deep learning algorithms. Our setup is the non-convex landscape optimization point of view, we consider a one time scale parametrization and we consider the situation where these algorithms may be used or not with mini-batches. We adopt the point of view of stochastic algorithms and establish the almost sure convergence of these methods when using a decreasing step-size point of view towards the set of critical points of the target function. With a mild extra assumption on the noise, we also obtain the convergence towards the set of minimizer of the function. Along our study, we also obtain a "convergence rate" of the methods, in the vein of the works of \textbackslash cite\{GhadimiLan\}.},
  archivePrefix = {arXiv},
  eprint = {2012.05640},
  eprinttype = {arxiv},
  journal = {arXiv:2012.05640 [cs, math, stat]},
  keywords = {.unlabeled,Computer Science - Machine Learning,Mathematics - Probability,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{Gamboa2007,
  title = {Semi-Parametric Estimation of Shifts},
  author = {Gamboa, Fabrice and Loubes, Jean-Michel and Maza, Elie},
  year = {2007},
  volume = {1},
  pages = {616--640},
  doi = {10.1214/07-EJS026},
  abstract = {We observe a large number of functions differing from each other only by a translation parameter. While the main pattern is unknown, we propose to estimate the shift parameters using M-estimators. Fourier transform enables to transform this statistical problem into a semi-parametric framework. We study the convergence of the estimator and provide its asymptotic behavior. Moreover, we use the method in the applied case of velocity curve forecasting.},
  annotation = {\_eprint: 0712.1936v1},
  file = {/Users/ztzhang/Zotero/storage/3IAUVT4Z/Gamboa, Loubes, Maza - 2007 - Semi-parametric estimation of shifts.pdf},
  journal = {Electronic Journal of Statistics},
  keywords = {AMS 2000 subject classifications: Primary 60G17,Empirical process,Fourier transform,M-estimation,s}
}

@article{Gao2015,
  ids = {gaoRateoptimalGraphonEstimation2015a},
  title = {Rate-Optimal Graphon Estimation},
  author = {Gao, Chao and Lu, Yu and Zhou, Harrison H.},
  year = {2015},
  month = dec,
  volume = {43},
  pages = {2624--2652},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {00905364},
  doi = {10.1214/15-AOS1354},
  abstract = {Network analysis is becoming one of the most active research areas in statistics. Significant advances have been made recently on developing theories, methodologies and algorithms for analyzing networks. However, there has been little fundamental study on optimal estimation. In this paper, we establish optimal rate of convergence for graphon estimation. For the stochastic block model with k clusters , we show that the optimal rate under the mean squared error is n -1 log k + k 2 /n 2. The minimax upper bound improves the existing results in literature through a technique of solving a quadratic equation. When k {$\leq$} {$\surd$} n log n, as the number of the cluster k grows, the minimax rate grows slowly with only a logarithmic order n -1 log k. A key step to establish the lower bound is to construct a novel subset of the parameter space and then apply Fano's lemma, from which we see a clear distinction of the nonparametric graphon estimation problem from classical nonparametric regression, due to the lack of identifia-bility of the order of nodes in exchangeable random graph models. As an immediate application, we consider nonparametric graphon estimation in a H\"older class with smoothness {$\alpha$}. When the smoothness {$\alpha$} {$\geq$} 1, the optimal rate of convergence is n -1 log n, independent of {$\alpha$}, while for {$\alpha$} {$\in$} (0, 1), the rate is n -2{$\alpha$}/({$\alpha$}+1) , which is, to our surprise, identical to the classical nonparametric rate.},
  annotation = {\_eprint: 1410.5837v3},
  file = {/Users/ztzhang/Zotero/storage/2EIVDADE/Gao, Lu, Zhou - 2015 - RATE-OPTIMAL GRAPHON ESTIMATION(3).pdf},
  journal = {The Annals of Statistics},
  keywords = {.Stochastic block model,60G05,graphon,Graphon,minimax rate,Minimax rate,Network,nonparametric regression,Nonparametric regression},
  mrnumber = {MR3405606},
  number = {6},
  zmnumber = {1332.60050}
}

@article{Gao2016,
  title = {Optimal {{Estimation}} and {{Completion}} of {{Matrices}} with {{Biclustering Structures}}},
  author = {Gao, Chao and Lu, Yu and Ma, Zongming and Zhou, Harrison H},
  year = {2016},
  volume = {17},
  pages = {1--29},
  abstract = {Biclustering structures in data matrices were first formalized in a seminal paper by John Hartigan (Hartigan, 1972) where one seeks to cluster cases and variables simultaneously. Such structures are also prevalent in block modeling of networks. In this paper, we develop a theory for the estimation and completion of matrices with biclustering structures, where the data is a partially observed and noise contaminated matrix with a certain underlying biclustering structure. In particular, we show that a constrained least squares estimator achieves minimax rate-optimal performance in several of the most important scenarios. To this end, we derive unified high probability upper bounds for all sub-Gaussian data and also provide matching minimax lower bounds in both Gaussian and binary cases. Due to the close connection of graphon to stochastic block models, an immediate consequence of our general results is a minimax rate-optimal estimator for sparse graphons.},
  file = {/Users/ztzhang/Zotero/storage/S6U6WE8I/Gao et al. - 2016 - Optimal Estimation and Completion of Matrices with Biclustering Structures.pdf},
  journal = {Journal of Machine Learning Research},
  keywords = {.Stochastic block model,Biclustering,graphon,matrix completion,missing data,sparse network}
}

@article{Gao2017,
  title = {Testing for {{Global Network Structure Using Small Subgraph Statistics}}},
  author = {Gao, Chao and Lafferty, John},
  year = {2017},
  month = oct,
  abstract = {We study the problem of testing for community structure in networks using relations between the observed frequencies of small subgraphs. We propose a simple test for the existence of communities based only on the frequencies of three-node subgraphs. The test statistic is shown to be asymptotically normal under a null assumption of no community structure, and to have power approaching one under a composite alternative hypothesis of a degree-corrected stochastic block model. We also derive a version of the test that applies to multivariate Gaussian data. Our approach achieves near-optimal detection rates for the presence of community structure, in regimes where the signal-to-noise is too weak to explicitly estimate the communities themselves, using existing computationally efficient algorithms. We demonstrate how the method can be effective for detecting structure in social networks, citation networks for scientific articles, and correlations of stock returns between companies on the S\textbackslash\&P 500.},
  archivePrefix = {arXiv},
  eprint = {1710.00862},
  eprinttype = {arxiv},
  journal = {arXiv:1710.00862 [cs, math, stat]},
  keywords = {.Network structure testing},
  primaryClass = {cs, math, stat}
}

@article{Gao2017a,
  title = {Achieving {{Optimal Misclassification Proportion}} in {{Stochastic Block Models}}},
  author = {Gao, Chao and Ma, Zongming and Zhang, Anderson Y and Zhou, Harrison H},
  year = {2017},
  volume = {18},
  pages = {1--45},
  abstract = {Community detection is a fundamental statistical problem in network data analysis. In this paper, we present a polynomial time two-stage method that provably achieves optimal statistical performance in misclassification proportion for stochastic block model under weak regularity conditions. Our two-stage procedure consists of a refinement stage motivated by penalized local maximum likelihood estimation. This stage can take a wide range of weakly consistent community detection procedures as its initializer, to which it applies and outputs a community assignment that achieves optimal misclassification proportion with high probability. The theoretical property is confirmed by simulated examples.},
  file = {/Users/ztzhang/Zotero/storage/BGPWTJ9X/Gao et al. - 2017 - Achieving Optimal Misclassification Proportion in Stochastic Block Models.pdf},
  journal = {Journal of Machine Learning Research},
  keywords = {Clustering,Community detection,Minimax rates,Network analysis,Spectral clustering}
}

@article{Gao2018,
  ids = {gaoMinimaxRatesNetwork2019},
  title = {Minimax {{Rates}} in {{Network Analysis}}: {{Graphon Estimation}}, {{Community Detection}} and {{Hypothesis Testing}}},
  author = {Gao, Chao and Ma, Zongming},
  year = {2018},
  month = nov,
  abstract = {This paper surveys some recent developments in fundamental limits and optimal algorithms for network analysis. We focus on minimax optimal rates in three fundamental problems of network analysis: graphon estimation, community detection, and hypothesis testing. For each problem, we review state-of-the-art results in the literature followed by general principles behind the optimal procedures that lead to minimax estimation and testing. This allows us to connect problems in network analysis to other statistical inference problems from a general perspective.},
  annotation = {\_eprint: 1811.06055},
  archivePrefix = {arXiv},
  eprint = {1811.06055},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/4UC2LTLX/Gao, Ma - 2018 - Minimax Rates in Network Analysis Graphon Estimation, Community Detection and Hypothesis Testing.pdf},
  journal = {arXiv:1811.06055},
  keywords = {.Community detection,.Graphon,.Hypothesis testing,.Minimax,Computer Science - Social and Information Networks,Mathematics - Statistics Theory,Statistics - Machine Learning}
}

@article{Gao2020,
  title = {Discussion of `{{Network}} Cross-Validation by Edge Sampling'},
  author = {Gao, Chao and Ma, Zongming},
  year = {2020},
  month = jun,
  volume = {107},
  pages = {281--284},
  issn = {0006-3444},
  doi = {10.1093/biomet/asaa022},
  journal = {Biometrika},
  keywords = {.Network cross-validation},
  number = {2}
}

@article{Gelman2021,
  title = {What Are the Most Important Statistical Ideas of the Past 50 Years?},
  author = {Gelman, Andrew and Vehtari, Aki},
  year = {2021},
  month = jan,
  abstract = {We argue that the most important statistical ideas of the past half century are: counterfactual causal inference, bootstrapping and simulation-based inference, overparameterized models and regularization, multilevel models, generic computation algorithms, adaptive decision analysis, robust inference, and exploratory data analysis. We discuss common features of these ideas, how they relate to modern computing and big data, and how they might be developed and extended in future decades. The goal of this article is to provoke thought and discussion regarding the larger themes of research in statistics and data science.},
  archivePrefix = {arXiv},
  eprint = {2012.00174},
  eprinttype = {arxiv},
  journal = {arXiv:2012.00174 [stat]},
  keywords = {.unlabeled,Statistics - Methodology},
  primaryClass = {stat}
}

@article{Gervini2005,
  title = {Nonparametric Maximum Likelihood Estimation of the Structural Mean of a Sample of Curves},
  author = {Gervini, Daniel and Gasser, Theo},
  year = {2005},
  month = dec,
  volume = {92},
  pages = {801--820},
  issn = {00063444},
  doi = {10.1093/biomet/92.4.801},
  abstract = {A random sample of curves can be usually thought of as noisy realisations of a compound stochastic process X(t) = ZW(t), where Z(t) produces random amplitude variation and W(t) produces random dynamic or phase variation. In most applications it is more important to estimate the so-called structural mean {$\mu$}(t) = EZ(t) than the crosssectional mean EX(t), but this estimation problem is difficult because the process Z(t) is not directly observable. In this paper we propose a nonparametric maximum likelihood estimator of {$\mu$}(t). This estimator is shown to be {$\surd$}n-consistent and asymptotically normal under the assumed model and robust to model misspecification. Simulations and a realdata example show that the proposed estimator is competitive with landmark registration, often considered the benchmark, and has the advantage of avoiding time-consuming and often infeasible individual landmark identification. \textcopyright{} 2005 Biometrika Trust.},
  file = {/Users/ztzhang/Zotero/storage/6M7QKRDF/Gervini, Gasser - 2005 - Nonparametric maximum likelihood estimation of the structural mean of a sample of curves.pdf},
  journal = {Biometrika},
  keywords = {Curve registration,Functional data,Longitudinal data,Phase variation,Time warping},
  number = {4}
}

@article{Ginestet2017,
  title = {{{HYPOTHESIS TESTING FOR NETWORK DATA IN FUNCTIONAL NEUROIMAGING}}},
  author = {Ginestet, Cedric E and Li, Jun and Balachandran, Prakash and Rosenberg, Steven and Kolaczyk {\textdagger}, Eric D},
  year = {2017},
  volume = {11},
  pages = {725--750},
  doi = {10.1214/16-AOAS1015},
  abstract = {In recent years, it has become common practice in neuroscience to use networks to summarize relational information in a set of measurements, typically assumed to be reflective of either functional or structural relationships between regions of interest in the brain. One of the most basic tasks of interest in the analysis of such data is the testing of hypotheses, in answer to questions such as "Is there a difference between the networks of these two groups of subjects?" In the classical setting, where the unit of interest is a scalar or a vector, such questions are answered through the use of familiar two-sample testing strategies. Networks, however, are not Euclidean objects, and hence classical methods do not directly apply. We address this challenge by drawing on concepts and techniques from geometry and high-dimensional statistical inference. Our work is based on a precise geometric characterization of the space of graph Laplacian matrices and a nonparametric notion of averaging due to Fr\'echet. We motivate and illustrate our resulting method-ologies for testing in the context of networks derived from functional neu-roimaging data on human subjects from the 1000 Functional Connectomes Project. In particular, we show that this global test is more statistically powerful than a mass-univariate approach. In addition, we have also provided a method for visualizing the individual contribution of each edge to the overall test statistic.},
  journal = {The Annals of Applied Statistics},
  keywords = {fMRI,Frechet mean,graph Laplacian,hypothesis testing,matrix manifold,network data,object data},
  number = {2}
}

@techreport{Girvan,
  title = {Community Structure in Social and Biological Networks},
  author = {Girvan, M and Newman, M E J},
  abstract = {A number of recent studies have focused on the statistical properties of networked systems such as social networks and the Worldwide Web. Researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. We propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well known-a collaboration network and a food web-and find that it detects significant and informative community divisions in both cases.},
  file = {/Users/ztzhang/Zotero/storage/DHTV2K78/Girvan, Newman - Unknown - Community structure in social and biological networks.pdf}
}

@article{Goldenberg2010,
  title = {A {{Survey}} of {{Statistical Network Models}}},
  author = {Goldenberg, Anna and Zheng, Alice X. and Fienberg, Stephen E. and Airoldi, Edoardo M.},
  year = {2010},
  month = feb,
  volume = {2},
  pages = {129--233},
  publisher = {{Now Publishers, Inc.}},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000005},
  abstract = {A Survey of Statistical Network Models},
  file = {/Users/ztzhang/Zotero/storage/9Q49ANFV/Goldenberg et al. - 2010 - A Survey of Statistical Network Models.pdf},
  journal = {Foundations and Trends\textregistered{} in Machine Learning},
  language = {English},
  number = {2}
}

@article{Gomez-Rodriguez2012,
  title = {Inferring {{Networks}} of {{Diffusion}} and {{Influence}}},
  author = {{Gomez-Rodriguez}, Manuel and Leskovec, Jure and Krause, Andreas},
  year = {2012},
  month = feb,
  volume = {5},
  pages = {1--37},
  issn = {15564681},
  doi = {10.1145/2086737.2086741},
  abstract = {Information diffusion and virus propagation are fundamental processes taking place in networks. While it is often possible to directly observe when nodes become infected with a virus or adopt the information, observing individual transmissions (i.e., who infects whom, or who influences whom) is typically very difficult. Furthermore, in many applications, the underlying network over which the diffusions and propagations spread is actually unobserved. We tackle these challenges by developing a method for tracing paths of diffusion and influence through networks and inferring the networks over which contagions propagate. Given the times when nodes adopt pieces of information or become infected, we identify the optimal network that best explains the observed infection times. Since the optimization problem is NP-hard to solve exactly, we develop an efficient approximation algorithm that scales to large datasets and finds provably near-optimal networks. We demonstrate the effectiveness of our approach by tracing information diffusion in a set of 170 million blogs and news articles over a one year period to infer how information flows through the online media space. We find that the diffusion network of news for the top 1,000 media sites and blogs tends to have a core-periphery structure with a small set of core media sites that diffuse information to the rest of the Web. These sites tend to have stable circles of influence with more general news media sites acting as connectors between them.},
  file = {/Users/ztzhang/Zotero/storage/TAESZUP5/Gomez-Rodriguez, Leskovec, Krause - 2012 - Inferring Networks of Diffusion and Influence.pdf},
  journal = {ACM Transactions on Knowledge Discovery from Data},
  number = {4}
}

@article{Greene2010,
  title = {Tracking the {{Evolution}} of {{Communities}} in {{Dynamic Social Networks}}},
  author = {Greene, Derek and Doyle, D{\'o}nal and Cunningham, P{\'a}draig},
  year = {2010},
  month = aug,
  pages = {176--183},
  publisher = {{IEEE}},
  doi = {10.1109/ASONAM.2010.17},
  file = {/Users/ztzhang/Zotero/storage/4CBEHSWR/Greene, Doyle, Cunningham - 2010 - Tracking the Evolution of Communities in Dynamic Social Networks.pdf},
  isbn = {978-1-4244-7787-6},
  journal = {2010 International Conference on Advances in Social Networks Analysis and Mining}
}

@article{Gursoy2020,
  title = {Extracting the Signed Backbone of Intrinsically Dense Weighted Networks},
  author = {Gursoy, Furkan and Badur, Bertan},
  year = {2020},
  month = dec,
  abstract = {Networks provide useful tools for analyzing diverse complex systems from natural, social, and technological domains. Growing size and variety of data such as more nodes and links and associated weights, directions, and signs can provide accessory information. Link and weight abundance, on the other hand, results in denser networks with noisy, insignificant, or otherwise redundant data. Moreover, typical network analysis and visualization techniques presuppose sparsity and are not appropriate or scalable for dense and weighted networks. As a remedy, network backbone extraction methods aim to retain only the important links while preserving the useful and elucidative structure of the original networks for further analyses. Here, we provide the first methods for extracting signed network backbones from intrinsically dense unsigned weighted networks. Utilizing a null model based on statistical techniques, the proposed significance filter and vigor filter allow inferring edge signs. Empirical analysis on migration, voting, temporal interaction, and species similarity networks reveals that the proposed filters extract meaningful and sparse signed backbones while preserving the multiscale nature of the network. The resulting backbones exhibit characteristics typically associated with signed networks such as reciprocity, structural balance, and community structure.},
  archivePrefix = {arXiv},
  eprint = {2012.05216},
  eprinttype = {arxiv},
  journal = {arXiv:2012.05216 [physics, stat]},
  keywords = {.unlabeled,Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Applications},
  primaryClass = {physics, stat}
}

@article{Hainmueller2018,
  title = {Parallel Emergence of Stable and Dynamic Memory Engrams in the Hippocampus},
  author = {Hainmueller, Thomas and Bartos, Marlene},
  year = {2018}
}

@article{Hallac2017,
  title = {Network {{Inference}} via the {{Time}}-{{Varying Graphical Lasso}}},
  author = {Hallac, David and Park, Youngsuk and Boyd, Stephen and Leskovec, Jure},
  year = {2017},
  month = jun,
  abstract = {Many important problems can be modeled as a system of interconnected entities, where each entity is recording time-dependent observations or measurements. In order to spot trends, detect anomalies, and interpret the temporal dynamics of such data, it is essential to understand the relationships between the different entities and how these relationships evolve over time. In this paper, we introduce the time-varying graphical lasso (TVGL), a method of inferring time-varying networks from raw time series data. We cast the problem in terms of estimating a sparse time-varying inverse covariance matrix, which reveals a dynamic network of interdependencies between the entities. Since dynamic network inference is a computationally expensive task, we derive a scalable message-passing algorithm based on the Alternating Direction Method of Multipliers (ADMM) to solve this problem in an efficient way. We also discuss several extensions, including a streaming algorithm to update the model and incorporate new observations in real time. Finally, we evaluate our TVGL algorithm on both real and synthetic datasets, obtaining interpretable results and outperforming state-of-the-art baselines in terms of both accuracy and scalability.},
  archivePrefix = {arXiv},
  eprint = {1703.01958},
  eprinttype = {arxiv},
  journal = {arXiv:1703.01958 [cs, math]},
  keywords = {.Graphical lasso,.Network inference,.TIme varying graphical lasso,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{Hallgren2021,
  title = {Changepoint Detection on a Graph of Time Series},
  author = {Hallgren, Karl L. and Heard, Nicholas A. and Turcotte, Melissa J. M.},
  year = {2021},
  month = feb,
  abstract = {When analysing multiple time series that may be subject to changepoints, it is sometimes possible to specify a priori, by means of a graph G, which pairs of time series are likely to be impacted by simultaneous changepoints. This article proposes a novel Bayesian changepoint model for multiple time series that borrows strength across clusters of connected time series in G to detect weak signals for synchronous changepoints. The graphical changepoint model is further extended to allow dependence between nearby but not necessarily synchronous changepoints across neighbour time series in G. A novel reversible jump MCMC algorithm making use of auxiliary variables is proposed to sample from the graphical changepoint model. The merit of the proposed model is demonstrated via a changepoint analysis of real network authentication data from Los Alamos National Laboratory (LANL), with some success at detecting weak signals for network intrusions across users that are linked by network connectivity, whilst limiting the number of false alerts.},
  archivePrefix = {arXiv},
  eprint = {2102.04112},
  eprinttype = {arxiv},
  journal = {arXiv:2102.04112 [stat]},
  keywords = {62-09,Statistics - Methodology},
  primaryClass = {stat}
}

@article{Han,
  ids = {hanConsistentEstimationDynamica},
  title = {Consistent Estimation of Dynamic and Multi-Layer Block Models},
  author = {Han, Qiuyi and Xu, Kevin S and Airoldi, Edoardo M},
  abstract = {Significant progress has been made recently on theoretical analysis of estimators for the stochas-tic block model (SBM). In this paper, we consider the multi-graph SBM, which serves as a foundation for many application settings including dynamic and multi-layer networks. We explore the asymptotic properties of two estima-tors for the multi-graph SBM, namely spectral clustering and the maximum-likelihood estimate (MLE), as the number of layers of the multi-graph increases. We derive sufficient conditions for consistency of both estimators and propose a variational approximation to the MLE that is computationally feasible for large networks. We verify the sufficient conditions via simulation and demonstrate that they are practical. In addition , we apply the model to two real data sets: a dynamic social network and a multi-layer social network with several types of relations.},
  file = {/Users/ztzhang/Zotero/storage/578CS974/Han et al. - Consistent estimation of dynamic and multi-layer b.pdf},
  keywords = {.Multilayer networks}
}

@article{Han2020,
  title = {Exact {{Clustering}} in {{Tensor Block Model}}: {{Statistical Optimality}} and {{Computational Limit}}},
  shorttitle = {Exact {{Clustering}} in {{Tensor Block Model}}},
  author = {Han, Rungang and Luo, Yuetian and Wang, Miaoyan and Zhang, Anru R.},
  year = {2020},
  month = dec,
  abstract = {High-order clustering aims to identify heterogeneous substructure in multiway dataset that arises commonly in neuroimaging, genomics, and social network studies. The non-convex and discontinuous nature of the problem poses significant challenges in both statistics and computation. In this paper, we propose a tensor block model and the computationally efficient methods, \textbackslash emph\{high-order Lloyd algorithm\} (HLloyd) and \textbackslash emph\{high-order spectral clustering\} (HSC), for high-order clustering in tensor block model. The convergence of the proposed procedure is established, and we show that our method achieves exact clustering under reasonable assumptions. We also give the complete characterization for the statistical-computational trade-off in high-order clustering based on three different signal-to-noise ratio regimes. Finally, we show the merits of the proposed procedures via extensive experiments on both synthetic and real datasets.},
  archivePrefix = {arXiv},
  eprint = {2012.09996},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/V65IBABF/Han et al. - 2020 - Exact Clustering in Tensor Block Model Statistica.pdf},
  journal = {arXiv:2012.09996 [math, stat]},
  keywords = {Tensor block model},
  primaryClass = {math, stat}
}

@article{Han2020a,
  title = {Universal {{Rank Inference}} via {{Residual Subsampling}} with {{Application}} to {{Large Networks}}},
  author = {Han, Xiao and Yang, Qing and Fan, Yingying},
  year = {2020},
  month = jul,
  abstract = {Determining the precise rank is an important problem in many large-scale applications with matrix data exploiting low-rank plus noise models. In this paper, we suggest a universal approach to rank inference via residual subsampling (RIRS) for testing and estimating rank in a wide family of models, including many popularly used network models such as the degree corrected mixed membership model as a special case. Our procedure constructs a test statistic via subsampling entries of the residual matrix after extracting the spiked components. The test statistic converges in distribution to the standard normal under the null hypothesis, and diverges to infinity with asymptotic probability one under the alternative hypothesis. The effectiveness of RIRS procedure is justified theoretically, utilizing the asymptotic expansions of eigenvectors and eigenvalues for large random matrices recently developed in Fan et al. (2019a) and Fan et al. (2019b). The advantages of the newly suggested procedure are demonstrated through several simulation and real data examples.},
  archivePrefix = {arXiv},
  eprint = {1912.11583},
  eprinttype = {arxiv},
  journal = {arXiv:1912.11583 [math, stat]},
  keywords = {.Cluster numbers,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@techreport{Handcock2007,
  title = {Model-Based Clustering for Social Networks},
  author = {Handcock, Mark S and Raftery, Adrian E and Tantrum, Jeremy M},
  year = {2007},
  volume = {170},
  pages = {301--354},
  abstract = {Network models are widely used to represent relations between interacting units or actors. Network data often exhibit transitivity, meaning that two actors that have ties to a third actor are more likely to be tied than actors that do not, homophily by attributes of the actors or dyads, and clustering. Interest often focuses on finding clusters of actors or ties, and the number of groups in the data is typically unknown. We propose a new model, the latent position cluster model , under which the probability of a tie between two actors depends on the distance between them in an unobserved Euclidean 'social space', and the actors' locations in the latent social space arise from a mixture of distributions, each corresponding to a cluster. We propose two estimation methods: a two-stage maximum likelihood method and a fully Bayesian method that uses Markov chain Monte Carlo sampling. The former is quicker and simpler, but the latter performs better. We also propose a Bayesian way of determining the number of clusters that are present by using approximate conditional Bayes factors. Our model represents transitivity, homophily by attributes and clustering simultaneously and does not require the number of clusters to be known. The model makes it easy to simulate realistic networks with clustering, which are potentially useful as inputs to models of more complex systems of which the network is part, such as epidemic models of infectious disease. We apply the model to two networks of social relations. A free software package in the R statistical language, latentnet, is available to analyse data by using the model.},
  journal = {J. R. Statist. Soc. A},
  keywords = {Bayes factor,Dyad,Latent space,Markov chain Monte Carlo methods,Mixture model,Transitivity},
  number = {2}
}

@article{Handel2016,
  title = {Structured {{Random Matrices}}},
  author = {Handel, Ramon Van},
  year = {2016},
  pages = {1--46},
  annotation = {\_eprint: arXiv:1610.05200v1},
  file = {/Users/ztzhang/Zotero/storage/NYVWHKVU/Handel - 2016 - Structured Random Matrices.pdf}
}

@article{Hanneke2010,
  title = {Discrete Temporal Models of Social Networks},
  author = {Hanneke, Steve and Fu, Wenjie and Xing, Eric P.},
  year = {2010},
  volume = {4},
  pages = {585--605},
  issn = {19357524},
  doi = {10.1214/09-EJS548},
  abstract = {We propose a family of statistical models for social network evolution over time, which represents an extension of Exponential Random Graph Models (ERGMs). Many of the methods for ERGMs are readily adapted for these models, including maximum likelihood estimation algorithms. We discuss models of this type and their properties, and give examples, as well as a demonstration of their use for hypothesis testing and classification. We believe our temporal ERG models represent a useful new framework for modeling time-evolving social networks, and rewiring networks from other domains such as gene regulation circuitry, and communication networks.},
  journal = {Electronic Journal of Statistics}
}

@article{Hawkes1971,
  title = {Point {{Spectra}} of {{Some Mutually Exciting Point Processes}}},
  author = {Hawkes, Alan G.},
  year = {1971},
  month = oct,
  volume = {33},
  pages = {438--443},
  publisher = {{Wiley}},
  doi = {10.1111/j.2517-6161.1971.tb01530.x},
  abstract = {The point spectral matrix is obtained for a class of mutually exciting point processes. The solution makes use of methods similar to those used in solving Wiener-Hopf integral equations. POINT},
  file = {/Users/ztzhang/Zotero/storage/3UE43XEN/Hawkes - 1971 - Point Spectra of Some Mutually Exciting Point Processes.pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  keywords = {.Hawkes processes},
  number = {3}
}

@article{Himelboim2019,
  title = {A {{Social Networks Approach}} to {{Viral Advertising}}: {{The Role}} of {{Primary}}, {{Contextual}}, and {{Low Influencers}}},
  author = {Himelboim, Itai and Golan, Guy J.},
  year = {2019},
  month = jul,
  volume = {5},
  pages = {205630511984751},
  publisher = {{SAGE Publications Ltd}},
  issn = {2056-3051},
  doi = {10.1177/2056305119847516},
  abstract = {{$<$}p{$>$}The diffusion of social networking platforms ushered in a new age of peer-to-peer distributed online advertising content, widely referred to as viral advertising. The current study proposes a social networks approach to the study of viral advertising and identifying influencers. Expanding beyond the conventional retweets metrics to include Twitter mentions as connection in the network, this study identifies three groups of influencers, based on their connectivity in their networks: Hubs, or highly retweeted users, are Primary Influencers; Bridges, or highly mentioned users who associate connect users who would otherwise be disconnected, are Contextual Influencers, and Isolates are the Low Influence users. Each of these users' roles in viral advertising is discussed and illustrated through the Heineken's Worlds Apart campaign as a case study. Providing a unique examination of viral advertising from a network paradigm, our study advances scholarship on social media influencers and their contribution to content virality on digital platforms.{$<$}/p{$>$}},
  journal = {Social Media + Society},
  keywords = {.Social networks,social media influencers,Twitter,viral advertising,viral marketing},
  number = {3}
}

@article{Hoff2002,
  ids = {hoffLatentSpaceApproaches2002a},
  title = {Latent {{Space Approaches}} to {{Social Network Analysis}}},
  author = {Hoff, Peter D. and Raftery, Adrian E. and Handcock, Mark S.},
  year = {2002},
  month = dec,
  volume = {97},
  pages = {1090--1098},
  issn = {01621459},
  doi = {10.1198/016214502388618906},
  abstract = {Network models are widely used to represent relational information among interacting units. In studies of social networks, recent emphasis has been placed on random graph models where the nodes usually represent individual social actors and the edges represent the presence of a specii ed relation between actors. We develop a class of models where the probability of a relation between actors depends on the positions of individuals in an unobserved "social space." We make inference for the social space within maximum likelihood and Bayesian frameworks, and propose Markov chain Monte Carlo procedures for making inference on latent positions and the effects of observed covariates. We present analyses of three standard datasets from the social networks literature, and compare the method to an alternative stochastic blockmodeling approach. In addition to improving on model t for these datasets, our method provides a visual and interpretable model-based spatial representation of social relationships and improves on existing methods by allowing the statistical uncertainty in the social space to be quantii ed and graphically represented.},
  file = {/Users/ztzhang/Zotero/storage/JMVBVQ4Z/Hoff, Raftery, Handcock - 2002 - Latent Space Approaches to Social Network Analysis(2).pdf;/Users/ztzhang/Zotero/storage/MLKPXXIJ/Hoff, Raftery, Handcock - 2002 - Latent space approaches to social network analysis.pdf;/Users/ztzhang/Zotero/storage/YW6ZASIM/Hoff et al. - 2002 - Latent Space Approaches to Social Network Analysis.pdf},
  journal = {Journal of the American Statistical Association},
  keywords = {.Stochastic block model,Conditional independence model,Latent position model,Latent space,Network data,Random graph,Visualization},
  number = {460}
}

@article{Holland1981,
  title = {An Exponential Family of Probability Distributions for Directed Graphs},
  author = {Holland, Paul W. and Leinhardt, Samuel},
  year = {1981},
  volume = {76},
  pages = {33--50},
  publisher = {{Taylor \& Francis Group}},
  journal = {Journal of the american Statistical association},
  keywords = {.Stochastic block model},
  number = {373}
}

@article{Holland1983,
  ids = {hollandStochasticBlockmodelsFirst1983a},
  title = {Stochastic Blockmodels: First Steps},
  author = {Holland, Paul W and Blackmond, Kathryn and Leinhardt, Samuel},
  year = {1983},
  volume = {5},
  pages = {9--137},
  abstract = {A stochastic model is proposed for social networks in which the actors in a network are partItIoned mto subgroups called blocks. The model provides a stochastrc generalization of the blockmodel. Estimation techniques are developed for the special case of a single relation social network, with blocks specified D prrorr. An extension of the model allows for tendencies toward reciprocation of ties beyond those explained by the partition. The extended model prowdes a one degree-of-freedom test of the model. A numerical example from the social network hterature 1s used to illustrate the methods.},
  file = {/Users/ztzhang/Zotero/storage/49Z6FK62/Holland et al. - 1983 - Stochastic blockmodels First steps.pdf;/Users/ztzhang/Zotero/storage/96FYSKBE/Holland, Blackmond, Leinhardt - 1983 - Stochastic blockmodels first steps.pdf},
  journal = {Social Networks},
  keywords = {.Stochastic block model}
}

@article{Holme,
  title = {Modern Temporal Network Theory: {{A}} Colloquium},
  author = {Holme, Petter},
  abstract = {The power of any kind of network approach lies in the ability to simplify a complex system so that one can better understand its function as a whole. Sometimes it is beneficial, however, to include more information than in a simple graph of only nodes and links. Adding information about times of interactions can make predictions and mechanistic understanding more accurate. The drawback, however, is that there are not so many methods available, partly because temporal networks is a relatively young field, partly because it more difficult to develop such methods compared to for static networks. In this colloquium, we review the methods to analyze and model temporal networks and processes taking place on them, focusing mainly on the last three years. This includes the spreading of infectious disease, opinions, rumors, in social networks; information packets in computer networks; various types of signaling in biology, and more. We also discuss future directions.},
  annotation = {\_eprint: 1508.01303v3},
  file = {/Users/ztzhang/Zotero/storage/TNXCVHBE/Holme - Unknown - Modern temporal network theory A colloquium.pdf}
}

@article{Huang2020,
  title = {Spectral Clustering via Adaptive Layer Aggregation for Multi-Layer Networks},
  author = {Huang, Sihan and Weng, Haolei and Feng, Yang},
  year = {2020},
  month = dec,
  abstract = {One of the fundamental problems in network analysis is detecting community structure in multi-layer networks, of which each layer represents one type of edge information among the nodes. We propose integrative spectral clustering approaches based on effective convex layer aggregations. Our aggregation methods are strongly motivated by a delicate asymptotic analysis of the spectral embedding of weighted adjacency matrices and the downstream \$k\$-means clustering, in a challenging regime where community detection consistency is impossible. In fact, the methods are shown to estimate the optimal convex aggregation, which minimizes the mis-clustering error under some specialized multi-layer network models. Our analysis further suggests that clustering using Gaussian mixture models is generally superior to the commonly used \$k\$-means in spectral clustering. Extensive numerical studies demonstrate that our adaptive aggregation techniques, together with Gaussian mixture model clustering, make the new spectral clustering remarkably competitive compared to several popularly used methods.},
  archivePrefix = {arXiv},
  eprint = {2012.04646},
  eprinttype = {arxiv},
  journal = {arXiv:2012.04646 [cs, math, stat]},
  keywords = {.Multilayer networks},
  primaryClass = {cs, math, stat}
}

@article{Hubert1985,
  title = {Comparing Partitions},
  author = {Hubert, Lawrence and Arabie, Phipps},
  year = {1985},
  month = dec,
  volume = {2},
  pages = {193--218},
  publisher = {{Springer-Verlag}},
  issn = {01764268},
  doi = {10.1007/BF01908075},
  abstract = {The problem of comparing two different partitions of a finite set of objects reappears continually in the clustering literature. We begin by reviewing a well-known measure of partition correspondence often attributed to Rand (1971), discuss the issue of correcting this index for chance, and note that a recent normalization strategy developed by Morey and Agresti (1984) and adopted by others (e.g., Miligan and Cooper 1985) is based on an incorrect assumption. Then, the general problem of comparing partitions is approached indirectly by assessing the congruence of two proximity matrices using a simple cross-product measure. They are generated from corresponding partitions using various scoring rules. Special cases derivable include traditionally familiar statistics and/or ones tailored to weight certain object pairs differentially. Finally, we propose a measure based on the comparison of object triples having the advantage of a probabilistic interpretation in addition to being corrected for chance (i.e., assuming a constant value under a reasonable null hypothesis) and bounded between {$\pm$}1. \textcopyright{} 1985 Springer-Verlag New York Inc.},
  journal = {Journal of Classification},
  keywords = {Consensus indices,Measures of agreement,Measures of association},
  number = {1}
}

@article{Issartel2021,
  title = {On the {{Estimation}} of {{Network Complexity}}: {{Dimension}} of {{Graphons}}},
  shorttitle = {On the {{Estimation}} of {{Network Complexity}}},
  author = {Issartel, Yann},
  year = {2021},
  month = jan,
  abstract = {Network complexity has been studied for over half a century and has found a wide range of applications. Many methods have been developed to characterize and estimate the complexity of networks. However, there has been little research with statistical guarantees. In this paper, we develop a statistical theory of graph complexity in a general model of random graphs, the so-called graphon model. Given a graphon, we endow the latent space of the nodes with the neighborhood distance that measures the propensity of two nodes to be connected with similar nodes. Our complexity index is then based on the covering number and the Minkowski dimension of (a purified version of) this metric space. Although the latent space is not identifiable, these indices turn out to be identifiable. This notion of complexity has simple interpretations on popular examples of random graphs: it matches the number of communities in stochastic block models; the dimension of the Euclidean space in random geometric graphs; the regularity of the link function in H\textbackslash "older graphon models. From a single observation of the graph, we construct an estimator of the neighborhood-distance and show universal non-asymptotic bounds for its risk, matching minimax lower bounds. Based on this estimated distance, we compute the corresponding covering number and Minkowski dimension and we provide optimal non-asymptotic error bounds for these two plug-in estimators.},
  archivePrefix = {arXiv},
  eprint = {1909.02900},
  eprinttype = {arxiv},
  journal = {arXiv:1909.02900 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@inproceedings{Iwata2013,
  title = {Discovering Latent Influence in Online Social Activities via Shared Cascade Poisson Processes},
  author = {Iwata, Tomoharu and Shah, Amar and Ghahramani, Zoubin},
  year = {2013},
  month = aug,
  pages = {266},
  publisher = {{Association for Computing Machinery (ACM)}},
  doi = {10.1145/2487575.2487624},
  abstract = {\cyrchar\CYRM\cyrchar\cyro\cyrchar\cyrd\cyrchar\cyre\cyrchar\cyrl\cyrchar\cyri\cyrchar\cyrr\cyrchar\cyro\cyrchar\cyrv\cyrchar\cyra\cyrchar\cyrn\cyrchar\cyri\cyrchar\cyre{} \cyrchar\cyrs\cyrchar\cyro\cyrchar\cyrb\cyrchar\cyrery\cyrchar\cyrt\cyrchar\cyri\cyrchar\cyrishrt{} \cyrchar\cyrv{} \cyrchar\cyrn\cyrchar\cyre\cyrchar\cyrp\cyrchar\cyrr\cyrchar\cyre\cyrchar\cyrr\cyrchar\cyrery\cyrchar\cyrv\cyrchar\cyrn\cyrchar\cyro\cyrchar\cyrm{} \cyrchar\cyrv\cyrchar\cyrr\cyrchar\cyre\cyrchar\cyrm\cyrchar\cyre\cyrchar\cyrn\cyrchar\cyri. \cyrchar\CYRS\cyrchar\cyro\cyrchar\cyrb\cyrchar\cyrery\cyrchar\cyrt\cyrchar\cyri\cyrchar\cyre{} (t,u) - \cyrchar\cyrv{} \cyrchar\cyrm\cyrchar\cyro\cyrchar\cyrm\cyrchar\cyre\cyrchar\cyrn\cyrchar\cyrt{} t \cyrchar\cyrp\cyrchar\cyro\cyrchar\cyrl\cyrchar\cyrsftsn\cyrchar\cyrz\cyrchar\cyro\cyrchar\cyrv\cyrchar\cyra\cyrchar\cyrt\cyrchar\cyre\cyrchar\cyrl\cyrchar\cyrsftsn{} u \cyrchar\cyrp\cyrchar\cyrr\cyrchar\cyri\cyrchar\cyrn\cyrchar\cyrya\cyrchar\cyrl{} \cyrchar\cyrerev\cyrchar\cyrl\cyrchar\cyre\cyrchar\cyrm\cyrchar\cyre\cyrchar\cyrn\cyrchar\cyrt{} i},
  file = {/Users/ztzhang/Zotero/storage/M5WMAVJZ/Iwata, Shah, Ghahramani - 2013 - Discovering latent influence in online social activities via shared cascade poisson processes.pdf}
}

@article{Jain2020,
  title = {Correlation {{Across Environments Encoded}} by {{Hippocampal Place Cells}}},
  author = {Jain, Bhav and Elliott, Sean},
  year = {2020},
  month = dec,
  abstract = {The hippocampus is often attributed to episodic memory formation and storage in the mammalian brain; in particular, Alme et al. showed that hippocampal area CA3 forms statistically independent representations across a large number of environments, even if the environments share highly similar features. This lack of overlap between spatial maps indicates the large capacity of the CA3 circuitry. In this paper, we support the argument for the large capacity of the CA3 network. To do so, we replicate the key findings of Alme et al. and extend the results by perturbing the neural activity encodings with noise and conducting representation similarity analysis (RSA). We find that the correlations between firing rates are partially resistant to noise, and that the spatial representations across cells show similar patterns, even across different environments. Finally, we discuss some theoretical and practical implications of our results.},
  archivePrefix = {arXiv},
  eprint = {2012.14559},
  eprinttype = {arxiv},
  journal = {arXiv:2012.14559 [q-bio, stat]},
  keywords = {.Neuroscience},
  primaryClass = {q-bio, stat}
}

@article{JeremieBigot2010,
  title = {A Deconvolution Approach to Estimation of a Common Shape in a Shifted Curves Model},
  author = {J{\'e}r{\'e}mie Bigot, BY and Gadat, S{\'e}bastien},
  year = {2010},
  volume = {38},
  pages = {2422--2464},
  doi = {10.1214/10-AOS800},
  abstract = {This paper considers the problem of adaptive estimation of a mean pattern in a randomly shifted curve model. We show that this problem can be transformed into a linear inverse problem, where the density of the random shifts plays the role of a convolution operator. An adaptive estimator of the mean pattern, based on wavelet thresholding is proposed. We study its consistency for the quadratic risk as the number of observed curves tends to infinity , and this estimator is shown to achieve a near-minimax rate of convergence over a large class of Besov balls. This rate depends both on the smoothness of the common shape of the curves and on the decay of the Fourier coefficients of the density of the random shifts. Hence, this paper makes a connection between mean pattern estimation and the statistical analysis of linear inverse problems, which is a new point of view on curve registration and image warping problems. We also provide a new method to estimate the unknown random shifts between curves. Some numerical experiments are given to illustrate the performances of our approach and to compare them with another algorithm existing in the literature.},
  file = {/Users/ztzhang/Zotero/storage/YB44FR5W/Statistics, Annals - 2010 - A DECONVOLUTION APPROACH TO ESTIMATION OF.pdf},
  journal = {The Annals of Statistics},
  keywords = {42C40,62G08,adaptive estimation,Besov space,curve registration,deconvolution,inverse problem,Mean pattern estimation,Meyer wavelets,minimax rate},
  number = {4}
}

@article{Jia2020,
  title = {Clustering {{Ensemble Meets Low}}-Rank {{Tensor Approximation}}},
  author = {Jia, Yuheng and Liu, Hui and Hou, Junhui and Zhang, Qingfu},
  year = {2020},
  month = dec,
  abstract = {This paper explores the problem of clustering ensemble, which aims to combine multiple base clusterings to produce better performance than that of the individual one. The existing clustering ensemble methods generally construct a co-association matrix, which indicates the pairwise similarity between samples, as the weighted linear combination of the connective matrices from different base clusterings, and the resulting co-association matrix is then adopted as the input of an off-the-shelf clustering algorithm, e.g., spectral clustering. However, the co-association matrix may be dominated by poor base clusterings, resulting in inferior performance. In this paper, we propose a novel low-rank tensor approximation-based method to solve the problem from a global perspective. Specifically, by inspecting whether two samples are clustered to an identical cluster under different base clusterings, we derive a coherent-link matrix, which contains limited but highly reliable relationships between samples. We then stack the coherent-link matrix and the co-association matrix to form a three-dimensional tensor, the low-rankness property of which is further explored to propagate the information of the coherent-link matrix to the co-association matrix, producing a refined co-association matrix. We formulate the proposed method as a convex constrained optimization problem and solve it efficiently. Experimental results over 7 benchmark data sets show that the proposed model achieves a breakthrough in clustering performance, compared with 12 state-of-the-art methods. To the best of our knowledge, this is the first work to explore the potential of low-rank tensor on clustering ensemble, which is fundamentally different from previous approaches.},
  archivePrefix = {arXiv},
  eprint = {2012.08916},
  eprinttype = {arxiv},
  journal = {arXiv:2012.08916 [cs, stat]},
  keywords = {.unlabeled,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Johnson2016,
  title = {Composing Graphical Models with Neural Networks for Structured Representations and Fast Inference},
  author = {Johnson, Matthew J. and Duvenaud, David and Wiltschko, Alexander B. and Datta, Sandeep R. and Adams, Ryan P.},
  year = {2016},
  month = mar,
  abstract = {We propose a general modeling and inference framework that composes probabilistic graphical models with deep learning methods and combines their respective strengths. Our model family augments graphical structure in latent variables with neural network observation models. For inference, we extend variational autoencoders to use graphical model approximating distributions with recognition networks that output conjugate potentials. All components of these models are learned simultaneously with a single objective, giving a scalable algorithm that leverages stochastic variational inference, natural gradients, graphical model message passing, and the reparameterization trick. We illustrate this framework with several example models and an application to mouse behavioral phenotyping.},
  annotation = {\_eprint: 1603.06277},
  file = {/Users/ztzhang/Zotero/storage/3UWKSUS7/Johnson et al. - 2016 - Composing graphical models with neural networks for structured representations and fast inference(2).pdf;/Users/ztzhang/Zotero/storage/W83H3F55/Johnson et al. - 2016 - Composing graphical models with neural networks for structured representations and fast inference.pdf}
}

@article{Josephs2021,
  title = {Bayesian Classification, Anomaly Detection, and Survival Analysis Using Network Inputs with Application to the Microbiome},
  author = {Josephs, Nathaniel and Lin, Lizhen and Rosenberg, Steven and Kolaczyk, Eric D.},
  year = {2021},
  month = jan,
  abstract = {While the study of a single network is well-established, technological advances now allow for the collection of multiple networks with relative ease. Increasingly, anywhere from several to thousands of networks can be created from brain imaging, gene co-expression data, or microbiome measurements. And these networks, in turn, are being looked to as potentially powerful features to be used in modeling. However, with networks being non-Euclidean in nature, how best to incorporate them into standard modeling tasks is not obvious. In this paper, we propose a Bayesian modeling framework that provides a unified approach to binary classification, anomaly detection, and survival analysis with network inputs. We encode the networks in the kernel of a Gaussian process prior via their pairwise differences and we discuss several choices of provably positive definite kernel that can be plugged into our models. Although our methods are widely applicable, we are motivated here in particular by microbiome research (where network analysis is emerging as the standard approach for capturing the interconnectedness of microbial taxa across both time and space) and its potential for reducing preterm delivery and improving personalization of prenatal care.},
  archivePrefix = {arXiv},
  eprint = {2004.04765},
  eprinttype = {arxiv},
  journal = {arXiv:2004.04765 [stat]},
  keywords = {Statistics - Applications},
  primaryClass = {stat}
}

@article{Junuthula2019,
  title = {The {{Block Point Process Model}} for {{Continuous}}-{{Time Event}}-{{Based Dynamic Networks}}},
  author = {Junuthula, Ruthwik R. and Haghdan, Maysam and Xu, Kevin S. and Devabhaktuni, Vijay K.},
  year = {2019},
  month = feb,
  abstract = {We consider the problem of analyzing timestamped relational events between a set of entities, such as messages between users of an on-line social network. Such data are often analyzed using static or discrete-time network models, which discard a significant amount of information by aggregating events over time to form network snapshots. In this paper, we introduce a block point process model (BPPM) for continuous-time event-based dynamic networks. The BPPM is inspired by the well-known stochastic block model (SBM) for static networks. We show that networks generated by the BPPM follow an SBM in the limit of a growing number of nodes. We use this property to develop principled and efficient local search and variational inference procedures initialized by regularized spectral clustering. We fit BPPMs with exponential Hawkes processes to analyze several real network data sets, including a Facebook wall post network with over 3,500 nodes and 130,000 events.},
  archivePrefix = {arXiv},
  eprint = {1711.10967},
  eprinttype = {arxiv},
  journal = {arXiv:1711.10967 [physics, stat]},
  keywords = {.Continuous time,.Hawkes processes,.Point processes,.Stochastic block model,.Time varying networks,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Methodology},
  primaryClass = {physics, stat}
}

@article{kaAlbert,
  title = {Statistical Mechanics of Complex Networks},
  author = {{ka Albert}, R{\'e} and {szl{\'o} Barab{\'a} si}, Albert-L{\'a}},
  abstract = {Complex networks describe a wide range of systems in nature and society. Frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the Internet, a network of routers and computers connected by physical links. While traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. This article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. After reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network's robustness against failures and attacks. CONTENTS}
}

@article{Karlsson2010,
  title = {Awake Replay of Remote Experiences in the Hippocampus},
  author = {Karlsson, Mattias P and Frank, Loren M},
  year = {2010},
  volume = {12},
  pages = {913--918},
  doi = {10.1038/nn.2344.Awake},
  file = {/Users/ztzhang/Zotero/storage/HDYLLYEJ/Karlsson, Frank - 2010 - Awake replay of remote experiences in the hippocampus.pdf},
  number = {7}
}

@article{Karrer2011,
  ids = {karrerStochasticBlockmodelsCommunity2011a},
  title = {Stochastic Blockmodels and Community Structure in Networks},
  author = {Karrer, Brian and Newman, M. E.J.},
  year = {2011},
  month = jan,
  volume = {83},
  issn = {15393755},
  doi = {10.1103/PhysRevE.83.016107},
  abstract = {Stochastic blockmodels have been proposed as a tool for detecting community structure in networks as well as for generating synthetic networks for use as benchmarks. Most blockmodels, however, ignore variation in vertex degree, making them unsuitable for applications to real-world networks, which typically display broad degree distributions that can significantly distort the results. Here we demonstrate how the generalization of blockmodels to incorporate this missing element leads to an improved objective function for community detection in complex networks. We also propose a heuristic algorithm for community detection using this objective function or its non-degree-corrected counterpart and show that the degree-corrected version dramatically outperforms the uncorrected one in both real-world and synthetic networks.},
  archivePrefix = {arXiv},
  eprint = {1008.3926},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/NB7ZTKAC/Karrer, Newman - 2011 - Stochastic blockmodels and community structure in networks.pdf},
  journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
  keywords = {.Stochastic block model},
  number = {1}
}

@article{Kass2018,
  ids = {kassComputationalNeuroscienceMathematical2018a},
  title = {Computational {{Neuroscience}}: {{Mathematical}} and {{Statistical Perspectives}}},
  author = {Kass, Robert E and Amari, Shun-Ichi and Arai, Kensuke and Brown, Emery N and Diekman, Casey O and Diesmann, Markus and Doiron, Brent and Eden, Uri T and Fairhall, Adrienne L and Fiddyment, Grant M and Fukai, Tomoki and Gr{\"u}nGr, Sonja and Harrison, Matthew T and Helias, Moritz and Nakahara, Hiroyuki and Teramae, Jun-nosuke and Thomas, Peter J and Reimers, Mark and Rodu, Jordan and Rotstein, Horacio G and {Shea-Brown}, Eric and Shimazaki, Hideaki and Shinomoto, Shigeru and Yu, Byron M and Kramer, Mark A},
  year = {2018},
  publisher = {{Annual Reviews}},
  doi = {10.1146/annurev-statistics},
  abstract = {Mathematical and statistical models have played important roles in neuroscience, especially by describing the electrical activity of neurons recorded individually, or collectively across large networks. As the field moves forward rapidly, new challenges are emerging. For maximal effectiveness , those working to advance computational neuroscience will need to appreciate and exploit the complementary strengths of mechanistic theory and the statistical paradigm.},
  file = {/Users/ztzhang/Zotero/storage/RANHVQCW/Kass et al. - 2018 - Annual Review of Statistics and Its Application Computational Neuroscience Mathematical and Statistical Perspective.pdf},
  keywords = {.Theoretical neuroscience,neural data analysis,neural modeling,neural networks}
}

@article{Kay2016,
  title = {A Hippocampal Network for Spatial Coding during Immobility and Sleep},
  author = {Kay, Kenneth and Sosa, Marielena and Chung, Jason E and Mattias, P and Larkin, Margaret C and Frank, Loren M},
  year = {2016},
  volume = {531},
  pages = {258--264},
  publisher = {{Nature Publishing Group}},
  issn = {0028-0836},
  doi = {10.1038/nature17144},
  file = {/Users/ztzhang/Zotero/storage/8XY9FWIZ/Kay et al. - 2016 - A hippocampal network for spatial coding during immobility and sleep.pdf},
  journal = {Nature},
  keywords = {.Neuroscience,neural data analysis},
  number = {7593}
}

@techreport{Kemp,
  title = {Discovering {{Latent Classes}} in {{Relational Data}}},
  author = {Kemp, Charles and Griffiths, Thomas L and Tenenbaum, Joshua B},
  abstract = {We present a framework for learning abstract relational knowledge, with the aim of explaining how people acquire intuitive theories of physical, biological, or social systems. Our algorithm infers a generative relational model with latent classes, simultaneously determining the kinds of entities that exist in a domain, the number of these latent classes, and the relations between classes that are possible or likely. This model goes beyond previous category-learning models in psychology , which consider the attributes associated with individual categories but not the relationships that can exist between categories. We apply this domain-general framework in two specific domains: learning the structure of kinship systems and learning causal theories.},
  file = {/Users/ztzhang/Zotero/storage/ST23TN85/Kemp, Griffiths, Tenenbaum - Unknown - Discovering Latent Classes in Relational Data.pdf;/Users/ztzhang/Zotero/storage/XU7RRX7D/Kemp, Griffiths, Tenenbaum - Unknown - Discovering Latent Classes in Relational Data.pdf}
}

@techreport{Kempa,
  title = {Learning {{Systems}} of {{Concepts}} with an {{Infinite Relational Model}}},
  author = {Kemp, Charles and Tenenbaum, Joshua B and Griffiths, Thomas L and Yamada, Takeshi and Ueda, Naonori},
  abstract = {Relationships between concepts account for a large proportion of semantic knowledge. We present a nonpara-metric Bayesian model that discovers systems of related concepts. Given data involving several sets of entities, our model discovers the kinds of entities in each set and the relations between kinds that are possible or likely. We apply our approach to four problems: clustering objects and features, learning ontologies, discovering kin-ship systems, and discovering structure in political data. Philosophers, psychologists and computer scientists have proposed that semantic knowledge is best understood as a system of relations. Two questions immediately arise: how can these systems be represented, and how are these representations acquired? Researchers who start with the first question often devise complex representational schemes (e.g. Minsky's (1975) classic work on frames), but explaining how these representations are learned is a challenging problem. We take the opposite approach. We consider only simple relational systems, but show how these systems can be acquired by unsupervised learning. The systems we wish to discover are simple versions of the "domain theories" discussed by cognitive scientists and AI researchers (Davis 1990). Suppose that a domain includes several types, or sets of entities. One role of a domain theory is to specify the kinds of entities that exist in each set, and the possible or likely relationships between those kinds. Consider the domain of medicine, and a single type defined as the set of terms that might appear on a medical chart. A theory of this domain might specify that cancer and diabetes are both disorders, asbestos and arsenic are both chemicals, and that chemicals can cause disorders. Our model assumes that each entity belongs to exactly one kind, or cluster, and simultaneously discovers the clusters and the relationships between clusters that are best supported by the data. A key feature of our approach is that it does not require the number of clusters to be fixed in advance. The number of clusters used by a theory should be able to grow as more and more data are encountered, but a theory-learner should introduce no more clusters than are necessary to explain the data. Our approach automatically chooses an appropriate number of clusters using a prior that favors small numbers of clusters , but has access to a countably infinite collection of clusters. We therefore call our approach the infinite relational model (IRM). Previous infinite models (Rasmussen 2000; Antoniak 1974) have focused on feature data, and the IRM extends these approaches to work with arbitrary systems of relational data. Our framework can discover structure in relational data sets that appear quite different on the surface. We demonstrate its range by applying it to four problems. First we suggest that object-feature data can be profitably viewed as a relation between two sets of entities-the objects and the features-and show how the IRM simultaneously clusters both. We then use the IRM to learn a biomedical on-tology. Ontologies are classic examples of the theories we have described, since they group entities into higher-level concepts and specify how these high-level concepts relate to each other. Next we show that the IRM discovers aspects of the kinship structure of an Australian tribe. Our final example considers a political data set, and we discover a system with clusters of countries, clusters of interactions between countries, and clusters of country features. The Infinite Relational Model Suppose we are given one or more relations involving one or more types. The goal of the IRM is to partition each type into clusters, where a good set of partitions allows relationships between entities to be predicted by their cluster assignments. For example, we may have a single type people and a single relation likes(i, j) which indicates whether person i likes person j. Our goal is to organize the entities into clusters that relate to each other in predictable ways (Fig-ure 1a). We also allow predicate types: if there are multiple relations defined over the same domain, we will group them into a type and refer to them as predicates. For instance, we may have several social predicates defined over the domain people \texttimes{} people: likes({$\cdot$}, {$\cdot$}), admires({$\cdot$}, {$\cdot$}), respects({$\cdot$}, {$\cdot$}), and hates({$\cdot$}, {$\cdot$}). We can introduce a type for these social predicates , and define a ternary relation applies(i, j, p) which is true if predicate p applies to the pair (i, j). Our goal is now to simultaneously cluster the people and the predicates (Figure 1c). The IRM can handle arbitrarily complex systems of attributes, entities and relations: if we include demographic attributes for the people, for example, we can},
  file = {/Users/ztzhang/Zotero/storage/9TGY6JAZ/Kemp et al. - Unknown - Learning Systems of Concepts with an Infinite Relational Model.pdf}
}

@article{Keshavan2009,
  title = {Matrix {{Completion}} from {{Noisy Entries}}},
  author = {Keshavan, Raghunandan H. and Montanari, Andrea and Oh, Sewoong},
  year = {2009},
  month = jun,
  abstract = {Given a matrix M of low-rank, we consider the problem of reconstructing it from noisy observations of a small, random subset of its entries. The problem arises in a variety of applications, from collaborative filtering (the `Netflix problem') to structure-from-motion and positioning. We study a low complexity algorithm introduced by Keshavan et al.(2009), based on a combination of spectral techniques and manifold optimization, that we call here OptSpace. We prove performance guarantees that are order-optimal in a number of circumstances.},
  annotation = {\_eprint: 0906.2027},
  file = {/Users/ztzhang/Zotero/storage/QJ3PEEDD/Keshavan, Montanari, Oh - 2009 - Matrix Completion from Noisy Entries.pdf}
}

@article{Keshavan2009a,
  title = {Matrix {{Completion}} from a {{Few Entries}}},
  author = {Keshavan, Raghunandan H. and Montanari, Andrea and Oh, Sewoong},
  year = {2009},
  month = jan,
  abstract = {Let M be a random (alpha n) x n matrix of rank r{$<$}},
  annotation = {\_eprint: 0901.3150},
  file = {/Users/ztzhang/Zotero/storage/W57HCTX3/Keshavan, Montanari, Oh - 2009 - Matrix Completion from a Few Entries.pdf}
}

@article{Kim2018,
  title = {A Review of Dynamic Network Models with Latent Variables},
  author = {Kim, Bomin and Lee, Kevin H and Xue, Lingzhou and Niu, Xiaoyue},
  year = {2018},
  volume = {12},
  pages = {105--135},
  issn = {1935-7516},
  doi = {10.1214/18-SS121},
  abstract = {We present a selective review of statistical modeling of dynamic networks. We focus on models with latent variables, specifically, the latent space models and the latent class models (or stochastic blockmodels), which investigate both the observed features and the unobserved structure of networks. We begin with an overview of the static models, and then we introduce the dynamic extensions. For each dynamic model, we also discuss its applications that have been studied in the literature, with the data source listed in Appendix. Based on the review, we summarize a list of open problems and challenges in dynamic network modeling with latent variables. MSC 2010 subject classifications: Primary 62-02, 62-07; secondary 05C90.},
  file = {/Users/ztzhang/Zotero/storage/55EXFQCZ/Kim et al. - 2018 - A review of dynamic network models with latent variables.pdf},
  journal = {Statistics Surveys},
  keywords = {.Latent space model,.Stochastic block model,.Time varying networks,latent variable model}
}

@article{Kivela2014,
  title = {Multilayer Networks},
  author = {Kivel{\"a}, Mikko and Arenas, Alex and Barthelemy, Marc and Gleeson, James P. and Moreno, Yamir and Porter, Mason A.},
  year = {2014},
  month = sep,
  volume = {2},
  pages = {203--271},
  issn = {2051-1310},
  doi = {10.1093/comnet/cnu016},
  abstract = {In most natural and engineered systems, a set of entities interact with each other in complicated patterns that can encompass multiple types of relationships, change in time and include other types of complications. Such systems include multiple subsystems and layers of connectivity, and it is important to take such `multilayer' features into account to try to improve our understanding of complex systems. Consequently, it is necessary to generalize `traditional' network theory by developing (and validating) a framework and associated tools to study multilayer systems in a comprehensive fashion. The origins of such efforts date back several decades and arose in multiple disciplines, and now the study of multilayer networks has become one of the most important directions in network science. In this paper, we discuss the history of multilayer networks (and related concepts) and review the exploding body of work on such networks. To unify the disparate terminology in the large body of recent work, we discuss a general framework for multilayer networks, construct a dictionary of terminology to relate the numerous existing concepts to each other and provide a thorough discussion that compares, contrasts and translates between related notions such as multilayer networks, multiplex networks, interdependent networks, networks of networks and many others. We also survey and discuss existing data sets that can be represented as multilayer networks. We review attempts to generalize single-layer-network diagnostics to multilayer networks. We also discuss the rapidly expanding research on multilayer-network models and notions like community structure, connected components, tensor decompositions and various types of dynamical processes on multilayer networks. We conclude with a summary and an outlook.},
  journal = {Journal of Complex Networks},
  keywords = {.Multilayer networks},
  number = {3}
}

@article{Klimm2021,
  title = {Modularity Maximisation for Graphons},
  author = {Klimm, Florian and Jones, Nick S. and Schaub, Michael T.},
  year = {2021},
  month = jan,
  abstract = {Networks are a widely-used tool to investigate the large-scale connectivity structure in complex systems and graphons have been proposed as an infinite size limit of dense networks. The detection of communities or other meso-scale structures is a prominent topic in network science as it allows the identification of functional building blocks in complex systems. When such building blocks may be present in graphons is an open question. In this paper, we define a graphon-modularity and demonstrate that it can be maximised to detect communities in graphons. We then investigate specific synthetic graphons and show that they may show a wide range of different community structures. We also reformulate the graphon-modularity maximisation as a continuous optimisation problem and so prove the optimal community structure or lack thereof for some graphons, something that is usually not possible for networks. Furthermore, we demonstrate that estimating a graphon from network data as an intermediate step can improve the detection of communities, in comparison with exclusively maximising the modularity of the network. While the choice of graphon-estimator may strongly influence the accord between the community structure of a network and its estimated graphon, we find that there is a substantial overlap if an appropriate estimator is used. Our study demonstrates that community detection for graphons is possible and may serve as a privacy-preserving way to cluster network data.},
  archivePrefix = {arXiv},
  eprint = {2101.00503},
  eprinttype = {arxiv},
  journal = {arXiv:2101.00503 [nlin, physics:physics, stat]},
  keywords = {.Stochastic block model},
  primaryClass = {nlin, physics:physics, stat}
}

@article{Klopp2013,
  title = {Non-Asymptotic Approach to Varying Coefficient Model},
  author = {Klopp, Olga},
  year = {2013},
  volume = {7},
  pages = {454--479},
  doi = {10.1214/13-EJS778},
  file = {/Users/ztzhang/Zotero/storage/NQV3KYIH/Klopp - 2013 - Non-asymptotic approach to varying coefficient model.pdf},
  keywords = {60G57Varying coefficient model,62H12,62J99,and phrases,low,low rank matrix es-,received november 2012,statistical learning,timation,varying coefficient model}
}

@article{Klopp2015,
  title = {Sparse High-Dimensional Varying Coefficient Model: {{Nonasymptotic}} Minimax Study},
  author = {Klopp, Olga and Pensky, Marianna},
  year = {2015},
  month = jun,
  volume = {43},
  pages = {1273--1299},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364},
  doi = {10.1214/15-aos1309},
  abstract = {The objective of the present paper is to develop a minimax theory for the varying coefficient model in a nonasymptotic setting. We consider a high-dimensional sparse varying coefficient model where only few of the covariates are present and only some of those covariates are time dependent. Our analysis allows the time-dependent covariates to have different degrees of smoothness and to be spatially inhomogeneous. We develop the minimax lower bounds for the quadratic risk and construct an adaptive estimator which attains those lower bounds within a constant (if all time-dependent covariates are spatially homogeneous) or logarithmic factor of the number of observations.},
  file = {/Users/ztzhang/Zotero/storage/2Y3SR3J6/Klopp, Pensky - 2015 - Sparse high-dimensional varying coefficient model Nonasymptotic minimax study.pdf},
  journal = {The Annals of Statistics},
  number = {3}
}

@article{Klopp2017,
  title = {Oracle Inequalities for Network Models and Sparse Graphon Estimation},
  author = {Klopp, Olga and Tsybakov, Alexandre B. and Verzelen, Nicolas},
  year = {2017},
  month = feb,
  volume = {45},
  pages = {316--354},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {00905364},
  doi = {10.1214/16-AOS1454},
  abstract = {Inhomogeneous random graph models encompass many network models such as stochastic block models and latent position models. We consider the problem of statistical estimation of the matrix of connection probabilities based on the observations of the adjacency matrix of the network. Taking the stochastic block model as an approximation, we construct estimators of network connection probabilities-the ordinary block constant least squares estimator, and its restricted version. We show that they satisfy oracle inequalities with respect to the block constant oracle. As a consequence, we derive optimal rates of estimation of the probability matrix. Our results cover the important setting of sparse networks. Another consequence consists in establishing upper bounds on the minimax risks for graphon estimation in the L 2 norm when the probability matrix is sampled according to a graphon model. These bounds include an additional term accounting for the "agnostic" error induced by the variability of the latent unobserved variables of the graphon model. In this setting, the optimal rates are influenced not only by the bias and variance components as in usual nonparametric problems but also include the third component, which is the agnostic error. The results shed light on the differences between estimation under the empirical loss (the probability matrix estimation) and under the integrated loss (the graphon estimation). 1. Introduction. Consider a network defined as an undirected graph with n nodes. Assume that we observe the values A ij {$\in$} 0, 1 where A ij = 1 is interpreted as the fact that the nodes i and j are connected and A ij = 0 otherwise. We set A ii = 0 for all 1 {$\leq$} i {$\leq$} n and we assume that A ij is a Bernoulli random variable with parameter (0) ij = P(A ij = 1) for 1 {$\leq$} j {$<$} i {$\leq$} n. The random variables A ij , 1 {$\leq$} j {$<$} i {$\leq$} n, are assumed independent. We denote by A the adjacency matrix, that is, the n \texttimes{} n symmetric matrix with entries A ij for 1 {$\leq$} j {$<$} i {$\leq$} n and zero di},
  file = {/Users/ztzhang/Zotero/storage/FHU9J6HD/Klopp, Tsybakov, Verzelen - 2017 - Oracle inequalities for network models and sparse graphon estimation.pdf},
  journal = {Annals of Statistics},
  keywords = {.Stochastic block model,Inhomogeneous random graph,Networks,Oracle inequality,Sparse graphon,Sparsity},
  number = {1}
}

@article{Kneip1995,
  title = {Model {{Estimation}} in {{Nonlinear Regression Under Shape Invariance}}},
  author = {Kneip, Alois and Engel, Joachim},
  year = {1995},
  month = apr,
  volume = {23},
  pages = {551--570},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364},
  doi = {10.1214/aos/1176324535},
  abstract = {Given data from a sample of noisy curves, we consider a nonlinear parametric regression model with unknown model function. An iterative algorithm for estimating individual parameters as well as the model function is introduced under the assumption of a certain shape invariance: the individual regression curves are obtained from a common shape function by linear transformations of the axes. Our algorithm is based on least-squares methods for parameter estimation and on nonparametric kernel methods for curve estimation. Asymptotic distributions are derived for the individual parameter estimators as well as for the estimator of the shape function. An application to human growth data illustrates the method.},
  file = {/Users/ztzhang/Zotero/storage/LEUCH2UK/Kneip, Engel - 1995 - Model Estimation in Nonlinear Regression Under Shape Invariance.pdf},
  journal = {The Annals of Statistics},
  number = {2}
}

@article{Krampe2019,
  title = {Time Series Modeling on Dynamic Networks},
  author = {Krampe, Jonas},
  year = {2019},
  month = jul,
  volume = {13},
  pages = {4945--4976},
  issn = {1935-7524},
  doi = {10.1214/19-EJS1642},
  abstract = {This paper focuses on modeling the dynamic attributes of a dynamic network with a fixed number of vertices. These attributes are considered as time series which dependency structure is influenced by the underlying network. They are modeled by a multivariate doubly stochastic time series framework, that is we assume linear processes for which the coefficient matrices are stochastic processes themselves. We explicitly allow for dependence in the dynamics of the coefficient matrices as well as between these two stochastic processes. This framework allows for a separate modeling of the attributes and the underlying network. In this setting, we define network autoregressive models and discuss their stationarity conditions. Furthermore, an estimation approach is discussed in a low- and high-dimensional setting and how this can be applied to forecasting. The finite sample behavior of the forecast approach is investigated. This approach is applied to real data whereby the goal is to forecast the GDP of 33 economies.},
  annotation = {\_eprint: 1807.01133},
  file = {/Users/ztzhang/Zotero/storage/8YELS4IW/Krampe - 2019 - Time series modeling on dynamic networks.pdf},
  journal = {Electronic Journal of Statistics},
  number = {2}
}

@article{Kreiss2019,
  title = {Nonparametric Inference for Continuous-Time Event Counting and Link-Based Dynamic Network Models},
  author = {Krei{\ss}, Alexander and Mammen, Enno and Polonik, Wolfgang},
  year = {2019},
  volume = {13},
  pages = {2764--2829},
  publisher = {{The Institute of Mathematical Statistics and the Bernoulli Society}},
  issn = {1935-7524},
  doi = {10.1214/19-EJS1588},
  abstract = {A flexible approach for modeling both dynamic event counting and dynamic link-based networks based on counting processes is proposed, and estimation in these models is studied. We consider nonparametric likelihood based estimation of parameter functions via kernel smoothing. The asymptotic behavior of these estimators is rigorously analyzed in an asymptotic framework where the number of nodes tends to infinity. The finite sample performance of the estimators is illustrated through an empirical analysis of bike share data.},
  journal = {Electronic Journal of Statistics},
  keywords = {.Stochastic block model},
  language = {EN},
  mrnumber = {MR3995010},
  number = {2},
  zmnumber = {07104730}
}

@article{Kuhn2020,
  title = {Properties of the Stochastic Approximation {{EM}} Algorithm with Mini-Batch Sampling},
  author = {Kuhn, Estelle and Matias, Catherine and Rebafka, Tabea},
  year = {2020},
  month = nov,
  volume = {30},
  pages = {1725--1739},
  issn = {1573-1375},
  doi = {10.1007/s11222-020-09968-0},
  abstract = {To deal with very large datasets a mini-batch version of the Monte Carlo Markov Chain Stochastic Approximation Expectation\textendash Maximization algorithm for general latent variable models is proposed. For exponential models the algorithm is shown to be convergent under classical conditions as the number of iterations increases. Numerical experiments illustrate the performance of the mini-batch algorithm in various models. In particular, we highlight that mini-batch sampling results in an important speed-up of the convergence of the sequence of estimators generated by the algorithm. Moreover, insights on the effect of the mini-batch size on the limit distribution are presented. Finally, we illustrate how to use mini-batch sampling in practice to improve results when a constraint on the computing time is given.},
  journal = {Statistics and Computing},
  keywords = {.unlabeled},
  language = {en},
  number = {6}
}

@article{Kumar2009,
  title = {Linear-{{Time Approximation Schemes}} for {{Clustering Problems}} In},
  author = {Kumar, Amit and Sabharwal, Yogish and Sen, Sandeep},
  year = {2009},
  volume = {2},
  pages = {1--30},
  file = {/Users/ztzhang/Zotero/storage/YRPPJP7T/Kumar, Sabharwal, Sen - 2009 - Linear-Time Approximation Schemes for Clustering Problems in.pdf}
}

@article{Kundu2021,
  title = {Integrative {{Learning}} for {{Population}} of {{Dynamic Networks}} with {{Covariates}}},
  author = {Kundu, Suprateek and Ming, Jin and Nocera, Joe and McGregor, Keith M.},
  year = {2021},
  month = jan,
  abstract = {Although there is a rapidly growing literature on dynamic connectivity methods, the primary focus has been on separate network estimation for each individual, which fails to leverage common patterns of information. We propose novel graph-theoretic approaches for estimating a population of dynamic networks that are able to borrow information across multiple heterogeneous samples in an unsupervised manner and guided by covariate information. Specifically, we develop a Bayesian product mixture model that imposes independent mixture priors at each time scan and uses covariates to model the mixture weights, which results in time-varying clusters of samples designed to pool information. The computation is carried out using an efficient Expectation-Maximization algorithm. Extensive simulation studies illustrate sharp gains in recovering the true dynamic network over existing dynamic connectivity methods. An analysis of fMRI block task data with behavioral interventions reveal sub-groups of individuals having similar dynamic connectivity, and identifies intervention-related dynamic network changes that are concentrated in biologically interpretable brain regions. In contrast, existing dynamic connectivity approaches are able to detect minimal or no changes in connectivity over time, which seems biologically unrealistic and highlights the challenges resulting from the inability to systematically borrow information across samples.},
  archivePrefix = {arXiv},
  eprint = {2101.05539},
  eprinttype = {arxiv},
  journal = {arXiv:2101.05539 [stat]},
  keywords = {.unlabeled,Statistics - Methodology},
  primaryClass = {stat}
}

@article{Langendorf2021,
  title = {Empirically {{Classifying Network Mechanisms}}},
  author = {Langendorf, Ryan E. and Burgess, Matthew G.},
  year = {2021},
  month = jan,
  abstract = {Network models are used to study interconnected systems across many physical, biological, and social disciplines. Such models often assume a particular network-generating mechanism, which when fit to data produces estimates of mechanism-specific parameters that describe how systems function. For instance, a social network model might assume new individuals connect to others with probability proportional to their number of pre-existing connections ('preferential attachment'), and then estimate the disparity in interactions between famous and obscure individuals with similar qualifications. However, without a means of testing the relevance of the assumed mechanism, conclusions from such models could be misleading. Here we introduce a simple empirical approach which can mechanistically classify arbitrary network data. Our approach compares empirical networks to model networks from a user-provided candidate set of mechanisms, and classifies each network--with high accuracy--as originating from either one of the mechanisms or none of them. We tested 373 empirical networks against five of the most widely studied network mechanisms and found that most (228) were unlike any of these mechanisms. This raises the possibility that some empirical networks arise from mixtures of mechanisms. We show that mixtures are often unidentifiable because different mixtures can produce functionally equivalent networks. In such systems, which are governed by multiple mechanisms, our approach can still accurately predict out-of-sample functional properties.},
  archivePrefix = {arXiv},
  eprint = {2012.15863},
  eprinttype = {arxiv},
  journal = {arXiv:2012.15863 [cs, stat]},
  keywords = {.unlabeled,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Computation},
  primaryClass = {cs, stat}
}

@article{Lawton1971,
  title = {Self {{Modeling Curve Resolution}}},
  author = {Lawton, William H. and Sylvestre, Edward A.},
  year = {1971},
  month = aug,
  volume = {13},
  pages = {617},
  issn = {00401706},
  doi = {10.2307/1267173},
  file = {/Users/ztzhang/Zotero/storage/S85FW4N3/Lawton, Sylvestre - 1971 - Self Modeling Curve Resolution.pdf},
  journal = {Technometrics},
  number = {3}
}

@article{Lawton1972,
  title = {Self {{Modeling Nonlinear Regression}}},
  author = {Lawton, W. H. and Sylvestre, E. A. and Maggio, M. S.},
  year = {1972},
  volume = {14},
  pages = {513--532},
  issn = {15372723},
  doi = {10.1080/00401706.1972.10488942},
  abstract = {The paper is concerned with parametric models for populations of curves; i.e. models of the form yi(Z) = f(\$\th eta\$i; x) + error, i = I, 2, \textbackslash ldots, n. The shape invariant model f(\$\th eta\$i; x) = \$\th eta\$0i + \$\th eta\$1ig([x \textendash{} \$\th eta\$2i/\$\th eta\$3i) is introduced. If the function g(x) is known, then the \$\th eta\$i may be estimated by nonlinear regression. If g(x) is unknown, then the authors propose an iterative technique for simultaneous determination of the best g(x) and \$\th eta\$i. Generalizations of the shape invariant model to curve resolution are also discussed. Several applications of the method are also presented. \textcopyright{} 1972 Taylor and Francis Group, LLC.},
  file = {/Users/ztzhang/Zotero/storage/37KDQ4WE/Lawton, Sylvestre, Maggio - 1972 - Self Modeling Nonlinear Regression.pdf},
  journal = {Technometrics},
  keywords = {Curve Resolution,Least Square Splines,Mathematical Modeling,Nonlinear Regression},
  number = {3}
}

@article{Le2016,
  ids = {leOptimizationLowrankApproximation2016a},
  title = {Optimization via Low-Rank Approximation for Community Detection in Networks},
  author = {Le, Can M. and Levina, Elizaveta and Vershynin, Roman},
  year = {2016},
  month = feb,
  volume = {44},
  pages = {373--400},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {00905364},
  doi = {10.1214/15-AOS1360},
  abstract = {Community detection is one of the fundamental problems of network analysis, for which a number of methods have been proposed. Most model-based or criteria-based methods have to solve an optimization problem over a discrete set of labels to find communities, which is computationally infeasible. Some fast spectral algorithms have been proposed for specific methods or models, but only on a case-by-case basis. Here we propose a general approach for maximizing a function of a network adjacency matrix over discrete labels by projecting the set of labels onto a subspace approximating the leading eigenvectors of the expected adjacency matrix. This projection onto a low-dimensional space makes the feasible set of labels much smaller and the optimization problem much easier. We prove a general result about this method and show how to apply it to several previously proposed community detection criteria, establishing its consistency for label estimation in each case and demonstrating the fundamental connection between spectral properties of the network and various model-based approaches to community detection. Simulations and applications to real-world data are included to demonstrate our method performs well for multiple problems over a wide range of parameters.},
  file = {/Users/ztzhang/Zotero/storage/95A8LWRF/Le, Levina, Vershynin - 2016 - Optimization via low-rank approximation for community detection in networks.pdf;/Users/ztzhang/Zotero/storage/9EF83SWT/Le, Levina, Vershynin - 2016 - Optimization via low-rank approximation for community detection in networks(2).pdf},
  journal = {Annals of Statistics},
  keywords = {.Community detection,.Spectral clustering,.Stochastic block model},
  mrnumber = {MR3449772},
  number = {1},
  zmnumber = {1331.62312}
}

@article{Le2016a,
  title = {{{CONCENTRATION AND REGULARIZATION OF RANDOM GRAPHS}}},
  author = {Le, C A N M and Levina, Elizaveta and Vershynin, Roman},
  year = {2016},
  pages = {1--21},
  annotation = {\_eprint: arXiv:1506.00669v2},
  file = {/Users/ztzhang/Zotero/storage/S5FKMJ9Y/Le, Levina, Vershynin - 2016 - CONCENTRATION AND REGULARIZATION OF RANDOM GRAPHS.pdf}
}

@article{Lee2019,
  title = {A Review of Stochastic Block Models and Extensions for Graph Clustering},
  author = {Lee, Clement and Wilkinson, Darren J.},
  year = {2019},
  month = dec,
  volume = {4},
  pages = {1--50},
  publisher = {{Springer}},
  issn = {23648228},
  doi = {10.1007/s41109-019-0232-2},
  abstract = {There have been rapid developments in model-based clustering of graphs, also known as block modelling, over the last ten years or so. We review different approaches and extensions proposed for different aspects in this area, such as the type of the graph, the clustering approach, the inference approach, and whether the number of groups is selected or estimated. We also review models that combine block modelling with topic modelling and/or longitudinal modelling, regarding how these models deal with multiple types of data. How different approaches cope with various issues will be summarised and compared, to facilitate the demand of practitioners for a concise overview of the current status of these areas of literature.},
  annotation = {\_eprint: 1903.00114},
  file = {/Users/ztzhang/Zotero/storage/DGMF9CNG/Lee, Wilkinson - 2019 - A Review of Stochastic Block Models and Extensions for Graph Clustering.pdf;/Users/ztzhang/Zotero/storage/U9IJT54E/Lee, Wilkinson - 2019 - A review of stochastic block models and extensions for graph clustering(2).pdf},
  journal = {Applied Network Science},
  keywords = {.Stochastic block model,Longitudinal modelling,Mixed member-ship models,Mixed membership models,Model-based clustering,Statistical inference,Topic modelling},
  number = {1}
}

@article{Lee2020,
  title = {Model-Based Clustering of Time-Evolving Networks through Temporal Exponential-Family Random Graph Models},
  author = {Lee, Kevin H. and Xue, Lingzhou and Hunter, David R.},
  year = {2020},
  month = jan,
  volume = {175},
  pages = {104540},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2019.104540},
  abstract = {Dynamic networks are a general language for describing time-evolving complex systems, and discrete time network models provide an emerging statistical technique for various applications. It is a fundamental research question to detect a set of nodes sharing similar connectivity patterns in time-evolving networks. Our work is primarily motivated by detecting groups based on interesting features of the time-evolving networks (e.g., stability). In this work, we propose a model-based clustering framework for time-evolving networks based on discrete time exponential-family random graph models, which simultaneously allows both modeling and detecting group structure. To choose the number of groups, we use the conditional likelihood to construct an effective model selection criterion. Furthermore, we propose an efficient variational expectation\textendash maximization (EM) algorithm to find approximate maximum likelihood estimates of network parameters and mixing proportions. The power of our method is demonstrated in simulation studies and empirical applications to international trade networks and the collaboration networks of a large research university.},
  journal = {Journal of Multivariate Analysis},
  keywords = {.Exponential random graph models,.Time varying networks,Minorization–maximization,Model selection,Model-based clustering,Temporal ERGM,Time-evolving network,Variational EM algorithm},
  language = {en}
}

@article{Lee2021,
  title = {Anomaly {{Detection}} in {{Large Scale Networks}} with {{Latent Space Models}}},
  author = {Lee, Wesley and McCormick, Tyler H. and Neil, Joshua and Sodja, Cole and Cui, Yanran},
  year = {2021},
  month = jan,
  abstract = {We develop a real-time anomaly detection algorithm for directed activity on large, sparse networks. We model the propensity for future activity using a dynamic logistic model with interaction terms for sender- and receiver-specific latent factors in addition to sender- and receiver-specific popularity scores; deviations from this underlying model constitute potential anomalies. Latent nodal attributes are estimated via a variational Bayesian approach and may change over time, representing natural shifts in network activity. Estimation is augmented with a case-control approximation to take advantage of the sparsity of the network and reduces computational complexity from \$O(N\^2)\$ to \$O(E)\$, where \$N\$ is the number of nodes and \$E\$ is the number of observed edges. We run our algorithm on network event records collected from an enterprise network of over 25,000 computers and are able to identify a red team attack with half the detection rate required of the model without latent interaction terms.},
  archivePrefix = {arXiv},
  eprint = {1911.05522},
  eprinttype = {arxiv},
  journal = {arXiv:1911.05522 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Social and Information Networks,Statistics - Applications,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{Lei2016,
  title = {A Goodness-of-Fit Test for Stochastic Block Models},
  author = {Lei, Jing},
  year = {2016},
  month = feb,
  volume = {44},
  pages = {401--424},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/15-AOS1370},
  abstract = {The stochastic block model is a popular tool for studying community structures in network data. We develop a goodness-of-fit test for the stochastic block model. The test statistic is based on the largest singular value of a residual matrix obtained by subtracting the estimated block mean effect from the adjacency matrix. Asymptotic null distribution is obtained using recent advances in random matrix theory. The test is proved to have full power against alternative models with finer structures. These results naturally lead to a consistent sequential testing estimate of the number of communities.},
  journal = {Annals of Statistics},
  keywords = {.Stochastic block model},
  language = {EN},
  mrnumber = {MR3449773},
  number = {1},
  zmnumber = {1331.62283}
}

@article{Lei2018,
  title = {Network {{Representation Using Graph Root Distributions}}},
  author = {Lei, Jing},
  year = {2018},
  pages = {1--35},
  annotation = {\_eprint: arXiv:1802.09684v1},
  file = {/Users/ztzhang/Zotero/storage/ZTCU8SQS/Lei - 2018 - Network Representation Using Graph Root Distributions.pdf}
}

@article{Lei2020,
  ids = {leiConvergenceConcentrationEmpirical2020a},
  title = {Convergence and {{Concentration}} of {{Empirical Measures}} under {{Wasserstein Distance}} in {{Unbounded Functional Spaces}}},
  author = {Lei, Jing},
  year = {2020},
  abstract = {We provide upper bounds of the expected Wasserstein distance between a probability measure and its empirical version, generalizing recent results for finite dimensional Euclidean spaces and bounded functional spaces. Such a generalization can cover Euclidean spaces with large dimensionality, with the optimal dependence on the di-mensionality. Our method also covers the important case of Gaussian processes in separable Hilbert spaces, with rate-optimal upper bounds for functional data distributions whose coordinates decay geometrically or polynomially. Moreover, our bounds of the expected value can be combined with mean-concentration results to yield improved exponential tail probability bounds for the Wasserstein error of empirical measures under Bernstein-type or log Sobolev-type conditions.},
  annotation = {\_eprint: 1804.10556v2},
  archivePrefix = {arXiv},
  eprint = {1804.10556},
  eprinttype = {arxiv},
  isbn = {1804.10556v2},
  keywords = {.Concentration theory,.Empirical measures,.Empirical processes,Mathematics - Statistics Theory,Statistics - Machine Learning}
}

@article{Lei2020a,
  ids = {leiDiscussionNetworkCrossvalidation2020a},
  title = {Discussion of `{{Network}} Cross-Validation by Edge Sampling'},
  author = {Lei, J and Lin, K Z},
  year = {2020},
  month = jun,
  volume = {107},
  pages = {285--287},
  issn = {0006-3444},
  doi = {10.1093/biomet/asaa009},
  file = {/Users/ztzhang/Zotero/storage/8D9PVMJT/5837741.html;/Users/ztzhang/Zotero/storage/W7TT6JR6/5837741.html},
  journal = {Biometrika},
  keywords = {.Network cross-validation},
  number = {2}
}

@article{Lei2020b,
  title = {Cross-{{Validation With Confidence}}},
  author = {Lei, Jing},
  year = {2020},
  month = oct,
  volume = {115},
  pages = {1978--1997},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2019.1672556},
  abstract = {Cross-validation is one of the most popular model and tuning parameter selection methods in statistics and machine learning. Despite its wide applicability, traditional cross-validation methods tend to overfit, due to the ignorance of the uncertainty in the testing sample. We develop a novel statistically principled inference tool based on cross-validation that takes into account the uncertainty in the testing sample. This method outputs a set of highly competitive candidate models containing the optimal one with guaranteed probability. As a consequence, our method can achieve consistent variable selection in a classical linear regression setting, for which existing cross-validation methods require unconventional split ratios. When used for tuning parameter selection, the method can provide an alternative trade-off between prediction accuracy and model interpretability than existing variants of cross-validation. We demonstrate the performance of the proposed method in several simulated and real data examples. Supplemental materials for this article can be found online.},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2019.1672556},
  journal = {Journal of the American Statistical Association},
  keywords = {.Cross-validation,.Network cross-validation,Hypothesis testing,Model selection,Overfitting,Tuning parameter selection},
  number = {532}
}

@article{Lei2020c,
  ids = {leiConsistentCommunityDetection},
  title = {Consistent Community Detection in Multi-Layer Network Data},
  author = {Lei, Jing and Chen, Kehui and Lynch, Brian},
  year = {2020},
  pages = {1--7},
  abstract = {10 We consider multi-layer network data where the relationships between pairs of elements are reflected in multiple modalities and may be described by multivariate or even high-dimensional vectors. Under the multi-layer stochastic block model framework, we derive consistency results for a least squares estimation of memberships. Our theorems show that, as compared to single-layer community detection, a multi-layer network provides much richer information that allows 15 for consistent community detection from a much sparser network, with required edge density reduced by a factor of the square root of the number of layers. Moreover, the multi-layer framework can detect cohesive community structure across layers, which might be hard to detect by any single-layer or simple aggregation. Simulations and a data example are provided to support the theoretical results. 20},
  file = {/Users/ztzhang/Zotero/storage/EX7Q6U3X/Lei - Consistent community detection in multi-layer netw.pdf},
  journal = {Biometrika},
  keywords = {.Multilayer networks,Consistency,Some key words: Community detection,Sparse network,Tensor concentration bound}
}

@article{Li,
  title = {High-Dimensional {{Gaussian}} Graphical Models on Network-Linked Data},
  author = {Li, Tianxi and Qian, Cheng and Levina, Elizaveta and Zhu, Ji},
  pages = {45},
  abstract = {Graphical models are commonly used to represent conditional dependence relationships between variables. There are multiple methods available for exploring them from highdimensional data, but almost all of them rely on the assumption that the observations are independent and identically distributed. At the same time, observations connected by a network are becoming increasingly common, and tend to violate these assumptions. Here we develop a Gaussian graphical model for observations connected by a network with potentially different mean vectors, varying smoothly over the network. We propose an efficient estimation algorithm and demonstrate its effectiveness on both simulated and real data, obtaining meaningful and interpretable results on a statistics coauthorship network. We also prove that our method estimates both the inverse covariance matrix and the corresponding graph structure correctly under the assumption of network ``cohesion'', which refers to the empirically observed phenomenon of network neighbors sharing similar traits.},
  file = {/Users/ztzhang/Zotero/storage/CV2IAC9Y/Li et al. - High-dimensional Gaussian graphical models on netw.pdf},
  journal = {linked data},
  keywords = {.Dependent observations,.Gaussian graphical model},
  language = {en}
}

@article{Li2017,
  title = {When {{Do Birds}} of a {{Feather Flock Together}}? K-{{Means}}, {{Proximity}}, and {{Conic Programming}}},
  author = {Li, Xiaodong and Li, Yang and Ling, Shuyang and Strohmer, Thomas and Wei, Ke},
  year = {2017},
  month = oct,
  abstract = {Given a set of data, one central goal is to group them into clusters based on some notion of similarity between the individual objects. One of the most popular and widely-used approaches is k-means despite the computational hardness to find its global minimum. We study and compare the properties of different convex relaxations by relating them to corresponding proximity conditions, an idea originally introduced by Kumar and Kannan. Using conic duality theory, we present an improved proximity condition under which the Peng-Wei relaxation of k-means recovers the underlying clusters exactly. Our proximity condition improves upon Kumar and Kannan, and is comparable to that of Awashti and Sheffet where proximity conditions are established for projective k-means. In addition, we provide a necessary proximity condition for the exactness of the Peng-Wei relaxation. For the special case of equal cluster sizes, we establish a different and completely localized proximity condition under which the Amini-Levina relaxation yields exact clustering, thereby having addressed an open problem by Awasthi and Sheffet in the balanced case. Our framework is not only deterministic and model-free but also comes with a clear geometric meaning which allows for further analysis and generalization. Moreover, it can be conveniently applied to analyzing various data generative models such as the stochastic ball models and Gaussian mixture models. With this method, we improve the current minimum separation bound for the stochastic ball models and achieve the state-of-the-art results of learning Gaussian mixture models.},
  annotation = {\_eprint: 1710.06008},
  file = {/Users/ztzhang/Zotero/storage/3ZQHF5CH/Li et al. - 2017 - When Do Birds of a Feather Flock Together k-Means, Proximity, and Conic Programming(2).pdf}
}

@article{Li2018,
  ids = {liConvexRelaxationMethods2018a},
  title = {Convex {{Relaxation Methods}} for {{Community Detection}}},
  author = {Li, Xiaodong and Chen, Yudong and Xu, Jiaming},
  year = {2018},
  month = sep,
  abstract = {This paper surveys recent theoretical advances in convex optimization approaches for community detection. We introduce some important theoretical techniques and results for establishing the consistency of convex community detection under various statistical models. In particular, we discuss the basic techniques based on the primal and dual analysis. We also present results that demonstrate several distinctive advantages of convex community detection, including robustness against outlier nodes, consistency under weak assortativity, and adaptivity to heterogeneous degrees. This survey is not intended to be a complete overview of the vast literature on this fast-growing topic. Instead, we aim to provide a big picture of the remarkable recent development in this area and to make the survey accessible to a broad audience. We hope that this expository article can serve as an introductory guide for readers who are interested in using, designing, and analyzing convex relaxation methods in network analysis.},
  annotation = {\_eprint: 1810.00315},
  archivePrefix = {arXiv},
  eprint = {1810.00315},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/PJPBMGF4/Li, Chen, Xu - 2018 - Convex Relaxation Methods for Community Detection.pdf},
  keywords = {.Stochastic block model}
}

@article{Li2019,
  ids = {liNetworkCrossvalidationEdge2020},
  title = {Network Cross-Validation by Edge Sampling},
  author = {Li, Tianxi and Levina, Elizaveta and Zhu, Ji},
  year = {2019},
  pages = {1--50},
  annotation = {\_eprint: arXiv:1612.04717v6},
  archivePrefix = {arXiv},
  eprint = {1612.04717},
  eprinttype = {arxiv},
  keywords = {.Network cross-validation,Statistics - Machine Learning,Statistics - Methodology}
}

@article{Li2020,
  title = {A {{Bayesian State}}-{{Space Approach}} to {{Mapping Directional Brain Networks}}},
  author = {Li, Huazhang and Wang, Yaotian and Yan, Guofen and Sun, Yinge and Tanabe, Seiji and Liu, Chang-Chia and Quigg, Mark and Zhang, Tingting},
  year = {2020},
  month = dec,
  abstract = {The human brain is a directional network system of brain regions involving directional connectivity. Seizures are a directional network phenomenon as abnormal neuronal activities start from a seizure onset zone (SOZ) and propagate to otherwise healthy regions. To localize the SOZ of an epileptic patient, clinicians use iEEG to record the patient's intracranial brain activity in many small regions. iEEG data are high-dimensional multivariate time series. We build a state-space multivariate autoregression (SSMAR) for iEEG data to model the underlying directional brain network. To produce scientifically interpretable network results, we incorporate into the SSMAR the scientific knowledge that the underlying brain network tends to have a cluster structure. Specifically, we assign to the SSMAR parameters a stochastic-blockmodel-motivated prior, which reflects the cluster structure. We develop a Bayesian framework to estimate the SSMAR, infer directional connections, and identify clusters for the unobserved network edges. The new method is robust to violations of model assumptions and outperforms existing network methods. By applying the new method to an epileptic patient's iEEG data, we reveal seizure initiation and propagation in the patient's brain network. Our method can also accurately localize the SOZ. Overall, this paper provides a tool to study the human brain network.},
  archivePrefix = {arXiv},
  eprint = {2012.11114},
  eprinttype = {arxiv},
  journal = {arXiv:2012.11114 [stat]},
  keywords = {.unlabeled,Statistics - Applications},
  primaryClass = {stat}
}

@article{Ling2019,
  title = {Certifying {{Global Optimality}} of {{Graph Cuts}} via {{Semidefinite Relaxation}}: {{A Performance Guarantee}} for {{Spectral Clustering}}},
  author = {Ling, Shuyang and Strohmer, Thomas},
  year = {2019},
  abstract = {Spectral clustering has become one of the most widely used clustering techniques when the structure of the individual clusters is non-convex or highly anisotropic. Yet, despite its immense popularity, there exists fairly little theory about performance guarantees for spectral clustering. This issue is partly due to the fact that spectral clustering typically involves two steps which complicated its theoretical analysis: first, the eigenvectors of the associated graph Laplacian are used to embed the dataset, and second, k-means clustering algorithm is applied to the embedded dataset to get the labels. This paper is devoted to the theoretical foundations of spectral clustering and graph cuts. We consider a convex relaxation of graph cuts, namely ratio cuts and normalized cuts, that makes the usual two-step approach of spectral clustering obsolete and at the same time gives rise to a rigorous theoretical analysis of graph cuts and spectral clustering. We derive deterministic bounds for successful spectral clustering via a spectral proximity condition that naturally depends on the algebraic connectivity of each cluster and the inter-cluster connectivity. Moreover, we demonstrate by means of some popular examples that our bounds can achieve near-optimality. Our findings are also fundamental to the theoretical understanding of kernel k-means. Numerical simulations confirm and complement our analysis.},
  annotation = {\_eprint: 1806.11429v3}
}

@article{Liu2014,
  title = {An {{Asynchronous Parallel Stochastic Coordinate Descent Algorithm}}},
  author = {Liu, Ji and Wright, Stephen J. and R{\'e}, Christopher and Bittorf, Victor and Sridhar, Srikrishna},
  year = {2014},
  month = nov,
  abstract = {We describe an asynchronous parallel stochastic coordinate descent algorithm for minimizing smooth unconstrained or separably constrained functions. The method achieves a linear convergence rate on functions that satisfy an essential strong convexity property and a sublinear rate (\$1/K\$) on general convex functions. Near-linear speedup on a multicore system can be expected if the number of processors is \$O(n\^\{1/2\})\$ in unconstrained optimization and \$O(n\^\{1/4\})\$ in the separable-constrained case, where \$n\$ is the number of variables. We describe results from implementation on 40-core processors.},
  archivePrefix = {arXiv},
  eprint = {1311.1873},
  eprinttype = {arxiv},
  journal = {arXiv:1311.1873 [math]},
  keywords = {.Stochastic Coordinate Descent,.Theory,Mathematics - Optimization and Control},
  primaryClass = {math}
}

@article{Liu2018,
  title = {Global Spectral Clustering in Dynamic Networks},
  author = {Liu, Fuchen and Choi, David and Xie, Lu and Roeder, Kathryn},
  year = {2018},
  month = jan,
  volume = {115},
  pages = {927--932},
  publisher = {{National Academy of Sciences}},
  issn = {10916490},
  doi = {10.1073/pnas.1718449115},
  abstract = {Community detection is challenging when the network structure is estimated with uncertainty. Dynamic networks present additional challenges but also add information across time periods. We propose a global community detection method, persistent communities by eigenvector smoothing (PisCES), that combines information across a series of networks, longitudinally, to strengthen the inference for each period. Our method is derived from evolutionary spectral clustering and degree correction methods. Data-driven solutions to the problem of tuning parameter selection are provided. In simulations we find that PisCES performs better than competing methods designed for a low signal-to-noise ratio. Recently obtained gene expression data from rhesus monkey brains provide samples from finely partitioned brain regions over a broad time span including pre- and postnatal periods. Of interest is how gene communities develop over space and time; however, once the data are divided into homogeneous spatial and temporal periods, sample sizes are very small, making inference quite challenging. Applying PisCES to medial prefrontal cortex in monkey rhesus brains from near conception to adulthood reveals dense communities that persist, merge, and diverge over time and others that are loosely organized and short lived, illustrating how dynamic community detection can yield interesting insights into processes such as brain development.},
  file = {/Users/ztzhang/Zotero/storage/RK9WFKCP/Liu et al. - 2018 - Global spectral clustering in dynamic networks.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords = {Community detection,Dynamic networks,Gene expression networks},
  number = {5}
}

@article{Lloyd1982,
  title = {Least {{Squares Quantization}} in {{PCM}}},
  author = {Lloyd, Stuart P.},
  year = {1982},
  volume = {28},
  pages = {129--137},
  issn = {15579654},
  doi = {10.1109/TIT.1982.1056489},
  abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quantization schemes for 2b quanta, b = 1,2, {$\cdot\cdot\cdot$}, 7, are given numerically for Gaussian and for Laplacian distribution of signal amplitudes. \textcopyright 1982 IEEE},
  file = {/Users/ztzhang/Zotero/storage/8E8KNZKM/Lloyd - 1982 - Least Squares Quantization in PCM.pdf},
  journal = {IEEE Transactions on Information Theory},
  number = {2}
}

@article{Longepierre2019,
  ids = {longepierreConsistencyMaximumLikelihood2019a},
  title = {Consistency of the Maximum Likelihood and Variational Estimators in a Dynamic Stochastic Block Model},
  author = {Longepierre, L. and Matias, Catherine},
  year = {2019},
  volume = {13},
  pages = {4157--4223},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {19357524},
  doi = {10.1214/19-EJS1624},
  abstract = {We consider a dynamic version of the stochastic block model, in which the nodes are partitioned into latent classes and the connection between two nodes is drawn from a Bernoulli distribution depending on the classes of these two nodes. The temporal evolution is modeled through a hidden Markov chain on the nodes memberships. We prove the consistency (as the number of nodes and time steps increase) of the maximum likelihood and variational estimators of the model parameters, and obtain upper bounds on the rates of convergence of these estimators. We also explore the particular case where the number of time steps is fixed and connectivity parameters are allowed to vary.},
  annotation = {\_eprint: 1903.04306},
  journal = {Electronic Journal of Statistics},
  keywords = {.Stochastic block model,Dynamic network,Dynamic stochastic block model,Maximum likelihood estimation,Temporal network,Variational estimation},
  mrnumber = {MR4021264},
  number = {2},
  zmnumber = {07136615}
}

@article{Loupos,
  title = {Starting {{Cold}}: {{The Power}} of {{Social Networks}} in {{Predicting Non}}-{{Contractual Customer Behavior}}},
  author = {Loupos, Pantelis and Nathan, Alexandros and Cerf, Moran},
  abstract = {The last decade has seen a rapid emergence of non-contractual networked services. The standard approach in predicting future customer behavior in those services involves collecting data on a user's past purchase behavior, and building statistical models to extrapolate a user's actions into the future. However, this method fails in the case of newly acquired customers where you have little or no transactional data. In this work, we study the extent to which knowledge of a customer's social network can solve this cold-start problem and predict the following aspects of customer behavior: (1) activity, (2) transaction levels and (3) membership to the group of most frequent customers. We conduct a dynamic analysis on approximately one million users from the most popular peer-to-peer payment application, Venmo. Our models produce high quality forecasts and demonstrate that social networks lead to a significant boost in predictive performance primarily during the first month of a customer's lifetime. Finally, we characterize significant structural network differences between the top 10\% and bottom 90\% of most frequent customers immediately after joining the service.},
  file = {/Users/ztzhang/Zotero/storage/EV23I424/Loupos, Nathan, Cerf - Unknown - Starting Cold The Power of Social Networks in Predicting Non-Contractual Customer Behavior.pdf},
  keywords = {.Social networks,Cold-Start,Customer Behavior,Non-Contractual Settings,Predictive Analytics}
}

@article{Loupos2017,
  title = {The {{Power}} of {{Social Networks}} in {{Predicting Non}}-{{Contractual Customer Activity}}: {{Evidence}} from {{Venmo}}},
  author = {Loupos, Pantelis and Nathan, Alexandros and Cerf, Moran},
  year = {2017},
  month = sep,
  publisher = {{Elsevier BV}},
  doi = {10.2139/ssrn.3001978},
  journal = {SSRN Electronic Journal},
  keywords = {.Social networks,Cold-Start,Customer Behavior,Non-Contractual Settings,Predictive Analytics}
}

@article{Lu,
  title = {Statistical and {{Computational Guarantees}} of {{Lloyd}}'s {{Algorithm}} and Its {{Variants}}},
  author = {Lu, Yu and Zhou, Harrison H},
  abstract = {Clustering is a fundamental problem in statistics and machine learning. Lloyd's algorithm, proposed in 1957, is still possibly the most widely used clustering algorithm in practice due to its simplicity and empirical performance. However, there has been little theoretical investigation on the statistical and computational guarantees of Lloyd's algorithm. This paper is an attempt to bridge this gap between practice and theory. We investigate the performance of Lloyd's algorithm on clustering sub-Gaussian mixtures. Under an appropriate initialization for labels or centers, we show that Lloyd's algorithm converges to an exponentially small clustering error after an order of log n iterations, where n is the sample size. The error rate is shown to be minimax optimal. For the two-mixture case, we only require the initializer to be slightly better than random guess. In addition, we extend the Lloyd's algorithm and its analysis to community detection and crowdsourcing, two problems that have received a lot of attention recently in statistics and machine learning. Two variants of Lloyd's algorithm are proposed respectively for community detection and crowdsourcing. On the theoretical side, we provide statistical and computational guarantees of the two algorithms, and the results improve upon some previous signal-to-noise ratio conditions in literature for both problems. Experimental results on simulated and real data sets demonstrate competitive performance of our algorithms to the state-of-the-art methods.},
  annotation = {\_eprint: 0000.0000},
  file = {/Users/ztzhang/Zotero/storage/AIF28MIA/Lu, Zhou - Unknown - Statistical and Computational Guarantees of Lloyd's Algorithm and its Variants.pdf}
}

@article{Lubold2021,
  title = {Identifying the Latent Space Geometry of Network Models through Analysis of Curvature},
  author = {Lubold, Shane and Chandrasekhar, Arun G. and McCormick, Tyler H.},
  year = {2021},
  month = jan,
  abstract = {Statistically modeling networks, across numerous disciplines and contexts, is fundamentally challenging because of (often high-order) dependence between connections. A common approach assigns each person in the graph to a position on a low-dimensional manifold. Distance between individuals in this (latent) space is inversely proportional to the likelihood of forming a connection. The choice of the latent geometry (the manifold class, dimension, and curvature) has consequential impacts on the substantive conclusions of the model. More positive curvature in the manifold, for example, encourages more and tighter communities; negative curvature induces repulsion among nodes. Currently, however, the choice of the latent geometry is an a priori modeling assumption and there is limited guidance about how to make these choices in a data-driven way. In this work, we present a method to consistently estimate the manifold type, dimension, and curvature from an empirically relevant class of latent spaces: simply connected, complete Riemannian manifolds of constant curvature. Our core insight comes by representing the graph as a noisy distance matrix based on the ties between cliques. Leveraging results from statistical geometry, we develop hypothesis tests to determine whether the observed distances could plausibly be embedded isometrically in each of the candidate geometries. We explore the accuracy of our approach with simulations and then apply our approach to data-sets from economics and sociology as well as neuroscience.},
  archivePrefix = {arXiv},
  eprint = {2012.10559},
  eprinttype = {arxiv},
  journal = {arXiv:2012.10559 [cs, math, stat]},
  keywords = {.unlabeled,Computer Science - Social and Information Networks,Mathematics - Geometric Topology,Statistics - Applications,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, math, stat}
}

@article{Lyzinski2017,
  title = {Community {{Detection}} and {{Classification}} in {{Hierarchical Stochastic Blockmodels}}},
  author = {Lyzinski, Vince and Tang, Minh and Athreya, Avanti and Park, Youngser and Priebe, Carey E.},
  year = {2017},
  month = jan,
  volume = {4},
  pages = {13--26},
  publisher = {{IEEE Computer Society}},
  issn = {23274697},
  doi = {10.1109/TNSE.2016.2634322},
  abstract = {In disciplines as diverse as social network analysis and neuroscience, many large graphs are believed to be composed of loosely connected smaller graph primitives, whose structure is more amenable to analysis We propose a robust, scalable, integrated methodology for community detection and community comparison in graphs. In our procedure, we first embed a graph into an appropriate Euclidean space to obtain a low-dimensional representation, and then cluster the vertices into communities. We next employ nonparametric graph inference techniques to identify structural similarity among these communities. These two steps are then applied recursively on the communities, allowing us to detect more fine-grained structure. We describe a hierarchical stochastic blockmodel - namely, a stochastic blockmodel with a natural hierarchical structure - and establish conditions under which our algorithm yields consistent estimates of model parameters and motifs, which we define to be stochastically similar groups of subgraphs. Finally, we demonstrate the effectiveness of our algorithm in both simulated and real data. Specifically, we address the problem of locating similar sub-communities in a partially reconstructed Drosophila connectome and in the social network Friendster.},
  annotation = {\_eprint: 1503.02115},
  journal = {IEEE Transactions on Network Science and Engineering},
  keywords = {.Stochastic block model,classification,Community detection,hierarchical random graphs},
  number = {1}
}

@article{MacDonald2020,
  title = {Latent Space Models for Multiplex Networks with Shared Structure},
  author = {MacDonald, Peter W. and Levina, Elizaveta and Zhu, Ji},
  year = {2020},
  month = dec,
  abstract = {Latent space models are frequently used for modeling single-layer networks and include many popular special cases, such as the stochastic block model and the random dot product graph. However, they are not well-developed for more complex network structures, which are becoming increasingly common in practice. Here we propose a new latent space model for multiplex networks: multiple, heterogeneous networks observed on a shared node set. Multiplex networks can represent a network sample with shared node labels, a network evolving over time, or a network with multiple types of edges. The key feature of our model is that it learns from data how much of the network structure is shared between layers and pools information across layers as appropriate. We establish identifiability, develop a fitting procedure using convex optimization in combination with a nuclear norm penalty, and prove a guarantee of recovery for the latent positions as long as there is sufficient separation between the shared and the individual latent subspaces. We compare the model to competing methods in the literature on simulated networks and on a multiplex network describing the worldwide trade of agricultural products.},
  archivePrefix = {arXiv},
  eprint = {2012.14409},
  eprinttype = {arxiv},
  journal = {arXiv:2012.14409 [stat]},
  keywords = {.Multilayer networks},
  primaryClass = {stat}
}

@article{Mao2021,
  title = {Random {{Graph Matching}} with {{Improved Noise Robustness}}},
  author = {Mao, Cheng and Rudelson, Mark and Tikhomirov, Konstantin},
  year = {2021},
  month = jan,
  abstract = {Graph matching, also known as network alignment, refers to finding a bijection between the vertex sets of two given graphs so as to maximally align their edges. This fundamental computational problem arises frequently in multiple fields such as computer vision and biology. Recently, there has been a plethora of work studying efficient algorithms for graph matching under probabilistic models. In this work, we propose a new algorithm for graph matching and show that, for two Erd\textbackslash H\{o\}s-R\textbackslash 'enyi graphs with edge correlation \$1-\textbackslash alpha\$, our algorithm recovers the underlying matching with high probability when \$\textbackslash alpha \textbackslash le 1 / (\textbackslash log \textbackslash log n)\^C\$, where \$n\$ is the number of vertices in each graph and \$C\$ denotes a positive universal constant. This improves the condition \$\textbackslash alpha \textbackslash le 1 / (\textbackslash log n)\^C\$ achieved in previous work.},
  archivePrefix = {arXiv},
  eprint = {2101.11783},
  eprinttype = {arxiv},
  journal = {arXiv:2101.11783 [cs, math, stat]},
  keywords = {.Graph matching,Computer Science - Data Structures and Algorithms,Mathematics - Probability,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{Mardia2019,
  title = {Concentration {{Inequalities}} for the {{Empirical Distribution}}},
  author = {Mardia, Jay and Jiao, Jiantao and T{\'a}nczos, Ervin and Nowak, Robert D. and Weissman, Tsachy},
  year = {2019},
  month = oct,
  abstract = {We study concentration inequalities for the Kullback\textendash Leibler (KL) divergence between the empirical distribution and the true distribution. Applying a recursion technique, we improve over the method of types bound uniformly in all regimes of sample size n and alphabet size k, and the improvement becomes more significant when k is large. We discuss the applications of our results in obtaining tighter concentration inequalities for L1 deviations of the empirical distribution from the true distribution, and the difference between concentration around the expectation or zero. We also obtain asymptotically tight bounds on the variance of the KL divergence between the empirical and true distribution, and demonstrate their quantitatively different behaviors between small and large sample sizes compared to the alphabet size.},
  archivePrefix = {arXiv},
  eprint = {1809.06522},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/UIT452T2/Mardia et al. - 2019 - Concentration Inequalities for the Empirical Distr.pdf},
  journal = {arXiv:1809.06522 [cs, math, stat]},
  keywords = {.Concentration theory,.Empirical measures,.Empirical processes,Computer Science - Information Theory,Mathematics - Statistics Theory},
  language = {en},
  primaryClass = {cs, math, stat}
}

@techreport{Mardia2019a,
  title = {Concentration {{Inequalities}} for the {{Empirical Distribution}} of {{Discrete Distributions}} : {{Beyond}} the {{Method}} of {{Types}}},
  author = {Mardia, Jay and Jiao, Jiantao and T{\'a}nczos, Ervin and Nowak, Robert D and Weissman, Tsachy},
  year = {2019},
  abstract = {We study concentration inequalities for the Kullback-Leibler (KL) divergence between the empirical distribution and the true distribution. Applying a recursion technique, we improve over the method of types bound uniformly in all regimes of sample size n and alphabet size k, and the improvement becomes more significant when k is large. We discuss the applications of our results in obtaining tighter concentration inequalities for L 1 deviations of the empirical distribution from the true distribution, and the difference between concentration around the expectation or zero. We also obtain asymptotically tight bounds on the variance of the KL divergence between the empirical and true distribution, and demonstrate their quantitatively different behaviors between small and large sample sizes compared to the alphabet size.},
  annotation = {\_eprint: 1809.06522v2}
}

@article{Mariadassou2010,
  title = {Uncovering Latent Structure in Valued Graphs: {{A}} Variational Approach},
  shorttitle = {Uncovering Latent Structure in Valued Graphs},
  author = {Mariadassou, Mahendra and Robin, St{\'e}phane and Vacher, Corinne},
  year = {2010},
  month = jun,
  volume = {4},
  pages = {715--742},
  issn = {1932-6157},
  doi = {10.1214/10-AOAS361},
  abstract = {As more and more network-structured data sets are available, the statistical analysis of valued graphs has become common place. Looking for a latent structure is one of the many strategies used to better understand the behavior of a network. Several methods already exist for the binary case. We present a model-based strategy to uncover groups of nodes in valued graphs. This framework can be used for a wide span of parametric random graphs models and allows to include covariates. Variational tools allow us to achieve approximate maximum likelihood estimation of the parameters of these models. We provide a simulation study showing that our estimation method performs well over a broad range of situations. We apply this method to analyze host--parasite interaction networks in forest ecosystems.},
  archivePrefix = {arXiv},
  eprint = {1011.1813},
  eprinttype = {arxiv},
  journal = {The Annals of Applied Statistics},
  keywords = {.Stochastic block model},
  number = {2}
}

@article{Matias2016,
  title = {Supplementary Material for: {{A}} Semiparametric Extension of the Stochastic Block Model for Longitudinal Networks},
  author = {Matias, C and Rebafka, T and Villers, F},
  year = {2016},
  volume = {1},
  pages = {1--25},
  file = {/Users/ztzhang/Zotero/storage/8GHM8EQN/Matias, Rebafka, Villers - 2016 - Supplementary material for A semiparametric extension of the stochastic block model for longitudina(2).pdf;/Users/ztzhang/Zotero/storage/JREW5I74/Matias, Rebafka, Villers - 2016 - Supplementary material for A semiparametric extension of the stochastic block model for longitudinal n.pdf},
  journal = {Advance Access publication on},
  number = {1}
}

@article{Matias2017,
  ids = {matiasStatisticalClusteringTemporal2016},
  title = {Statistical Clustering of Temporal Networks through a Dynamic Stochastic Block Model},
  author = {Matias, Catherine and Miele, Vincent},
  year = {2017},
  month = sep,
  volume = {79},
  pages = {1119--1141},
  issn = {13697412},
  doi = {10.1111/rssb.12200},
  abstract = {Statistical node clustering in discrete time dynamic networks is an emerging field that raises many challenges. Here, we explore statistical properties and frequentist inference in a model that combines a stochastic block model (SBM) for its static part with independent Markov chains for the evolution of the nodes groups through time. We model binary data as well as weighted dynamic random graphs (with discrete or continuous edges values). Our approach, motivated by the importance of controlling for label switching issues across the different time steps, focuses on detecting groups characterized by a stable within group connectivity behavior. We study identifiability of the model parameters , propose an inference procedure based on a variational expectation maximization algorithm as well as a model selection criterion to select for the number of groups. We carefully discuss our initialization strategy which plays an important role in the method and compare our procedure with existing ones on synthetic datasets. We also illustrate our approach on dynamic contact networks, one of encounters among high school students and two others on animal interactions. An implementation of the method is available as a R package called dynsbm.},
  annotation = {\_eprint: 1506.07464v2},
  archivePrefix = {arXiv},
  eprint = {1506.07464},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/ABQITTVB/Matias, Miele - 2016 - Statistical clustering of temporal networks through a dynamic stochastic block model.pdf},
  isbn = {1506.07464v2},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {.Stochastic block model,()},
  number = {4}
}

@article{Matias2018,
  ids = {matiasSemiparametricExtensionStochastic2017},
  title = {A Semiparametric Extension of the Stochastic Block Model for Longitudinal Networks},
  author = {Matias, Catherine and Rebafka, Tabea and Villers, Fanny},
  year = {2018},
  volume = {105},
  pages = {665--680},
  issn = {0006-3444},
  doi = {10.1093/biomet/asy016},
  abstract = {To model recurrent interaction events in continuous time, an extension of the stochastic block model is proposed where every individual belongs to a latent group and interactions between two individuals follow a conditional inhomogeneous Poisson process with intensity driven by the individuals' latent groups. The model is shown to be identifiable and its estimation is based on a semiparametric variational expectation-maximization algorithm. Two versions of the method are developed, using either a nonparametric histogram approach (with an adaptive choice of the partition size) or kernel intensity estimators. The number of latent groups can be selected by an integrated classification likelihood criterion. Finally, we demonstrate the performance of our procedure on synthetic experiments, analyse two datasets to illustrate the utility of our approach and comment on competing methods.},
  annotation = {\_eprint: 1512.07075},
  archivePrefix = {arXiv},
  eprint = {1512.07075},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/7T5M6V9D/Matias, Rebafka, Villers - 2018 - A semiparametric extension of the stochastic block model for longitudinal networks.pdf},
  journal = {Biometrika},
  keywords = {.Stochastic block model},
  number = {3}
}

@article{Matrix1983,
  title = {Simulation},
  author = {Matrix, Incomplete},
  year = {1983},
  pages = {1--8},
  file = {/Users/ztzhang/Zotero/storage/U9L4RA9L/Matrix - 1983 - Simulation.pdf}
}

@article{Matrix2019,
  title = {Generating the {{Incomplete Matrix}}},
  author = {Matrix, Incomplete},
  year = {2019},
  pages = {1--8},
  file = {/Users/ztzhang/Zotero/storage/FW8J56IQ/Matrix - 2019 - Generating the Incomplete Matrix.pdf}
}

@article{Meinshausen2006,
  title = {High-Dimensional Graphs and Variable Selection with the {{Lasso}}},
  author = {Meinshausen, Nicolai and B{\"u}hlmann, Peter},
  year = {2006},
  month = jun,
  volume = {34},
  pages = {1436--1462},
  issn = {00905364},
  doi = {10.1214/009053606000000281},
  abstract = {The pattern of zero entries in the inverse covariance matrix of a multivariate normal distribution corresponds to conditional independence restrictions between variables. Covariance selection aims at estimating those structural zeros from data. We show that neighborhood selection with the Lasso is a computationally attractive alternative to standard covariance selection for sparse high-dimensional graphs. Neighborhood selection estimates the conditional independence restrictions separately for each node in the graph and is hence equivalent to variable selection for Gaussian linear models. We show that the proposed neighborhood selection scheme is consistent for sparse high-dimensional graphs. Consistency hinges on the choice of the penalty parameter. The oracle value for optimal prediction does not lead to a consistent neighborhood estimate. Controlling instead the probability of falsely joining some distinct connectivity components of the graph, consistent estimation for sparse graphs is achieved (with exponential rates), even when the number of variables grows as the number of observations raised to an arbitrary power.},
  journal = {Annals of Statistics},
  keywords = {Covariance selection,Gaussian graphical models,Linear regression,Penalized regression},
  number = {3}
}

@article{Menardi2021,
  title = {Density-Based Clustering of Social Networks},
  author = {Menardi, Giovanna and De Stefano, Domenico},
  year = {2021},
  month = jan,
  abstract = {The idea underlying the modal formulation of density-based clustering is to associate groups with the regions around the modes of the probability density function underlying the data. This correspondence between clusters and dense regions in the sample space is here exploited to discuss an extension of this approach to the analysis of social networks. Such extension seems particularly appealing: conceptually, the notion of high-density cluster fits well the one of community in a network, regarded to as a collection of individuals with dense local ties in its neighbourhood. The lack of a probabilistic notion of density in networks is turned into a major strength of the proposed method, where node-wise measures that quantify the role and position of actors may be used to derive different community configurations. The approach allows for the identification of a hierarchical structure of clusters, which may catch different degrees of resolution of the clustering structure. This feature well fits the nature of social networks, disentangling a different involvement of individuals in social aggregations.},
  archivePrefix = {arXiv},
  eprint = {2101.08334},
  eprinttype = {arxiv},
  journal = {arXiv:2101.08334 [cs, stat]},
  keywords = {62P25,Computer Science - Social and Information Networks,Statistics - Applications},
  primaryClass = {cs, stat}
}

@article{Miao2021,
  title = {Informative Core Identification in Complex Networks},
  author = {Miao, Ruizhong and Li, Tianxi},
  year = {2021},
  month = jan,
  abstract = {In network analysis, the core structure of modeling interest is usually hidden in a larger network in which most structures are not informative. The noise and bias introduced by the non-informative component in networks can obscure the salient structure and limit many network modeling procedures' effectiveness. This paper introduces a novel core-periphery model for the non-informative periphery structure of networks without imposing a specific form for the informative core structure. We propose spectral algorithms for core identification as a data preprocessing step for general downstream network analysis tasks based on the model. The algorithm enjoys a strong theoretical guarantee of accuracy and is scalable for large networks. We evaluate the proposed method by extensive simulation studies demonstrating various advantages over many traditional core-periphery methods. The method is applied to extract the informative core structure from a citation network and give more informative results in the downstream hierarchical community detection.},
  archivePrefix = {arXiv},
  eprint = {2101.06388},
  eprinttype = {arxiv},
  journal = {arXiv:2101.06388 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{Negahban2012,
  title = {A {{Unified Framework}} for {{High}}-{{Dimensional Analysis}} of \${{M}}\$-{{Estimators}} with {{Decomposable Regularizers}}},
  author = {Negahban, Sahand N. and Ravikumar, Pradeep and Wainwright, Martin J. and Yu, Bin},
  year = {2012},
  month = nov,
  volume = {27},
  pages = {538--557},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/12-STS400},
  abstract = {High-dimensional statistical inference deals with models in which the the number of parameters ppp is comparable to or larger than the sample size nnn. Since it is usually impossible to obtain consistent procedures unless p/n\textrightarrow 0p/n\textrightarrow 0p/n\textbackslash rightarrow0, a line of recent work has studied models with various types of low-dimensional structure, including sparse vectors, sparse and structured matrices, low-rank matrices and combinations thereof. In such settings, a general approach to estimation is to solve a regularized optimization problem, which combines a loss function measuring how well the model fits the data with some regularization function that encourages the assumed structure. This paper provides a unified framework for establishing consistency and convergence rates for such regularized MMM-estimators under high-dimensional scaling. We state one main theorem and show how it can be used to re-derive some existing results, and also to obtain a number of new results on consistency and convergence rates, in both {$\mathscr{l}$}2{$\mathscr{l}$}2\textbackslash ell\_\{2\}-error and related norms. Our analysis also identifies two key properties of loss and regularization functions, referred to as restricted strong convexity and decomposability, that ensure corresponding regularized MMM-estimators have fast convergence rates and which are optimal in many well-studied cases.},
  journal = {Statistical Science},
  keywords = {.Consistency theory,.Convergence rate,.Regularized M-estimators,.Theory,$\\ell_{1}$-regularization,$M$-estimator,group Lasso,High-dimensional statistics,Lasso,nuclear norm,sparsity},
  language = {EN},
  mrnumber = {MR3025133},
  number = {4},
  zmnumber = {1331.62350}
}

@article{Neuristique,
  title = {Convergence {{Properties}} of the {{K}}-{{Means Algorithms}}},
  author = {Neuristique, Leon Bottou and Bengio, Yoshua},
  abstract = {This paper studies the convergence properties of the well known K-Means clustering algorithm. The K-Means algorithm can be described either as a gradient descent algorithm or by slightly extending the mathematics of the EM algorithm to this hard threshold case. We show that the K-Means algorithm actually minimizes the quantization error using the very fast Newton algorithm.},
  file = {/Users/ztzhang/Zotero/storage/DP7WF2ZQ/Neuristique, Bengio - Unknown - Convergence Properties of the K-Means Algorithms.pdf}
}

@article{Newman,
  title = {Finding and Evaluating Community Structure in Networks},
  author = {Newman, M E J and Girvan, M},
  doi = {10.1103/PhysRevE.69.026113},
  abstract = {We propose and study a set of algorithms for discovering community structure in networks-natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using any one of a number of possible ''betweenness'' measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems.},
  file = {/Users/ztzhang/Zotero/storage/ZIWFEMI8/Newman, Girvan - Unknown - Finding and evaluating community structure in networks.pdf},
  keywords = {0510a,8920Hh,numbers: 8975Hc}
}

@article{Newman2018,
  title = {Estimating Network Structure from Unreliable Measurements},
  author = {Newman, M. E.J.},
  year = {2018},
  month = dec,
  volume = {98},
  publisher = {{American Physical Society}},
  issn = {24700053},
  doi = {10.1103/PhysRevE.98.062321},
  abstract = {Most empirical studies of networks assume that the network data we are given represent a complete and accurate picture of the nodes and edges in the system of interest, but in real-world situations this is rarely the case. More often the data only specify the network structure imperfectly \textendash{} like data in essentially every other area of empirical science, network data are prone to measurement error and noise. At the same time, the data may be richer than simple network measurements, incorporating multiple measurements, weights, lengths or strengths of edges, node or edge labels, or annotations of various kinds. Here we develop a general method for making estimates of network structure and properties using any form of network data, simple or complex, when the data are unreliable, and give example applications to a selection of social and biological networks.},
  file = {/Users/ztzhang/Zotero/storage/CWPCNEMX/Newman - 2018 - Estimating network structure from unreliable measurements.pdf},
  journal = {Physical Review E},
  number = {6}
}

@article{Ng,
  title = {On {{Spectral Clustering}}: {{Analysis}} and an Algorithm},
  author = {Ng, Andrew Y and Jordan, Michael I and Weiss, Yair},
  pages = {8},
  abstract = {Despite many empirical successes of spectral clustering methodsalgorithms that cluster points using eigenvectors of matrices derived from the data- there are several unresolved issues. First, there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.},
  file = {/Users/ztzhang/Zotero/storage/L357TDSW/Ng et al. - On Spectral Clustering Analysis and an algorithm.pdf},
  keywords = {.Stochastic block model},
  language = {en}
}

@article{Ngo2012,
  title = {Scaled Gradients on {{Grassmann}} Manifolds for Matrix Completion},
  author = {Ngo, Thanh T. and Saad, Yousef},
  year = {2012},
  volume = {2},
  pages = {1412--1420},
  issn = {10495258},
  abstract = {This paper describes gradient methods based on a scaled metric on the Grassmann manifold for low-rank matrix completion. The proposed methods significantly improve canonical gradient methods, especially on ill-conditioned matrices, while maintaining established global convegence and exact recovery guarantees. A connection between a form of subspace iteration for matrix completion and the scaled gradient descent procedure is also established. The proposed conjugate gradient method based on the scaled gradient outperforms several existing algorithms for matrix completion and is competitive with recently proposed methods.},
  file = {/Users/ztzhang/Zotero/storage/T7DADZD2/Ngo, Saad - 2012 - Scaled gradients on Grassmann manifolds for matrix completion.pdf},
  isbn = {9781627480031},
  journal = {Advances in Neural Information Processing Systems}
}

@article{Nie2020,
  title = {Bayesian {{Bootstrap Spike}}-and-{{Slab LASSO}}},
  author = {Nie, Lizhen and Ro{\v c}kov{\'a}, Veronika},
  year = {2020},
  month = nov,
  abstract = {The impracticality of posterior sampling has prevented the widespread adoption of spike-and-slab priors in high-dimensional applications. To alleviate the computational burden, optimization strategies have been proposed that quickly find local posterior modes. Trading off uncertainty quantification for computational speed, these strategies have enabled spike-and-slab deployments at scales that would be previously unfeasible. We build on one recent development in this strand of work: the Spike-and-Slab LASSO procedure of Ro\textbackslash v\{c\}kov\textbackslash '\{a\} and George (2018). Instead of optimization, however, we explore multiple avenues for posterior sampling, some traditional and some new. Intrigued by the speed of Spike-and-Slab LASSO mode detection, we explore the possibility of sampling from an approximate posterior by performing MAP optimization on many independently perturbed datasets. To this end, we explore Bayesian bootstrap ideas and introduce a new class of jittered Spike-and-Slab LASSO priors with random shrinkage targets. These priors are a key constituent of the Bayesian Bootstrap Spike-and-Slab LASSO (BB-SSL) method proposed here. BB-SSL turns fast optimization into approximate posterior sampling. Beyond its scalability, we show that BB-SSL has a strong theoretical support. Indeed, we find that the induced pseudo-posteriors contract around the truth at a near-optimal rate in sparse normal-means and in high-dimensional regression. We compare our algorithm to the traditional Stochastic Search Variable Selection (under Laplace priors) as well as many state-of-the-art methods for shrinkage priors. We show, both in simulations and on real data, that our method fares superbly in these comparisons, often providing substantial computational gains.},
  archivePrefix = {arXiv},
  eprint = {2011.14279},
  eprinttype = {arxiv},
  journal = {arXiv:2011.14279 [stat]},
  keywords = {.unlabeled,Statistics - Computation,Statistics - Methodology},
  primaryClass = {stat}
}

@article{Nowicki2001,
  ids = {nowickiEstimationPredictionStochastic2001a},
  title = {Estimation and {{Prediction}} for {{Stochastic Blockstructures}}},
  author = {Nowicki, Krzysztof and Snijders, Tom A B},
  year = {2001},
  volume = {96},
  pages = {1077--1087},
  publisher = {{Taylor \& Francis}},
  file = {/Users/ztzhang/Zotero/storage/SILTUI6F/Nowicki and Snijders - 2001 - Estimation and Prediction for Stochastic Blockstru.pdf;/Users/ztzhang/Zotero/storage/VNHJHJCA/Nowicki, Snijders - 2001 - Estimation and Prediction for Stochastic Blockstructures.pdf},
  journal = {Journal of the American Statistical Association},
  keywords = {.Stochastic block model}
}

@article{Olhede2014,
  title = {Network Histograms and Universality of Blockmodel Approximation},
  author = {Olhede, S. C. and Wolfe, P. J.},
  year = {2014},
  month = oct,
  volume = {111},
  pages = {14722--14727},
  publisher = {{Proceedings of the National Academy of Sciences}},
  issn = {0027-8424},
  doi = {10.1073/pnas.1400374111},
  abstract = {In this article we introduce the network histogram: a statistical summary of network interactions, to be used as a tool for exploratory data analysis. A network histogram is obtained by fitting a stochastic blockmodel to a single observation of a network dataset. Blocks of edges play the role of histogram bins, and community sizes that of histogram bandwidths or bin sizes. Just as standard histograms allow for varying bandwidths, different blockmodel estimates can all be considered valid representations of an underlying probability model, subject to bandwidth constraints. Here we provide methods for automatic bandwidth selection, by which the network histogram approximates the generating mechanism that gives rise to exchangeable random graphs. This makes the blockmodel a universal network representation for unlabeled graphs. With this insight, we discuss the interpretation of network communities in light of the fact that many different community assignments can all give an equally valid representation of such a network. To demonstrate the fidelity-versus-interpretability tradeoff inherent in considering different numbers and sizes of communities, we analyze two publicly available networks - political weblogs and student friendships - and discuss how to interpret the network histogram when additional information related to node and edge labeling is present.},
  journal = {Proceedings of the National Academy of Sciences},
  number = {41}
}

@article{Pal2020,
  title = {Community Detection in the Sparse Hypergraph Stochastic Block Model},
  author = {Pal, Soumik and Zhu, Yizhe},
  year = {2020},
  month = dec,
  abstract = {We consider the community detection problem in sparse random hypergraphs. Angelini et al. (2015) conjectured the existence of a sharp threshold on model parameters for community detection in sparse hypergraphs generated by a hypergraph stochastic block model. We solve the positive part of the conjecture for the case of two blocks: above the threshold, there is a spectral algorithm which asymptotically almost surely constructs a partition of the hypergraph correlated with the true partition. Our method is a generalization to random hypergraphs of the method developed by Massouli\textbackslash '\{e\} (2014) for sparse random graphs.},
  archivePrefix = {arXiv},
  eprint = {1904.05981},
  eprinttype = {arxiv},
  journal = {arXiv:1904.05981 [cs, math, stat]},
  keywords = {.Community detection,.Hypergraph,.Stochastic block model,.Theory,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Mathematics - Combinatorics,Mathematics - Probability,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{Paninski2004,
  title = {Maximum Likelihood Estimation of Cascade Point-Process Neural Encoding Models},
  author = {Paninski, Liam},
  year = {2004},
  volume = {15},
  pages = {243--262},
  publisher = {{Institute of Physics Publishing}},
  issn = {0954898X},
  doi = {10.1088/0954-898X_15_4_002},
  abstract = {Recent work has examined the estimation of models of stimulus-driven neural activity in which some linear filtering process is followed by a nonlinear, probabilistic spiking stage. We analyze the estimation of one such model for which this nonlinear step is implemented by a known parametric function; the assumption that this function is known speeds the estimation process considerably. We investigate the shape of the likelihood function for this type of model, give a simple condition on the nonlinearity ensuring that no non-global local maxima exist in the likelihood-leading, in turn, to efficient algorithms for the computation of the maximum likelihood estimator-and discuss the implications for the form of the allowed nonlinearities. Finally, we note some interesting connections between the likelihood-based estimators and the classical spike-triggered average estimator, discuss some useful extensions of the basic model structure, and provide two novel applications to physiological data.},
  file = {/Users/ztzhang/Zotero/storage/XV387Y59/Paninski - 2004 - Maximum likelihood estimation of cascade point-process neural encoding models.pdf},
  journal = {Network: Computation in Neural Systems},
  number = {4}
}

@article{Panzarasa2009,
  title = {Patterns and Dynamics of Users' Behavior and Interaction: {{Network}} Analysis of an Online Community},
  shorttitle = {Patterns and Dynamics of Users' Behavior and Interaction},
  author = {Panzarasa, Pietro and Opsahl, Tore and Carley, Kathleen M.},
  year = {2009},
  volume = {60},
  pages = {911--932},
  issn = {1532-2890},
  doi = {10.1002/asi.21015},
  abstract = {This research draws on longitudinal network data from an online community to examine patterns of users' behavior and social interaction, and infer the processes underpinning dynamics of system use. The online community represents a prototypical example of a complex evolving social network in which connections between users are established over time by online messages. We study the evolution of a variety of properties since the inception of the system, including how users create, reciprocate, and deepen relationships with one another, variations in users' gregariousness and popularity, reachability and typical distances among users, and the degree of local redundancy in the system. Results indicate that the system is a ``small world'' characterized by the emergence, in its early stages, of a hub-dominated structure with heterogeneity in users' behavior. We investigate whether hubs are responsible for holding the system together and facilitating information flow, examine first-mover advantages underpinning users' ability to rise to system prominence, and uncover gender differences in users' gregariousness, popularity, and local redundancy. We discuss the implications of the results for research on system use and evolving social networks, and for a host of applications, including information diffusion, communities of practice, and the security and robustness of information systems.},
  annotation = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21015},
  journal = {Journal of the American Society for Information Science and Technology},
  language = {en},
  number = {5}
}

@article{Papamichalis2020,
  title = {Robustness on {{Networks}}},
  author = {Papamichalis, Marios and Lunagomez, Simon and Wolfe, Patrick J.},
  year = {2020},
  month = dec,
  abstract = {We adopt the statistical framework on robustness proposed by Watson and Holmes in 2016 and then tackle the practical challenges that hinder its applicability to network models. The goal is to evaluate how the quality of an inference for a network feature degrades when the assumed model is misspecified. Decision theory methods aimed to identify model missespecification are applied in the context of network data with the goal of investigating the stability of optimal actions to perturbations to the assumed model. Here the modified versions of the model are contained within a well defined neighborhood of model space. Our main challenge is to combine stochastic optimization and graph limits tools to explore the model space. As a result, a method for robustness on exchangeable random networks is developed. Our approach is inspired by recent developments in the context of robustness and recent works in the robust control, macroeconomics and financial mathematics literature and more specifically and is based on the concept of graphon approximation through its empirical graphon.},
  archivePrefix = {arXiv},
  eprint = {2012.02914},
  eprinttype = {arxiv},
  journal = {arXiv:2012.02914 [math, stat]},
  keywords = {.unlabeled,Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{Passino2021,
  title = {Mutually Exciting Point Process Graphs for Modelling Dynamic Networks},
  author = {Passino, Francesco Sanna and Heard, Nicholas A.},
  year = {2021},
  month = feb,
  abstract = {A new class of models for dynamic networks is proposed, called mutually exciting point process graphs (MEG), motivated by a practical application in computer network security. MEG is a scalable network-wide statistical model for point processes with dyadic marks, which can be used for anomaly detection when assessing the significance of previously unobserved connections. The model combines mutually exciting point processes to estimate dependencies between events and latent space models to infer relationships between the nodes. The intensity functions for each network edge are parameterised exclusively by node-specific parameters, which allows information to be shared across the network. Fast inferential procedures using modern gradient ascent algorithms are exploited. The model is tested on simulated graphs and real world computer network datasets, demonstrating excellent performance.},
  archivePrefix = {arXiv},
  eprint = {2102.06527},
  eprinttype = {arxiv},
  journal = {arXiv:2102.06527 [cs, stat]},
  keywords = {.Dynamic network,.Hawkes processes,.Latent space model,.Time varying networks,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Paul,
  ids = {paulRandomEffectsStochastic2020},
  title = {A {{RANDOM EFFECTS STOCHASTIC BLOCK MODEL FOR JOINT COMMUNITY DETECTION IN MULTIPLE NETWORKS WITH APPLICATIONS TO NEUROIMAGING}} *},
  author = {Paul, Subhadeep and Chen, Yuguo},
  abstract = {To analyze data from multi-subject experiments in neuroimaging studies, we develop a modeling framework for joint community detection in a group of related networks that can be considered as a sample from a population of networks. The proposed random effects stochas-tic block model facilitates the study of group differences and subject-specific variations in the community structure. The model proposes a putative mean community structure which is representative of the group or the population under consideration, but is not the community structure of any individual component network. Instead, the community memberships of nodes vary in each component network with a transition matrix, thus modeling the variation in community structure across a group of subjects. To estimate the quantities of interest, we propose two methods: a variational EM algorithm, and a model-free "two-step" method called Co-OSNTF which is based on non-negative matrix factorization. We also develop a resampling-based hypothesis test for differences between community structure in two populations both at the whole network level and node level. The methodology is applied to the COBRE dataset, a publicly available fMRI dataset from multi-subject experiments involving schizophrenia patients. Our methods reveal an overall putative community structure representative of the group as well as subject-specific variations within each of the two groups, healthy controls and schizophrenia patients. The model has good predictive ability for predicting community structure in subjects from the same population but outside the training sample. Using our network level hypothesis tests we are able to ascertain statistically significant difference in community structure between the two groups, while our node level tests help determine the nodes that are driving the difference.},
  annotation = {\_eprint: 1805.02292v2},
  archivePrefix = {arXiv},
  eprint = {1805.02292},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/WAQNP6JP/Paul, Chen - Unknown - A RANDOM EFFECTS STOCHASTIC BLOCK MODEL FOR JOINT COMMUNITY DETECTION IN MULTIPLE NETWORKS WITH APPLICATIONS TO N.pdf},
  keywords = {.Multi-subject network}
}

@article{Paul2020,
  title = {Null {{Models}} and {{Community Detection}} in {{Multi}}-{{Layer Networks}}},
  author = {Paul, Subhadeep and Chen, Yuguo},
  year = {2020},
  month = dec,
  abstract = {Multi-layer networks are networks on a set of entities (nodes) with multiple types of relations (edges) among them where each type of relation/interaction is represented as a network layer. As with single layer networks, community detection is an important task in multi-layer networks. A large group of popular community detection methods in networks are based on optimizing a quality function known as the modularity score, which is a measure of presence of modules or communities in networks. Hence a first step in community detection is defining a suitable modularity score that is appropriate for the network in question. Here we introduce several multi-layer network modularity measures under different null models of the network, motivated by empirical observations in networks from a diverse field of applications. In particular we define the multi-layer configuration model, the multi-layer expected degree model and their various modifications as null models for multi-layer networks to derive different modularities. The proposed modularities are grouped into two categories. The first category, which is based on degree corrected multi-layer stochastic block model, has the multi-layer expected degree model as their null model. The second category, which is based on multi-layer extensions of Newman-Girvan modularity, has the multi-layer configuration model as their null model. These measures are then optimized to detect the optimal community assignment of nodes. We compare the effectiveness of the measures in community detection in simulated networks and then apply them to four real networks.},
  archivePrefix = {arXiv},
  eprint = {1608.00623},
  eprinttype = {arxiv},
  journal = {arXiv:1608.00623 [physics, stat]},
  keywords = {.Multilayer networks},
  primaryClass = {physics, stat}
}

@article{Pavlovic2020,
  ids = {pavlovicMultisubjectStochasticBlockmodels2020a},
  title = {Multi-Subject {{Stochastic Blockmodels}} for Adaptive Analysis of Individual Differences in Human Brain Network Cluster Structure},
  author = {Pavlovi{\'c}, Dragana M. and Guillaume, Bryan R.L. and Towlson, Emma K. and Kuek, Nicole M.Y. and Afyouni, Soroosh and V{\'e}rtes, Petra E. and Yeo, B. T.Thomas and Bullmore, Edward T. and Nichols, Thomas E.},
  year = {2020},
  month = oct,
  volume = {220},
  pages = {116611},
  publisher = {{Academic Press Inc.}},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2020.116611},
  abstract = {There is considerable interest in elucidating the cluster structure of brain networks in terms of modules, blocks or clusters of similar nodes. However, it is currently challenging to handle data on multiple subjects since most of the existing methods are applicable only on a subject-by-subject basis or for analysis of an average group network. The main limitation of per-subject models is that there is no obvious way to combine the results for group comparisons, and of group-averaged models that they do not reflect the variability between subjects. Here, we propose two new extensions of the classical Stochastic Blockmodel (SBM) that use a mixture model to estimate blocks or clusters of connected nodes, combined with a regression model to capture the effects of subject-level covariates on individual differences in cluster structure. The proposed Multi-Subject Stochastic Blockmodels (MS-SBMs) can flexibly account for between-subject variability in terms of homogeneous or heterogeneous covariate effects on connectivity using subject demographics such as age or diagnostic status. Using synthetic data, representing a range of block sizes and cluster structures, we investigate the accuracy of the estimated MS-SBM parameters as well as the validity of inference procedures based on the Wald, likelihood ratio and permutation tests. We show that the proposed multi-subject SBMs recover the true cluster structure of synthetic networks more accurately and adaptively than standard methods for modular decomposition (i.e. the Fast Louvain and Newman Spectral algorithms). Permutation tests of MS-SBM parameters were more robustly valid for statistical inference and Type I error control than tests based on standard asymptotic assumptions. Applied to analysis of multi-subject resting-state fMRI networks (13 healthy volunteers; 12 people with schizophrenia; n=268 brain regions), we show that Heterogeneous Stochastic Blockmodel (Het-SBM) identifies a range of network topologies simultaneously, including modular and core structures.},
  journal = {NeuroImage},
  keywords = {.Multi-subject network,.Stochastic block model,Community detection,Firth estimation,Integrated classification likelihood criterion,Likelihood ratio,Mixture models,Modularity,Network analysis,Permutation test,Variational approximation,Wald test},
  pmid = {32058004}
}

@article{Peng2005,
  title = {Approximating {{K}}-Means-Type Clustering via Semidefinite Programming},
  author = {Peng, Jiming and Wei, Yu},
  year = {2005},
  abstract = {One of the fundamental clustering problems is to assign n points into k clusters based on the minimal sum-of-squares(MSSC), which is known to be NP-hard. In this paper, by using matrix arguments, we first model MSSC as a so-called 0-1 semidefinite programming (SDP). We show that our 0-1 SDP model provides an unified framework for several clustering approaches such as normalized k-cut and spectral clustering. Moreover, the 0-1 SDP model allows us to solve the underlying problem approximately via the relaxed linear and semidefinite programming. Secondly, we consider the issue of how to extract a feasible solution of the original 0-1 SDP model from the approximate solution of the relaxed SDP problem. By using principal component analysis, we develop a rounding procedure to construct a feasible partitioning from a solution of the relaxed problem. In our rounding procedure, we need to solve a K-means clustering problem in k-1 , which can be solved in O(n k 2 -2k+2) time. In case of bi-clustering, the running time of our rounding procedure can be reduced to O(n log n). We show that our algorithm can provide a 2-approximate solution to the original problem. Promising numerical results for bi-clustering based on our new method are reported.},
  keywords = {0-1 SDP,Approximation,K-means clustering,Principal component analysis,Semi-definite programming}
}

@techreport{Pensky2017,
  title = {Spectral Clustering in the Dynamic Stochastic Block Model},
  author = {Pensky, Marianna and Zhang, Teng},
  year = {2017},
  abstract = {In the present paper, we studied a Dynamic Stochastic Block Model (DSBM) under the assumptions that the connection probabilities, as functions of time, are smooth and that at most s nodes can switch their class memberships between two consecutive time points. We estimate the edge probability tensor by a kernel-type procedure and extract the group memberships of the nodes by spectral clustering. The procedure is computationally viable, adaptive to the unknown smoothness of the functional connection probabilities, to the rate s of membership switching and to the unknown number of clusters. In addition, it is accompanied by non-asymptotic guarantees for the precision of estimation and clustering.},
  annotation = {\_eprint: 1705.01204v1},
  file = {/Users/ztzhang/Zotero/storage/C2GQ7BVB/Pensky, Zhang - 2017 - Spectral clustering in the dynamic stochastic block model.pdf},
  keywords = {()}
}

@article{Pensky2019,
  ids = {penskySpectralClusteringDynamic2019a},
  title = {Spectral Clustering in the Dynamic Stochastic Block Model},
  author = {Pensky, Marianna and Zhang, Teng},
  year = {2019},
  volume = {13},
  pages = {678--709},
  publisher = {{The Institute of Mathematical Statistics and the Bernoulli Society}},
  issn = {1935-7524},
  doi = {10.1214/19-EJS1533},
  abstract = {In the present paper, we have studied a Dynamic Stochastic Block Model (DSBM) under the assumptions that the connection probabilities , as functions of time, are smooth and that at most s nodes can switch their class memberships between two consecutive time points. We estimate the edge probability tensor by a kernel-type procedure and extract the group memberships of the nodes by spectral clustering. The procedure is computationally viable, adaptive to the unknown smoothness of the functional connection probabilities, to the rate s of membership switching, and to the unknown number of clusters. In addition, it is accompanied by non-asymptotic guarantees for the precision of estimation and clustering. MSC 2010 subject classifications: Primary 62F12, 05C80; secondary 62H30.},
  journal = {Electronic Journal of Statistics},
  keywords = {.Dynamic stochastic block model,.Spectral clustering,.Stochastic block model,.Time varying networks,05C80,62F12,62H30Time-varying network,adaptive estimation,and phrases,dynamic s,dynamic stochastic block,dynamic stochastic block model,model,received march 2018,spectral clustering,time-varying network,Time-varying network},
  mrnumber = {MR3914178},
  zmnumber = {07038001}
}

@article{Pensky2019a,
  title = {Dynamic Network Models and Graphon Estimation},
  author = {Pensky, Marianna},
  year = {2019},
  month = aug,
  volume = {47},
  pages = {2378--2403},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364},
  doi = {10.1214/18-aos1751},
  abstract = {In the present paper we consider a dynamic stochastic network model. The objective is estimation of the tensor of connection probabilities {$\Lambda$} when it is generated by a Dynamic Stochastic Block Model (DSBM) or a dynamic graphon. In particular, in the context of the DSBM, we derive a penalized least squares estimator \$\textbackslash widehat\textbackslash Lambda\$ of {$\Lambda$} and show that \$\textbackslash widehat\textbackslash Lambda\$ satisfies an oracle inequality and also attains minimax lower bounds for the risk. We extend those results to estimation of {$\Lambda$} when it is generated by a dynamic graphon function. The estimators constructed in the paper are adaptive to the unknown number of blocks in the context of the DSBM or to the smoothness of the graphon function. The technique relies on the vectorization of the model and leads to much simpler mathematical arguments than the ones used previously in the stationary set up. In addition, all results in the paper are non-asymptotic and allow a variety of extensions.},
  annotation = {\_eprint: 1607.00673},
  file = {/Users/ztzhang/Zotero/storage/T9692L7J/Pensky - 2019 - Dynamic network models and graphon estimation(2).pdf},
  journal = {The Annals of Statistics},
  keywords = {.Stochastic block model,05C80,60G05,62F35,Dynamic network,graphon,minimax rate,nonparametric regression},
  number = {4}
}

@article{Perry2013,
  title = {Point Process Modeling for Directed Interaction Networks},
  author = {Perry, Patrick O. and Wolfe, Patrick J.},
  year = {2013},
  month = nov,
  volume = {75},
  pages = {821--849},
  issn = {13697412},
  doi = {10.1111/rssb.12013},
  abstract = {Network data often take the form of repeated interactions between senders and receivers tabulated over time. A primary question to ask of such data is which traits and behaviors are predictive of interaction. To answer this question, a model is introduced for treating directed interactions as a multivariate point process: a Cox multiplicative intensity model using covariates that depend on the history of the process. Consistency and asymptotic normality are proved for the resulting partial-likelihood-based estimators under suitable regularity conditions, and an efficient fitting procedure is described. Multicast interactions\textendash those involving a single sender but multiple receivers\textendash are treated explicitly. The resulting inferential framework is then employed to model message sending behavior in a corporate e-mail network. The analysis gives a precise quantification of which static shared traits and dynamic network effects are predictive of message recipient selection.},
  annotation = {\_eprint: arXiv:1011.1703v3},
  file = {/Users/ztzhang/Zotero/storage/6T8EJRRI/Perry, Wolfe - 2013 - Point process modelling for directed interaction networks(2).pdf;/Users/ztzhang/Zotero/storage/A3HNEMBK/Perry, Wolfe - 2013 - Point process modelling for directed interaction networks.pdf;/Users/ztzhang/Zotero/storage/DAY2LAZ4/Perry, Wolfe - 2013 - Point process modeling for directed interaction networks.pdf},
  journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
  keywords = {Cox proportional hazards model,Network data analysis,Partial likelihood inference,Point processes},
  number = {5}
}

@article{Picard2018,
  title = {Continuous Testing for {{Poisson}} Process Intensities: {{A}} New Perspective on Scanning Statistics},
  author = {Picard, Franck and {Reynaud-Bouret}, Patricia and Roquain, Etienne},
  year = {2018},
  month = dec,
  volume = {105},
  pages = {931--944},
  publisher = {{Oxford University Press}},
  issn = {14643510},
  doi = {10.1093/biomet/asy044},
  abstract = {We propose a novel continuous testing framework to test the intensities of Poisson Processes. This framework allows a rigorous definition of the complete testing procedure, from an infinite number of hypothesis to joint error rates. Our work extends traditional procedures based on scanning win-dows, by controlling the family-wise error rate and the false discovery rate in a non-asymptotic manner and in a continuous way. The decision rule is based on a p-value process that can be estimated by a Monte-Carlo procedure. We also propose new test statistics based on kernels. Our method is applied in Neurosciences and Genomics through the standard test of homogeneity, and the two-sample test.},
  file = {/Users/ztzhang/Zotero/storage/6RADDTQQ/Picard, Reynaud-Bouret, Roquain - 2018 - Continuous testing for Poisson process intensities A new perspective on scanning statistics.pdf},
  journal = {Biometrika},
  keywords = {False discovery rate,Familywise error rate,Multiple testing,Poisson process.},
  number = {4}
}

@article{Policastro2021,
  title = {{{ROBustness In Network}} (Robin): An {{R}} Package for {{Comparison}} and {{Validation}} of Communities},
  shorttitle = {{{ROBustness In Network}} (Robin)},
  author = {Policastro, Valeria and Righelli, Dario and Carissimo, Annamaria and Cutillo, Luisa and De Feis, Italia},
  year = {2021},
  month = feb,
  abstract = {In network analysis, many community detection algorithms have been developed, however, their implementation leaves unaddressed the question of the statistical validation of the results. Here we present robin(ROBustness In Network), an R package to assess the robustness of the community structure of a network found by one or more methods to give indications about their reliability. The procedure initially detects if the community structure found by a set of algorithms is statistically significant and then compares two selected detection algorithms on the same graph to choose the one that better fits the network of interest. We demonstrate the use of our package on the American College Football benchmark dataset.},
  archivePrefix = {arXiv},
  eprint = {2102.03106},
  eprinttype = {arxiv},
  journal = {arXiv:2102.03106 [stat]},
  keywords = {.Network structure testing,.R package,Statistics - Computation,Statistics - Methodology,Statistics - Other Statistics},
  primaryClass = {stat}
}

@article{Pollard1981,
  title = {Strong {{Consistency}} of {{K}}-{{Means Clustering}}},
  author = {Pollard, David},
  year = {1981},
  volume = {9},
  pages = {135--140},
  file = {/Users/ztzhang/Zotero/storage/V2RBJA6B/Pollard - 1981 - Strong Consistency of K-Means Clustering.pdf;/Users/ztzhang/Zotero/storage/ZGUMLBPQ/Pollard - 1981 - Strong Consistency of $K$-Means Clustering.pdf},
  journal = {Source: The Annals of Statistics},
  number = {1}
}

@article{Qiao2019,
  title = {Functional {{Graphical Models}}},
  author = {Qiao, Xinghao and Guo, Shaojun and James, Gareth M},
  year = {2019},
  volume = {114},
  pages = {211--222},
  issn = {0162-1459},
  doi = {10.1080/01621459.2017.1390466},
  abstract = {Graphical models have attracted increasing attention in recent years, especially in settings involving high-dimensional data. In particular, Gaussian graphical models are used to model the conditional dependence structure among multiple Gaussian random variables. As a result of its computational efficiency, the graph-ical lasso (glasso) has become one of the most popular approaches for fitting high-dimensional graphical models. In this paper, we extend the graphical models concept to model the conditional dependence structure among p random functions. In this setting, not only is p large, but each function is itself a high-dimensional object, posing an additional level of statistical and computational complexity. We develop an extension of the glasso criterion (fglasso), which estimates the functional graphical model by imposing a block sparsity constraint on the precision matrix, via a group lasso penalty. The fglasso criterion can be optimized using an efficient block coordinate descent algorithm. We establish the concentration inequalities of the estimates, which guarantee the desirable graph support recovery property, that is, with probability tending to one, the fglasso will correctly identify the true conditional dependence structure. Finally, we show that the fglasso significantly outperforms possible competing methods through both simulations and an analysis of a real-world electroencephalography dataset comparing alcoholic and nonalcoholic patients.},
  journal = {Journal of the American Statistical Association},
  keywords = {Block coordinate descent algorithm,Block sparse precision matrix,Functional data,Functional principal component analysis,Graphical models}
}

@article{Rastelli2020,
  title = {A Stochastic Block Model for Interaction Lengths},
  author = {Rastelli, Riccardo and Fop, Michael},
  year = {2020},
  month = jun,
  volume = {14},
  pages = {485--512},
  issn = {1862-5355},
  doi = {10.1007/s11634-020-00403-w},
  abstract = {We propose a new stochastic block model that focuses on the analysis of interaction lengths in dynamic networks. The model does not rely on a discretization of the time dimension and may be used to analyze networks that evolve continuously over time. The framework relies on a clustering structure on the nodes, whereby two nodes belonging to the same latent group tend to create interactions and non-interactions of similar lengths. We introduce a variational expectation\textendash maximization algorithm to perform inference, and adapt a widely used clustering criterion to perform model choice. Finally, we validate our methodology using simulated data experiments and showing two illustrative applications concerning face-to-face interaction data and a bike sharing network.},
  journal = {Advances in Data Analysis and Classification},
  keywords = {.Stochastic block model},
  language = {en},
  number = {2}
}

@article{Rebafka2019,
  title = {Graph Inference with Clustering and False Discovery Rate Control},
  author = {Rebafka, Tabea and Roquain, Etienne and Villers, Fanny},
  year = {2019},
  month = jul,
  abstract = {In this paper, a noisy version of the stochastic block model (NSBM) is introduced and we investigate the three following statistical inferences in this model: estimation of the model parameters, clustering of the nodes and identification of the underlying graph. While the two first inferences are done by using a variational expectation-maximization (VEM) algorithm, the graph inference is done by controlling the false discovery rate (FDR), that is, the average proportion of errors among the edges declared significant, and by maximizing the true discovery rate (TDR), that is, the average proportion of edges declared significant among the true edges. Provided that the VEM algorithm provides reliable parameter estimates and clustering, we theoretically show that our procedure does control the FDR while satisfying an optimal TDR property, up to remainder terms that become small when the size of the graph grows. Numerical experiments show that our method outperforms the classical FDR controlling methods that ignore the underlying SBM topology. In addition, these simulations demonstrate that the FDR/TDR properties of our method are robust to model mis-specification, that is, are essentially maintained outside our model.},
  archivePrefix = {arXiv},
  eprint = {1907.10176},
  eprinttype = {arxiv},
  journal = {arXiv:1907.10176 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{Robins2007,
  title = {An Introduction to Exponential Random Graph (P*) Models for Social Networks},
  author = {Robins, Garry and Pattison, Pip and Kalish, Yuval and Lusher, Dean},
  year = {2007},
  month = may,
  volume = {29},
  pages = {173--191},
  issn = {03788733},
  doi = {10.1016/j.socnet.2006.08.002},
  abstract = {This article provides an introductory summary to the formulation and application of exponential random graph models for social networks. The possible ties among nodes of a network are regarded as random variables, and assumptions about dependencies among these random tie variables determine the general form of the exponential random graph model for the network. Examples of different dependence assumptions and their associated models are given, including Bernoulli, dyad-independent and Markov random graph models. The incorporation of actor attributes in social selection models is also reviewed. Newer, more complex dependence assumptions are briefly outlined. Estimation procedures are discussed, including new methods for Monte Carlo maximum likelihood estimation. We foreshadow the discussion taken up in other papers in this special edition: that the homogeneous Markov random graph models of Frank and Strauss [Frank, O., Strauss, D., 1986. Markov graphs. Journal of the American Statistical Association 81, 832\textendash 842] are not appropriate for many observed networks, whereas the new model specifications of Snijders et al. [Snijders, T.A.B., Pattison, P., Robins, G.L., Handock, M. New specifications for exponential random graph models. Sociological Methodology, in press] offer substantial improvement.},
  journal = {Social Networks},
  keywords = {.Exponential random graph models,.Social networks},
  language = {en},
  number = {2}
}

@article{Rohe2011,
  title = {Spectral Clustering and the High-Dimensional Stochastic Blockmodel},
  author = {Rohe, Karl and Chatterjee, Sourav and Yu, Bin},
  year = {2011},
  month = aug,
  volume = {39},
  pages = {1878--1915},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/11-AOS887},
  abstract = {Networks or graphs can easily represent a diverse set of data sources that are characterized by interacting units or actors. Social networks, representing people who communicate with each other, are one example. Communities or clusters of highly connected actors form an essential feature in the structure of several empirical networks. Spectral clustering is a popular and computationally feasible method to discover these communities. The stochastic blockmodel [Social Networks 5 (1983) 109\textendash 137] is a social network model with well-defined communities; each node is a member of one community. For a network generated from the Stochastic Blockmodel, we bound the number of nodes ``misclustered'' by spectral clustering. The asymptotic results in this paper are the first clustering results that allow the number of clusters in the model to grow with the number of nodes, hence the name high-dimensional. In order to study spectral clustering under the stochastic blockmodel, we first show that under the more general latent space model, the eigenvectors of the normalized graph Laplacian asymptotically converge to the eigenvectors of a ``population'' normalized graph Laplacian. Aside from the implication for spectral clustering, this provides insight into a graph visualization technique. Our method of studying the eigenvectors of random matrices is original.},
  journal = {Annals of Statistics},
  keywords = {.Stochastic block model},
  language = {EN},
  mrnumber = {MR2893856},
  number = {4},
  zmnumber = {1227.62042}
}

@article{Ronn2009,
  title = {Nonparametric Maximum Likelihood Estimation of Randomly Time-Transformed Curves},
  author = {R{\o}nn, Birgitte B and Skovgaard, Ib M},
  year = {2009},
  volume = {23},
  pages = {1--17},
  journal = {Brazilian Journal of Probability and Statistics},
  number = {1}
}

@article{Rossetti2018,
  title = {Community Discovery in Dynamic Networks: {{A}} Survey},
  author = {Rossetti, Giulio and Cazabet, R{\'e}my},
  year = {2018},
  month = feb,
  volume = {51},
  publisher = {{Association for Computing Machinery}},
  issn = {15577341},
  doi = {10.1145/3172867},
  abstract = {Several research studies have shown that complex networks modeling real-world phenomena are characterized by striking properties: (i) they are organized according to community structure, and (ii) their structure evolves with time. Many researchers have worked on methods that can efficiently unveil substructures in complex networks, giving birth to the field of community discovery. A novel and fascinating problem started capturing researcher interest recently: the identification of evolving communities. Dynamic networks can be used to model the evolution of a system: nodes and edges are mutable, and their presence, or absence, deeply impacts the community structure that composes them. This survey aims to present the distinctive features and challenges of dynamic community discovery and propose a classification of published approaches. As a ``user manual,'' this work organizes state-of-the-art methodologies into a taxonomy, based on their rationale, and their specific instantiation. Given a definition of network dynamics, desired community characteristics, and analytical needs, this survey will support researchers to identify the set of approaches that best fit their needs. The proposed classification could also help researchers choose in which direction to orient their future research.},
  annotation = {\_eprint: 1707.03186},
  file = {/Users/ztzhang/Zotero/storage/Q8X8VNXU/Rossetti, Cazabet - 2018 - Community discovery in dynamic networks A survey.pdf},
  journal = {ACM Computing Surveys},
  keywords = {Community discovery,Dynamic networks,Temporal networks},
  number = {2}
}

@article{Samelson1971,
  title = {Pacific Journal of Mathematics},
  author = {Samelson, H. and Hobby, C. R. and Dugundji, J. and Arens, Richard},
  year = {1971},
  volume = {37},
  pages = {1},
  issn = {00308730},
  abstract = {In this note we describe those additive mappings from a second symmetric product space to another, over a field of characteristic not 2 or 3, which preserve decomposable elements of the form ??u ??? u where u is a vector and ?? is a scalar. This leads to the corresponding result concerning additive mappings from one vector space of symmetric matrices to another which preserve rank less than or equal to one. We also discuss some consequences of this characterization theorem. ?? 2005 Elsevier Inc. All rights reserved.},
  file = {/Users/ztzhang/Zotero/storage/ZQQLQWWQ/Samelson et al. - 1971 - Pacific journal of mathematics.pdf},
  journal = {Pacific Journal of Mathematics},
  number = {3}
}

@article{Sarkar2005,
  title = {Dynamic Social Network Analysis Using Latent Space Models},
  author = {Sarkar, Purnamrita and Moore, Andrew W.},
  year = {2005},
  month = dec,
  volume = {7},
  pages = {31--40},
  issn = {19310145},
  doi = {10.1145/1117454.1117459},
  abstract = {This paper explores two aspects of social network modeling. First, we generalize a successful static model of relationships into a dynamic model that accounts for friendships drifting over time. Second, we show how to make it tractable to learn such models from data, even as the number of entities n gets large. The generalized model associates each entity with a point in p-dimensional Euclidean latent space. The points can move as time progresses but large moves in latent space are improbable. Observed links between entities are more likely if the entities are close in latent space. We show how to make such a model tractable (sub-quadratic in the number of entities) by the use of appropriate kernel functions for similarity in latent space; the use of low dimensional KD-trees; a new efficient dynamic adaptation of multidimensional scaling for a first pass of approximate projection of entities into latent space; and an efficient conjugate gradient update rule for non-linear local optimization in which amortized time per entity during an update is O(log n). We use both synthetic and real-world data on up to 11,000 entities which indicate near-linear scaling in computation time and improved performance over four alternative approaches. We also illustrate the system operating on twelve years of NIPS co-authorship data.},
  file = {/Users/ztzhang/Zotero/storage/G7PI7HGC/Sarkar, Moore - 2005 - Dynamic social network analysis using latent space models.pdf},
  journal = {ACM SIGKDD Explorations Newsletter},
  number = {2}
}

@article{Selection2019,
  title = {1 {{GD}} on {{Manifold}}},
  author = {Selection, Step Size},
  year = {2019},
  pages = {1--5},
  file = {/Users/ztzhang/Zotero/storage/ND6PEBJY/Selection - 2019 - 1 GD on Manifold.pdf}
}

@article{Sengupta2018,
  title = {A Block Model for Node Popularity in Networks with Community Structure},
  author = {Sengupta, Srijan and Chen, Yuguo},
  year = {2018},
  volume = {80},
  pages = {365--386},
  issn = {1467-9868},
  doi = {10.1111/rssb.12245},
  abstract = {The community structure that is observed in empirical networks has been of particular interest in the statistics literature, with a strong emphasis on the study of block models. We study an important network feature called node popularity, which is closely associated with community structure. Neither the classical stochastic block model nor its degree-corrected extension can satisfactorily capture the dynamics of node popularity as observed in empirical networks. We propose a popularity-adjusted block model for flexible and realistic modelling of node popularity. We establish consistency of likelihood modularity for community detection as well as estimation of node popularities and model parameters, and demonstrate the advantages of the new modularity over the degree-corrected block model modularity in simulations. By analysing the political blogs network, the British Members of Parliament network and the `Digital bibliography and library project' bibliographical network, we illustrate that improved empirical insights can be gained through this methodology.},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12245},
  copyright = {\textcopyright{} 2017 Royal Statistical Society},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {.Stochastic block model,.unlabeled,Community detection,Degree-corrected block model,Likelihood modularity,Node popularity,Popularity-adjusted block model},
  language = {en},
  number = {2}
}

@article{Simma2012,
  title = {Modeling {{Events}} with {{Cascades}} of {{Poisson Processes}}},
  author = {Simma, Aleksandr and Jordan, Michael I.},
  year = {2012},
  month = mar,
  abstract = {We present a probabilistic model of events in continuous time in which each event triggers a Poisson process of successor events. The ensemble of observed events is thereby modeled as a superposition of Poisson processes. Efficient inference is feasible under this model with an EM algorithm. Moreover, the EM algorithm can be implemented as a distributed algorithm, permitting the model to be applied to very large datasets. We apply these techniques to the modeling of Twitter messages and the revision history of Wikipedia.},
  annotation = {\_eprint: 1203.3516},
  file = {/Users/ztzhang/Zotero/storage/29WY5V6Z/Simma, Jordan - 2012 - Modeling Events with Cascades of Poisson Processes.pdf}
}

@inproceedings{Singer1988,
  title = {A {{Computer Simulation}} of {{Cerebral Neocortex}}: {{Computational Capabilities}} of {{Nonlinear Neural Networks}}},
  shorttitle = {A {{Computer Simulation}} of {{Cerebral Neocortex}}},
  booktitle = {Neural {{Information Processing Systems}}},
  author = {Singer, Alexander and Donoghue, John},
  editor = {Anderson, D.},
  year = {1988},
  publisher = {{American Institute of Physics}}
}

@article{Skaggs,
  title = {An {{Information}}-{{Theoretic Approach}} to {{Deciphering}} the {{Hippocampal Code}}},
  author = {Skaggs, William E and Mcnaughton, Bruce L and Gothard, Katalin M and Markus, Etan J},
  pages = {1030--1038},
  file = {/Users/ztzhang/Zotero/storage/WHPYFBNU/Skaggs et al. - Unknown - An Information-Theoretic Approach to Deciphering the Hippocampal Code.pdf},
  number = {1990}
}

@incollection{Skyrms2009,
  title = {A {{Dynamic Model}} of {{Social Network Formation}}},
  booktitle = {Adaptive {{Networks}}: {{Theory}}, {{Models}} and {{Applications}}},
  author = {Skyrms, Brian and Pemantle, Robin},
  editor = {Gross, Thilo and Sayama, Hiroki},
  year = {2009},
  pages = {231--251},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-01284-6_11},
  abstract = {We consider a dynamic social network model in which agents play repeated games in pairings determined by a stochastically evolving social network. Individual agents begin to interact at random, with the interactions modeled as games. The game payoffs determine which interactions are reinforced, and the network structure emerges as a consequence of the dynamics of the agents' learning behavior. We study this in a variety of game-theoretic conditions and show that the behavior is complex and sometimes dissimilar to behavior in the absence of structural dynamics. We argue that modeling network structure as dynamic increases realism without rendering the problem of analysis intractable.},
  isbn = {978-3-642-01284-6},
  keywords = {.Social networks,Evolutionary Game Theory,Game Payoff,Negative Reinforcement,Random Limit},
  language = {en},
  series = {Understanding {{Complex Systems}}}
}

@article{Snijders,
  title = {Stochastic {{Actor}}-{{Oriented Models}} for {{Network Dynamics}}},
  author = {Snijders, Tom A B and Pickup, Mark},
  pages = {38},
  file = {/Users/ztzhang/Zotero/storage/EDCG25IW/Snijders and Pickup - Stochastic Actor-Oriented Models for Network Dynam.pdf},
  keywords = {.Social networks},
  language = {en}
}

@article{Snijdersa,
  title = {Statistical {{Methods}} for {{Social Network Dynamics}}},
  author = {Snijders, Tom A B},
  pages = {245},
  file = {/Users/ztzhang/Zotero/storage/M45PAKEP/Snijders - Statistical Methods   for Social Network Dynamics.pdf},
  journal = {Social networks},
  keywords = {.Social networks},
  language = {en}
}

@article{SOBEL2007,
  title = {Causal Diagrams for Empirical Research},
  author = {SOBEL, MICHAEL E.},
  year = {2007},
  month = jan,
  volume = {82},
  pages = {700--702},
  publisher = {{Oxford University Press (OUP)}},
  issn = {0006-3444},
  doi = {10.1093/biomet/82.4.700},
  journal = {Biometrika},
  number = {4}
}

@article{Sosa2020,
  title = {A {{Review}} of {{Latent Space Models}} for {{Social Networks}}},
  author = {Sosa, Juan and Buitrago, Lina},
  year = {2020},
  month = dec,
  abstract = {In this paper, we provide a review on both fundamentals of social networks and latent space modeling. The former discusses important topics related to network description, including vertex characteristics and network structure; whereas the latter articulates relevant advances in network modeling, including random graph models, generalized random graph models, exponential random graph models, and social space models. We discuss in detail several latent space models provided in literature, providing special attention to distance, class, and eigen models in the context of undirected, binary networks. In addition, we also examine empirically the behavior of these models in terms of prediction and goodness-of-fit using more than twenty popular datasets of the network literature.},
  archivePrefix = {arXiv},
  eprint = {2012.02307},
  eprinttype = {arxiv},
  journal = {arXiv:2012.02307 [cs, stat]},
  keywords = {.unlabeled,Computer Science - Social and Information Networks,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{Stewart2021,
  title = {Pseudo-Likelihood-Based \${{M}}\$-Estimation of Random Graphs with Dependent Edges and Parameter Vectors of Increasing Dimension},
  author = {Stewart, Jonathan R. and Schweinberger, Michael},
  year = {2021},
  month = feb,
  abstract = {An important question in statistical network analysis is how to estimate models of dependent network data without sacrificing computational scalability and statistical guarantees. We demonstrate that scalable estimation of random graph models with dependent edges is possible, by establishing the first consistency results and convergence rates for pseudo-likelihood-based \$M\$-estimators for parameter vectors of increasing dimension based on a single observation of dependent random variables. The main results cover models of dependent random variables satisfying weak dependence conditions, and may be of independent interest. To showcase consistency results and convergence rates, we introduce a novel class of generalized \$\textbackslash beta\$-models with dependent edges and parameter vectors of increasing dimension. We establish consistency results and convergence rates for pseudo-likelihood-based \$M\$-estimators of generalized \$\textbackslash beta\$-models with dependent edges, in dense- and sparse-graph settings.},
  archivePrefix = {arXiv},
  eprint = {2012.07167},
  eprinttype = {arxiv},
  journal = {arXiv:2012.07167 [math, stat]},
  keywords = {.unlabeled,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{Su2018,
  title = {Network Estimation via Graphon with Node Features},
  author = {Su, Yi and Wong, Raymond K W and Lee, Thomas C M},
  year = {2018},
  abstract = {Estimating the probabilities of linkages in a network has gained increasing interest in recent years. One popular model for network analysis is the exchangeable graph model (ExGM) characterized by a two-dimensional function known as a graphon. Estimating an underlying graphon becomes the key of such analysis. Several nonparametric estimation methods have been proposed , and some are provably consistent. However, if certain useful features of the nodes (e.g., age and schools in social network context) are available, none of these methods was designed to incorporate this source of information to help with the estimation. This paper develops a consistent graphon estimation method that integrates the information from both the adjacency matrix itself and node features. We show that properly leveraging the features can improve the estimation. A cross-validation method is proposed to automatically select the tuning parameter of the method.},
  annotation = {\_eprint: 1809.00420v1},
  file = {/Users/ztzhang/Zotero/storage/N9BFTSP5/Su, Wong, Lee - 2018 - Network estimation via graphon with node features.pdf},
  keywords = {consistency,exchangeable graph model,feature assisted neighborhood smoothing (FANS),generative model,nonparametric}
}

@article{Sun2016,
  title = {Guaranteed {{Matrix Completion}} via {{Non}}-Convex {{Factorization}}},
  author = {Sun, Ruoyu and Luo, Zhi-quan},
  year = {2016},
  annotation = {\_eprint: arXiv:1411.8003v3},
  file = {/Users/ztzhang/Zotero/storage/D992GMNE/Sun, Luo - 2016 - Guaranteed Matrix Completion via Non-convex Factorization(2).pdf;/Users/ztzhang/Zotero/storage/UQK9GLNR/Sun, Luo - 2016 - Guaranteed Matrix Completion via Non-Convex Factorization.pdf},
  keywords = {alternating minimization,Matrix completion,matrix factorization,nonconvex optimization,Perturbation analysis,SGD},
  number = {2}
}

@article{Sussman2012,
  title = {A {{Consistent Adjacency Spectral Embedding}} for {{Stochastic Blockmodel Graphs}}},
  author = {Sussman, Daniel L. and Tang, Minh and Fishkind, Donniell E. and Priebe, Carey E.},
  year = {2012},
  month = sep,
  volume = {107},
  pages = {1119--1128},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2012.699795},
  abstract = {We present a method to estimate block membership of nodes in a random graph generated by a stochastic blockmodel. We use an embedding procedure motivated by the random dot product graph model, a particular example of the latent position model. The embedding associates each node with a vector; these vectors are clustered via minimization of a square error criterion. We prove that this method is consistent for assigning nodes to blocks, as only a negligible number of nodes will be misassigned. We prove consistency of the method for directed and undirected graphs. The consistent block assignment makes possible consistent parameter estimation for a stochastic blockmodel. We extend the result in the setting where the number of blocks grows slowly with the number of nodes. Our method is also computationally feasible even for very large graphs. We compare our method with Laplacian spectral clustering through analysis of simulated data and a graph derived from Wikipedia documents.},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2012.699795},
  journal = {Journal of the American Statistical Association},
  keywords = {.Stochastic block model},
  number = {499}
}

@article{Toyoda2003,
  title = {Extracting {{Evolution}} of {{Web Communities}} from a {{Series}} of {{Web Archives}}},
  author = {Toyoda, Masashi and Kitsuregawa, Masaru},
  year = {2003},
  abstract = {Recent advances in storage technology make it possible to store a series of large Web archives. It is now an exciting challenge for us to observe evolution of the Web. In this paper, we propose a method for observing evolution of web communities. A web community is a set of web pages created by individuals or associations with a common interest on a topic. So far, various link analysis techniques have been developed to extract web communities. We analyze evolution of web communities by comparing four Japanese web archives crawled from 1999 to 2002. Statistics of these archives and community evolution are examined, and the global behavior of evolution is described. Several metrics are introduced to measure the degree of web community evolution , such as growth rate, novelty, and stability. We developed a system for extracting detailed evolution of communities using these metrics. It allows us to understand when and how communities emerged and evolved. Some evolution examples are shown using our system.},
  file = {/Users/ztzhang/Zotero/storage/ZQR54USM/Toyoda, Kitsuregawa - 2003 - Extracting Evolution of Web Communities from a Series of Web Archives.pdf},
  keywords = {Algorithms Keywords Web,evolution,H54 [Information Interfaces and Presentation]: Hy-,Link analysis,Measurement,web community}
}

@article{Tsybakov2009,
  title = {Introduction to {{Nonparametric Estimation}}},
  author = {Tsybakov, Alexandre B.},
  year = {2009},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/b13794},
  isbn = {978-0-387-79051-0},
  series = {Springer {{Series}} in {{Statistics}}}
}

@article{Vazquez2003,
  title = {Growing Network with Local Rules: {{Preferential}} Attachment, Clustering Hierarchy, and Degree Correlations},
  shorttitle = {Growing Network with Local Rules},
  author = {V{\'a}zquez, Alexei},
  year = {2003},
  month = may,
  volume = {67},
  pages = {056104},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.67.056104},
  abstract = {The linear preferential attachment hypothesis has been shown to be quite successful in explaining the existence of networks with power-law degree distributions. It is then quite important to determine if this mechanism is the consequence of a general principle based on local rules. In this work it is claimed that an effective linear preferential attachment is the natural outcome of growing network models based on local rules. It is also shown that the local models offer an explanation for other properties like the clustering hierarchy and degree correlations recently observed in complex networks. These conclusions are based on both analytical and numerical results for different local rules, including some models already proposed in the literature.},
  journal = {Physical Review E},
  keywords = {.Hierarchical clustering,.Preferential attachment},
  number = {5}
}

@article{Venkatesh2010,
  title = {The {{Community Network Lifecycle}}: {{A Framework}} for {{Research}} and {{Action Special Issue}}: {{ICTs}} and {{Community Networking}}},
  shorttitle = {The {{Community Network Lifecycle}}},
  author = {Venkatesh, Murali},
  year = {2010},
  month = jun,
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/714044682},
  copyright = {Copyright Taylor and Francis Group, LLC},
  journal = {The Information Society},
  keywords = {.Network lifecycle},
  language = {en}
}

@article{Vimond2010,
  title = {Efficient Estimation for a Subclass of Shape Invariant Models},
  author = {Vimond, Myriam},
  year = {2010},
  volume = {38},
  pages = {1885--1912},
  doi = {10.1214/07-AOS566},
  abstract = {In this paper, we observe a fixed number of unknown 2{$\pi$}-periodic functions differing from each other by both phases and amplitude. This semiparametric model appears in literature under the name "shape invariant model." While the common shape is unknown, we introduce an asymptotically efficient estimator of the finite-dimensional parameter (phases and amplitude) using the profile likelihood and the Fourier basis. Moreover, this estimation method leads to a consistent and asymptotically linear estimator for the common shape.},
  annotation = {\_eprint: 1010.0796v1},
  file = {/Users/ztzhang/Zotero/storage/SREPGILE/Vimond - 2010 - Efficient estimation for a subclass of shape invariant models.pdf},
  journal = {The Annals of Statistics},
  number = {3}
}

@article{Vu,
  title = {Continuous-{{Time Regression Models}} for {{Longitudinal Networks}}},
  author = {Vu, Duy Q and Asuncion, Arthur U and Hunter, David R and Smyth, Padhraic},
  abstract = {The development of statistical models for continuous-time longitudinal network data is of increasing interest in machine learning and social science. Leveraging ideas from survival and event history analysis, we introduce a continuous-time regression modeling framework for network event data that can incorporate both time-varying network statistics and time-varying regression coefficients. We also develop an efficient inference scheme that allows our approach to scale to large networks. On synthetic and real-world data, empirical results demonstrate that the proposed inference approach can accurately estimate the coefficients of the regression model, which is useful for interpreting the evolution of the network; furthermore, the learned model has systematically better predictive performance compared to standard baseline methods.},
  keywords = {.Regression models,.Time varying networks}
}

@article{Wan2019,
  title = {Single-{{Cell Reconstruction}} of {{Emerging Population Activity}} in an {{Entire Developing Circuit}}},
  author = {Wan, Yinan and Wei, Ziqiang and Looger, Loren L. and Koyama, Minoru and Druckmann, Shaul and Keller Correspondence, Philipp J and Keller, Philipp J.},
  year = {2019},
  month = sep,
  volume = {179},
  issn = {00928674},
  doi = {10.1016/j.cell.2019.08.039},
  abstract = {Graphical Abstract Highlights d Neurons are tracked from birth to entire circuit at cell-type and functional levels d Neurogenesis and emergence of coordinated activity is analyzed at a single-cell level d Motoneurons, active first, form ensembles that synchronize globally, based on size d Neuron maturation is stereotyped, based on birth time and anatomical origin In Brief Wan et al. reconstruct neurogenesis and the emergence of coordinated neuronal activity at the single-cell level in the zebrafish spinal cord by tracking neuron lineages, movements, molecular identities, and activity in the entire developing circuit. They find that functional maturation of neurons is stereotyped, based on birth time and anatomical origin, and that early motoneuron activity leads ensembles that synchronize globally, based on network size.},
  file = {/Users/ztzhang/Zotero/storage/D5ZGMEGR/Wan et al. - 2019 - Single-Cell Reconstruction of Emerging Population Activity in an Entire Developing Circuit.pdf},
  journal = {Cell},
  keywords = {calcium imaging,circuit development,computational data analysis,embryonic development,light-sheet microscopy,population activity,spinal cord,zebrafish}
}

@article{Wang1987,
  ids = {wangStochasticBlockmodelsDirected1987a},
  title = {Stochastic {{Blockmodels}} for {{Directed Graphs}}},
  author = {Wang, Yuchung J; and Wong, George Y},
  year = {1987},
  volume = {82},
  pages = {8--19},
  publisher = {{Taylor \& Francis}},
  file = {/Users/ztzhang/Zotero/storage/F5N6ZM8D/Wang, Wong - 1987 - Stochastic Blockmodels for Directed Graphs.pdf},
  journal = {Journal of the American Statistical Association},
  keywords = {.Stochastic block model},
  number = {397}
}

@article{Wang1997,
  title = {Alignment of Curves by Dynamic Time Warping},
  author = {Wang, Kongming and Gasser, Theo},
  year = {1997},
  volume = {25},
  pages = {1276},
  file = {/Users/ztzhang/Zotero/storage/QI4D7FHX/Wang, Gasser - 1997 - Alignment of curves by dynamic time warping.pdf},
  journal = {The Annals of Statistics},
  number = {3}
}

@article{Wang2019,
  title = {Joint {{Latent Space Model}} for {{Social Networks}} with {{Multivariate Attributes}}},
  author = {Wang, Selena Shuo and Paul, Subhadeep and De Boeck, Paul},
  year = {2019},
  month = oct,
  abstract = {In many application problems in social, behavioral, and economic sciences, researchers often have data on a social network among a group of individuals along with high dimensional multivariate measurements for each individual. To analyze such networked data structures, we propose a joint Attribute and Person Latent Space Model (APLSM) that summarizes information from the social network and the multiple attribute measurements in a person-attribute joint latent space. We develop a Variational Bayesian Expectation-Maximization estimation algorithm to estimate the posterior distribution of the attribute and person locations in the joint latent space. This methodology allows for effective integration, informative visualization, and prediction of social networks and high dimensional attribute measurements. Using APLSM, we explore the inner workings of the French financial elites based on their social networks and their career, political views, and social status. We observe a division in the social circles of the French elites in accordance with the differences in their individual characteristics.},
  keywords = {.Latent space model,.Nodal attribute,.Social networks},
  language = {en}
}

@techreport{Wang2019a,
  title = {Multiway Clustering via Tensor Block Models},
  author = {Wang, Miaoyan and Zeng, Yuchen},
  year = {2019},
  volume = {32},
  pages = {715--725},
  abstract = {We consider the problem of identifying multiway block structure from a large noisy tensor. Such problems arise frequently in applications such as genomics, recommendation system, topic modeling, and sensor network localization. We propose a tensor block model, develop a unified least-square estimation, and obtain the theoretical accuracy guarantees for multiway clustering. The statistical convergence of the estimator is established, and we show that the associated clustering procedure achieves partition consistency. A sparse regularization is further developed for identifying important blocks with elevated means. The proposal handles a broad range of data types, including binary, continuous, and hybrid observations. Through simulation and application to two real datasets, we demonstrate the outperformance of our approach over previous methods.},
  file = {/Users/ztzhang/Zotero/storage/B28M9BJT/Wang, Zeng - 2019 - Multiway clustering via tensor block models.pdf},
  journal = {Advances in Neural Information Processing Systems}
}

@article{Wang2021,
  title = {Sequential Change-Point Detection for Mutually Exciting Point Processes over Networks},
  author = {Wang, Haoyun and Xie, Liyan and Xie, Yao and Cuozzo, Alex and Mak, Simon},
  year = {2021},
  month = feb,
  abstract = {We present a new CUSUM procedure for sequentially detecting change-point in the self and mutual exciting processes, a.k.a. Hawkes networks using discrete events data. Hawkes networks have become a popular model for statistics and machine learning due to their capability in modeling irregularly observed data where the timing between events carries a lot of information. The problem of detecting abrupt changes in Hawkes networks arises from various applications, including neuronal imaging, sensor network, and social network monitoring. Despite this, there has not been a computationally and memory-efficient online algorithm for detecting such changes from sequential data. We present an efficient online recursive implementation of the CUSUM statistic for Hawkes processes, both decentralized and memory-efficient, and establish the theoretical properties of this new CUSUM procedure. We then show that the proposed CUSUM method achieves better performance than existing methods, including the Shewhart procedure based on count data, the generalized likelihood ratio (GLR) in the existing literature, and the standard score statistic. We demonstrate this via a simulated example and an application to population code change-detection in neuronal networks.},
  archivePrefix = {arXiv},
  eprint = {2102.05724},
  eprinttype = {arxiv},
  journal = {arXiv:2102.05724 [cs, stat]},
  keywords = {.Change point detection,.Hawkes processes,.Time varying networks,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Wang2021a,
  title = {Multiway Clustering via Tensor Block Models},
  author = {Wang, Miaoyan and Zeng, Yuchen},
  year = {2021},
  month = jan,
  abstract = {We consider the problem of identifying multiway block structure from a large noisy tensor. Such problems arise frequently in applications such as genomics, recommendation system, topic modeling, and sensor network localization. We propose a tensor block model, develop a unified least-square estimation, and obtain the theoretical accuracy guarantees for multiway clustering. The statistical convergence of the estimator is established, and we show that the associated clustering procedure achieves partition consistency. A sparse regularization is further developed for identifying important blocks with elevated means. The proposal handles a broad range of data types, including binary, continuous, and hybrid observations. Through simulation and application to two real datasets, we demonstrate the outperformance of our approach over previous methods.},
  archivePrefix = {arXiv},
  eprint = {1906.03807},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/WXLLSZH2/Wang and Zeng - 2021 - Multiway clustering via tensor block models.pdf},
  journal = {arXiv:1906.03807 [cs, math, stat]},
  keywords = {Tensor block model},
  primaryClass = {cs, math, stat}
}

@article{Weed2017,
  ids = {weedSharpAsymptoticFinitesample2017a},
  title = {Sharp Asymptotic and Finite-Sample Rates of Convergence of Empirical Measures in {{Wasserstein}} Distance},
  author = {Weed, Jonathan and Bach, Francis},
  year = {2017},
  abstract = {The Wasserstein distance between two probability measures on a metric space is a measure of closeness with applications in statistics , probability, and machine learning. In this work, we consider the fundamental question of how quickly the empirical measure obtained from n independent samples from \textmu{} approaches \textmu{} in the Wasserstein distance of any order. We prove sharp asymptotic and finite-sample results for this rate of convergence for general measures on general compact metric spaces. Our finite-sample results show the existence of multi-scale behavior, where measures can exhibit radically different rates of convergence as n grows.},
  annotation = {\_eprint: 1707.00087v1},
  archivePrefix = {arXiv},
  eprint = {1707.00087},
  eprinttype = {arxiv},
  keywords = {.Concentration theory,.Empirical measures,.Empirical processes,(),60B10; 62E17,Mathematics - Probability,Mathematics - Statistics Theory}
}

@article{Weylandt2021,
  title = {Automatic {{Registration}} and {{Clustering}} of {{Time Series}}},
  author = {Weylandt, Michael and Michailidis, George},
  year = {2021},
  month = feb,
  abstract = {Clustering of time series data exhibits a number of challenges not present in other settings, notably the problem of registration (alignment) of observed signals. Typical approaches include pre-registration to a user-specified template or time warping approaches which attempt to optimally align series with a minimum of distortion. For many signals obtained from recording or sensing devices, these methods may be unsuitable as a template signal is not available for pre-registration, while the distortion of warping approaches may obscure meaningful temporal information. We propose a new method for automatic time series alignment within a clustering problem. Our approach, Temporal Registration using Optimal Unitary Transformations (TROUT), is based on a novel dissimilarity measure between time series that is easy to compute and automatically identifies optimal alignment between pairs of time series. By embedding our new measure in a optimization formulation, we retain well-known advantages of computational and statistical performance. We provide an efficient algorithm for TROUT-based clustering and demonstrate its superior performance over a range of competitors.},
  archivePrefix = {arXiv},
  eprint = {2012.04756},
  eprinttype = {arxiv},
  journal = {arXiv:2012.04756 [cs, stat]},
  keywords = {.unlabeled,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{Wolfe2013,
  title = {Nonparametric Graphon Estimation},
  author = {Wolfe, Patrick J. and Olhede, Sofia C.},
  year = {2013},
  month = sep,
  abstract = {We propose a nonparametric framework for the analysis of networks, based on a natural limit object termed a graphon. We prove consistency of graphon estimation under general conditions, giving rates which include the important practical setting of sparse networks. Our results cover dense and sparse stochastic blockmodels with a growing number of classes, under model misspecification. We use profile likelihood methods, and connect our results to approximation theory, nonparametric function estimation, and the theory of graph limits.},
  annotation = {\_eprint: 1309.5936},
  file = {/Users/ztzhang/Zotero/storage/PU5RIAP8/Wolfe, Olhede - 2013 - Nonparametric graphon estimation.pdf;/Users/ztzhang/Zotero/storage/UA94VU2V/Wolfe, Olhede - Unknown - Nonparametric graphon estimation.pdf},
  keywords = {.Stochastic block model,05C80,62G05,62G20,graph limits,nonparametric regression,sparse random graphs,statistical network analysis}
}

@article{Wu2021,
  title = {Testing Correlation of Unlabeled Random Graphs},
  author = {Wu, Yihong and Xu, Jiaming and Yu, Sophie H.},
  year = {2021},
  month = feb,
  abstract = {We study the problem of detecting the edge correlation between two random graphs with \$n\$ unlabeled nodes. This is formalized as a hypothesis testing problem, where under the null hypothesis, the two graphs are independently generated; under the alternative, the two graphs are edge-correlated under some latent node correspondence, but have the same marginal distributions as the null. For both Gaussian-weighted complete graphs and dense Erd\textbackslash H\{o\}s-R\textbackslash 'enyi graphs (with edge probability \$n\^\{-o(1)\}\$), we determine the sharp threshold at which the optimal testing error probability exhibits a phase transition from zero to one as \$n\textbackslash to \textbackslash infty\$. For sparse Erd\textbackslash H\{o\}s-R\textbackslash 'enyi graphs with edge probability \$n\^\{-\textbackslash Omega(1)\}\$, we determine the threshold within a constant factor. The proof of the impossibility results is an application of the conditional second-moment method, where we bound the truncated second moment of the likelihood ratio by carefully conditioning on the typical behavior of the intersection graph (consisting of edges in both observed graphs) and taking into account the cycle structure of the induced random permutation on the edges. Notably, in the sparse regime, this is accomplished by leveraging the pseudoforest structure of subcritical Erd\textbackslash H\{o\}s-R\textbackslash 'enyi graphs and a careful enumeration of subpseudoforests that can be assembled from short orbits of the edge permutation.},
  archivePrefix = {arXiv},
  eprint = {2008.10097},
  eprinttype = {arxiv},
  journal = {arXiv:2008.10097 [math, stat]},
  keywords = {.unlabeled,Mathematics - Combinatorics,Mathematics - Probability,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{Xu2012,
  title = {An Alternating Direction Algorithm for Matrix Completion with Nonnegative Factors},
  author = {Xu, Yangyang and Yin, Wotao and Wen, Zaiwen and Zhang, Yin},
  year = {2012},
  month = apr,
  volume = {7},
  pages = {365--384},
  issn = {16733452},
  doi = {10.1007/s11464-012-0194-5},
  abstract = {This paper introduces an algorithm for the nonnegative matrix factorization-and-completion problem, which aims to find nonnegative low-rank matrices X and Y so that the product XY approximates a nonnegative data matrix M whose elements are partially known (to a certain accuracy). This problem aggregates two existing problems: (i) nonnegative matrix factorization where all entries of M are given, and (ii) low-rank matrix completion where nonnegativity is not required. By taking the advantages of both nonnegativity and low-rankness, one can generally obtain superior results than those of just using one of the two properties. We propose to solve the non-convex constrained least-squares problem using an algorithm based on the classic alternating direction augmented Lagrangian method. Preliminary convergence properties of the algorithm and numerical simulation results are presented. Compared to a recent algorithm for nonnegative matrix factorization, the proposed algorithm produces factorizations of similar quality using only about half of the matrix entries. On tasks of recovering incomplete grayscale and hyperspectral images, the proposed algorithm yields overall better qualities than those produced by two recent matrix-completion algorithms that do not exploit nonnegativity.},
  file = {/Users/ztzhang/Zotero/storage/JICFR9YH/Xu et al. - 2012 - An alternating direction algorithm for matrix completion with nonnegative factors.pdf},
  journal = {Frontiers of Mathematics in China},
  keywords = {alternating direction method,hyperspectral unmixing,matrix completion,nonnegative matrix factorization},
  number = {2}
}

@article{Xu2012a,
  title = {Infinite {{Hidden Relational Models}}},
  author = {Xu, Zhao and Tresp, Volker and Yu, Kai and Kriegel, Hans-Peter},
  year = {2012},
  month = jun,
  abstract = {In many cases it makes sense to model a relationship symmetrically, not implying any particular directionality. Consider the classical example of a recommendation system where the rating of an item by a user should symmetrically be dependent on the attributes of both the user and the item. The attributes of the (known) relationships are also relevant for predicting attributes of entities and for predicting attributes of new relations. In recommendation systems, the exploitation of relational attributes is often referred to as collaborative filtering. Again, in many applications one might prefer to model the collaborative effect in a symmetrical way. In this paper we present a relational model, which is completely symmetrical. The key innovation is that we introduce for each entity (or object) an infinite-dimensional latent variable as part of a Dirichlet process (DP) model. We discuss inference in the model, which is based on a DP Gibbs sampler, i.e., the Chinese restaurant process. We extend the Chinese restaurant process to be applicable to relational modeling. Our approach is evaluated in three applications. One is a recommendation system based on the MovieLens data set. The second application concerns the prediction of the function of yeast genes/proteins on the data set of KDD Cup 2001 using a multi-relational model. The third application involves a relational medical domain. The experimental results show that our model gives significantly improved estimates of attributes describing relationships or entities in complex relational models.},
  annotation = {\_eprint: 1206.6864}
}

@article{Xu2014,
  ids = {xuDynamicStochasticBlockmodels2014a},
  title = {Dynamic Stochastic Blockmodels for Time-Evolving Social Networks},
  author = {Xu, Kevin S. and Hero, Alfred O.},
  year = {2014},
  volume = {8},
  pages = {552--562},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {19324553},
  doi = {10.1109/JSTSP.2014.2310294},
  abstract = {Significant efforts have gone into the development of statistical models for analyzing data in the form of networks, such as social networks. Most existing work has focused on modeling static networks, which represent either a single time snapshot or an aggregate view over time. There has been recent interest in statistical modeling of dynamic networks, which are observed at multiple points in time and offer a richer representation of many complex phenomena. In this paper, we present a state-space model for dynamic networks that extends the well-known stochastic blockmodel for static networks to the dynamic setting. We fit the model in a near-optimal manner using an extended Kalman filter (EKF) augmented with a local search. We demonstrate that the EKF-based algorithm performs competitively with a state-of-the-art algorithm based on Markov chain Monte Carlo sampling but is significantly less computationally demanding.},
  archivePrefix = {arXiv},
  eprint = {1403.0921},
  eprinttype = {arxiv},
  file = {/Users/ztzhang/Zotero/storage/3RMI3KJG/Xu, Hero - 2014 - Dynamic stochastic blockmodels for time-evolving social networks(2).pdf;/Users/ztzhang/Zotero/storage/TRPDZ9KN/Xu, Hero - 2014 - Dynamic stochastic blockmodels for time-evolving social networks.pdf},
  journal = {IEEE Journal on Selected Topics in Signal Processing},
  keywords = {.State-space model,.Stochastic block model,.Time varying networks,extended Kalman filter,on-line estimation},
  number = {4}
}

@article{Xu2015,
  ids = {xuStochasticBlockTransition},
  title = {Stochastic Block Transition Models for Dynamic Networks},
  author = {Xu, Kevin S.},
  year = {2015},
  volume = {38},
  pages = {1079--1087},
  publisher = {{Microtome Publishing}},
  issn = {15337928},
  abstract = {There has been great interest in recent years on statistical models for dynamic networks. In this paper, I propose a stochastic block transition model (SBTM) for dynamic networks that is inspired by the well-known stochastic block model (SBM) for static networks and previous dynamic extensions of the SBM. Unlike most existing dynamic network models, it does not make a hidden Markov assumption on the edge-level dynamics, allowing the presence or absence of edges to directly influence future edge probabilities while retaining the interpretability of the SBM. I derive an approximate inference procedure for the SBTM and demonstrate that it is significantly better at reproducing durations of edges in real social network data.},
  annotation = {\_eprint: 1411.5404},
  file = {/Users/ztzhang/Zotero/storage/A5R2EL5N/Xu - Stochastic Block Transition Models for Dynamic Net.pdf;/Users/ztzhang/Zotero/storage/QDFKAM77/Xu - 2015 - Stochastic Block Transition Models for Dynamic Networks.pdf},
  journal = {Journal of Machine Learning Research},
  keywords = {.Stochastic block model,.Time varying networks}
}

@article{Xu2020,
  title = {Learning {{Graphons}} via {{Structured Gromov}}-{{Wasserstein Barycenters}}},
  author = {Xu, Hongteng and Luo, Dixin and Carin, Lawrence and Zha, Hongyuan},
  year = {2020},
  month = dec,
  abstract = {We propose a novel and principled method to learn a nonparametric graph model called graphon, which is defined in an infinite-dimensional space and represents arbitrary-size graphs. Based on the weak regularity lemma from the theory of graphons, we leverage a step function to approximate a graphon. We show that the cut distance of graphons can be relaxed to the Gromov-Wasserstein distance of their step functions. Accordingly, given a set of graphs generated by an underlying graphon, we learn the corresponding step function as the Gromov-Wasserstein barycenter of the given graphs. Furthermore, we develop several enhancements and extensions of the basic algorithm, \$e.g.\$, the smoothed Gromov-Wasserstein barycenter for guaranteeing the continuity of the learned graphons and the mixed Gromov-Wasserstein barycenters for learning multiple structured graphons. The proposed approach overcomes drawbacks of prior state-of-the-art methods, and outperforms them on both synthetic and real-world data. The code is available at https://github.com/HongtengXu/SGWB-Graphon.},
  archivePrefix = {arXiv},
  eprint = {2012.05644},
  eprinttype = {arxiv},
  journal = {arXiv:2012.05644 [cs, stat]},
  keywords = {.unlabeled,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Yang2011,
  title = {Detecting Communities and Their Evolutions in Dynamic Social Networks - {{A Bayesian}} Approach},
  author = {Yang, Tianbao and Chi, Yun and Zhu, Shenghuo and Gong, Yihong and Jin, Rong},
  year = {2011},
  month = feb,
  volume = {82},
  pages = {157--189},
  issn = {08856125},
  doi = {10.1007/s10994-010-5214-7},
  abstract = {Although a large body of work is devoted to finding communities in static social networks, only a few studies examined the dynamics of communities in evolving social networks. In this paper, we propose a dynamic stochastic block model for finding communities and their evolution in a dynamic social network. The proposed model captures the evolution of communities by explicitly modeling the transition of community memberships for individual nodes in the network. Unlike many existing approaches for modeling social networks that estimate parameters by their most likely values (i.e., point estimation), in this study, we employ a Bayesian treatment for parameter estimation that computes the posterior distributions for all the unknown parameters. This Bayesian treatment allows us to capture the uncertainty in parameter values and therefore is more robust to data noise than point estimation. In addition, an efficient algorithm is developed for Bayesian inference to handle large sparse social networks. Extensive experimental studies based on both synthetic data and real-life data demonstrate that our model achieves higher accuracy and reveals more insights in the data than several state-of-the-art algorithms. \textcopyright{} 2010 The Author(s).},
  file = {/Users/ztzhang/Zotero/storage/A4IT9JTF/Yang et al. - 2011 - Detecting communities and their evolutions in dynamic social networks - A Bayesian approach.pdf},
  journal = {Machine Learning},
  keywords = {.Stochastic block model,Bayesian inference,Community,Community evolution,Dynamic stochastic block model,Gibbs sampling},
  number = {2}
}

@article{Yauck2020,
  title = {General {{Regression Methods}} for {{Respondent}}-{{Driven Sampling Data}}},
  author = {Yauck, Mamadou and Moodie, Erica E. M. and Apelian, Herak and Fourmigue, Alain and Grace, Daniel and Hart, Trevor and Lambert, Gilles and Cox, Joseph},
  year = {2020},
  month = dec,
  abstract = {Respondent-Driven Sampling (RDS) is a variant of link-tracing sampling techniques that aim to recruit hard-to-reach populations by leveraging individuals' social relationships. As such, an RDS sample has a graphical component which represents a partially observed network of unknown structure. Moreover, it is common to observe homophily, or the tendency to form connections with individuals who share similar traits. Currently, there is a lack of principled guidance on multivariate modeling strategies for RDS to address homophilic covariates and the dependence between observations within the network. In this work, we propose a methodology for general regression techniques using RDS data. This is used to study the socio-demographic predictors of HIV treatment optimism (about the value of antiretroviral therapy) among gay, bisexual and other men who have sex with men, recruited into an RDS study in Montreal, Canada.},
  archivePrefix = {arXiv},
  eprint = {2012.00457},
  eprinttype = {arxiv},
  journal = {arXiv:2012.00457 [stat]},
  keywords = {.unlabeled,Statistics - Methodology},
  primaryClass = {stat}
}

@article{Yu2021,
  title = {Graph {{Matching}} with {{Partially}}-{{Correct Seeds}}},
  author = {Yu, Liren and Xu, Jiaming and Lin, Xiaojun},
  year = {2021},
  month = jan,
  abstract = {Graph matching aims to find the latent vertex correspondence between two edge-correlated graphs and has found numerous applications across different fields. In this paper, we study a seeded graph matching problem, which assumes that a set of seeds, i.e., pre-mapped vertex-pairs, is given in advance. While most previous work requires all seeds to be correct, we focus on the setting where the seeds are partially correct. Specifically, consider two correlated graphs whose edges are sampled independently from a parent \textbackslash ER graph \$\textbackslash mathcal\{G\}(n,p)\$. A mapping between the vertices of the two graphs is provided as seeds, of which an unknown \$\textbackslash beta\$ fraction is correct. We first analyze a simple algorithm that matches vertices based on the number of common seeds in the \$1\$-hop neighborhoods, and then further propose a new algorithm that uses seeds in the \$2\$-hop neighborhoods. We establish non-asymptotic performance guarantees of perfect matching for both \$1\$-hop and \$2\$-hop algorithms, showing that our new \$2\$-hop algorithm requires substantially fewer correct seeds than the \$1\$-hop algorithm when graphs are sparse. Moreover, by combining our new performance guarantees for the \$1\$-hop and \$2\$-hop algorithms, we attain the best-known results (in terms of the required fraction of correct seeds) across the entire range of graph sparsity and significantly improve the previous results in \textbackslash cite\{10.14778/2794367.2794371,lubars2018correcting\} when \$p\textbackslash ge n\^\{-5/6\}\$. For instance, when \$p\$ is a constant or \$p=n\^\{-3/4\}\$, we show that only \$\textbackslash Omega(\textbackslash sqrt\{n\textbackslash log n\})\$ correct seeds suffice for perfect matching, while the previously best-known results demand \$\textbackslash Omega(n)\$ and \$\textbackslash Omega(n\^\{3/4\}\textbackslash log n)\$ correct seeds, respectively. Numerical experiments corroborate our theoretical findings, demonstrating the superiority of our \$2\$-hop algorithm on a variety of synthetic and real graphs.},
  archivePrefix = {arXiv},
  eprint = {2004.03816},
  eprinttype = {arxiv},
  journal = {arXiv:2004.03816 [cs, stat]},
  keywords = {.Graph matching,Computer Science - Data Structures and Algorithms,Computer Science - Discrete Mathematics,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Yuan2007,
  title = {Model Selection and Estimation in the {{Gaussian}} Graphical Model},
  author = {Yuan, Ming and Lin, Yi},
  year = {2007},
  month = mar,
  volume = {94},
  pages = {19--35},
  issn = {00063444},
  doi = {10.1093/biomet/asm018},
  abstract = {We propose penalized likelihood methods for estimating the concentration matrix in the Gaussian graphical model. The methods lead to a sparse and shrinkage estimator of the concentration matrix that is positive definite, and thus conduct model selection and estimation simultaneously. The implementation of the methods is nontrivial because of the positive definite constraint on the concentration matrix, but we show that the computation can be done effectively by taking advantage of the efficient maxdet algorithm developed in convex optimization. We propose a BIC-type criterion for the selection of the tuning parameter in the penalized likelihood methods. The connection between our methods and existing methods is illustrated. Simulations and real examples demonstrate the competitive performance of the new methods.},
  file = {/Users/ztzhang/Zotero/storage/PYHW7RTR/Yuan, Lin - 2007 - Model selection and estimation in the Gaussian graphical model.pdf},
  journal = {Biometrika},
  keywords = {Covariance selection,Lasso,Maxdet algorithm,Nonnegative garrote,Penalized likelihood},
  number = {1}
}

@article{Zhang2016,
  title = {{{MINIMAX RATES OF COMMUNITY DETECTION IN STOCHASTIC BLOCK MODELS}}},
  author = {Zhang, Anderson Y and Zhou, Harrison H},
  year = {2016},
  volume = {44},
  pages = {2252--2280},
  doi = {10.1214/15-AOS1428},
  abstract = {Recently, network analysis has gained more and more attention in statistics , as well as in computer science, probability and applied mathematics. Community detection for the stochastic block model (SBM) is probably the most studied topic in network analysis. Many methodologies have been proposed. Some beautiful and significant phase transition results are obtained in various settings. In this paper, we provide a general minimax theory for community detection. It gives minimax rates of the mis-match ratio for a wide rage of settings including homogeneous and inhomogeneous SBMs, dense and sparse networks, finite and growing number of communities. The minimax rates are exponential, different from polynomial rates we often see in statistical literature. An immediate consequence of the result is to establish threshold phenomenon for strong consistency (exact recovery) as well as weak consistency (partial recovery). We obtain the upper bound by a range of penalized likelihood-type approaches. The lower bound is achieved by a novel reduction from a global mis-match ratio to a local clustering problem for one node through an exchangeability property.},
  file = {/Users/ztzhang/Zotero/storage/7ZSZXC76/Zhang, Zhou - 2016 - MINIMAX RATES OF COMMUNITY DETECTION IN STOCHASTIC BLOCK MODELS.pdf},
  journal = {The Annals of Statistics},
  keywords = {.Stochastic block model,60G05,community detection,minimax rate,Network},
  number = {5}
}

@article{Zhang2017,
  title = {Estimating Network Edge Probabilities by Neighbourhood Smoothing},
  author = {Zhang, Yuan and Levina, Elizaveta and Zhu, Ji},
  year = {2017},
  month = dec,
  volume = {104},
  pages = {771--783},
  issn = {0006-3444},
  doi = {10.1093/biomet/asx042},
  abstract = {{$<$}p{$>$}The estimation of probabilities of network edges from the observed adjacency matrix has important applications to the prediction of missing links and to network denoising. It is usually addressed by estimating the graphon, a function that determines the matrix of edge probabilities, but this is ill-defined without strong assumptions on the network structure. Here we propose a novel computationally efficient method, based on neighbourhood smoothing, to estimate the expectation of the adjacency matrix directly, without making the structural assumptions that graphon estimation requires. The neighbourhood smoothing method requires little tuning, has a competitive mean squared error rate and outperforms many benchmark methods for link prediction in simulated and real networks.{$<$}/p{$>$}},
  file = {/Users/ztzhang/Zotero/storage/RWMFJDCC/Zhang, Levina, Zhu - 2017 - Estimating network edge probabilities by neighbourhood smoothing.pdf},
  journal = {Biometrika},
  number = {4}
}

@article{Zhang2019,
  ids = {zhangMixedEffectTimeVaryingNetwork2018},
  title = {Mixed-{{Effect Time}}-{{Varying Network Model}} and {{Application}} in {{Brain Connectivity Analysis}}},
  author = {Zhang, Jingfei and Sun, Will Wei and Li, Lexin},
  year = {2019},
  publisher = {{American Statistical Association}},
  issn = {1537274X},
  doi = {10.1080/01621459.2019.1677242},
  abstract = {Time-varying networks are fast emerging in a wide range of scientific and business applications. Most existing dynamic network models are limited to a single-subject and discrete-time setting. In this article, we propose a mixed-effect network model that characterizes the continuous time-varying behavior of the network at the population level, meanwhile taking into account both the individual subject variability as well as the prior module information. We develop a multistep optimization procedure for a constrained likelihood estimation and derive the associated asymptotic properties. We demonstrate the effectiveness of our method through both simulations and an application to a study of brain development in youth. Supplementary materials for this article are available online.},
  archivePrefix = {arXiv},
  eprint = {1806.03829},
  eprinttype = {arxiv},
  journal = {Journal of the American Statistical Association},
  keywords = {.Multi-subject network,.Stochastic block model,Brain connectivity analysis,Fused lasso,Generalized linear mixed-effect model,Time-varying network}
}

@article{Zhang2019a,
  title = {Node {{Features Adjusted Stochastic Block Model}}},
  author = {Zhang, Yun and Chen, Kehui and Sampson, Allan and Hwang, Kai and Luna, Beatriz},
  year = {2019},
  month = apr,
  volume = {28},
  pages = {362--373},
  issn = {1061-8600},
  doi = {10.1080/10618600.2018.1530117},
  journal = {Journal of Computational and Graphical Statistics},
  number = {2}
}

@article{Zhang2020,
  title = {Adjusted Chi-Square Test for Degree-Corrected Block Models},
  author = {Zhang, Linfan and Amini, Arash A.},
  year = {2020},
  month = dec,
  abstract = {We propose a goodness-of-fit test for degree-corrected stochastic block models (DCSBM). The test is based on an adjusted chi-square statistic for measuring equality of means among groups of \$n\$ multinomial distributions with \$d\_1,\textbackslash dots,d\_n\$ observations. In the context of network models, the number of multinomials, \$n\$, grows much faster than the number of observations, \$d\_i\$, hence the setting deviates from classical asymptotics. We show that a simple adjustment allows the statistic to converge in distribution, under null, as long as the harmonic mean of \$\textbackslash\{d\_i\textbackslash\}\$ grows to infinity. This result applies to large sparse networks where the role of \$d\_i\$ is played by the degree of node \$i\$. Our distributional results are nonasymptotic, with explicit constants, providing finite-sample bounds on the Kolmogorov-Smirnov distance to the target distribution. When applied sequentially, the test can also be used to determine the number of communities. The test operates on a (row) compressed version of the adjacency matrix, conditional on the degrees, and as a result is highly scalable to large sparse networks. We incorporate a novel idea of compressing the columns based on a \$(K+1)\$-community assignment when testing for \$K\$ communities. This approach increases the power in sequential applications without sacrificing computational efficiency, and we prove its consistency in recovering the number of communities. Since the test statistic does not rely on a specific alternative, its utility goes beyond sequential testing and can be used to simultaneously test against a wide range of alternatives outside the DCSBM family. We show the effectiveness of the approach by extensive numerical experiments with simulated and real data. In particular, applying the test to the Facebook-100 dataset, we find that a DCSBM with a small number of communities is far from a good fit in almost all cases.},
  archivePrefix = {arXiv},
  eprint = {2012.15047},
  eprinttype = {arxiv},
  journal = {arXiv:2012.15047 [cs, math, stat]},
  keywords = {.Network structure testing},
  primaryClass = {cs, math, stat}
}

@article{Zhang2021,
  title = {Consistency of Random-Walk Based Network Embedding Algorithms},
  author = {Zhang, Yichi and Tang, Minh},
  year = {2021},
  month = jan,
  abstract = {Random-walk based network embedding algorithms like node2vec and DeepWalk are widely used to obtain Euclidean representation of the nodes in a network prior to performing down-stream network inference tasks. Nevertheless, despite their impressive empirical performance, there is a lack of theoretical results explaining their behavior. In this paper we studied the node2vec and DeepWalk algorithms through the perspective of matrix factorization. We analyze these algorithms in the setting of community detection for stochastic blockmodel graphs; in particular we established large-sample error bounds and prove consistent community recovery of node2vec/DeepWalk embedding followed by k-means clustering. Our theoretical results indicate a subtle interplay between the sparsity of the observed networks, the window sizes of the random walks, and the convergence rates of the node2vec/DeepWalk embedding toward the embedding of the true but unknown edge probabilities matrix. More specifically, as the network becomes sparser, our results suggest using larger window sizes, or equivalently, taking longer random walks, in order to attain better convergence rate for the resulting embeddings. The paper includes numerical experiments corroborating these observations.},
  archivePrefix = {arXiv},
  eprint = {2101.07354},
  eprinttype = {arxiv},
  journal = {arXiv:2101.07354 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Zhao,
  title = {A {{Nonconvex Optimization Framework}} for {{Low Rank Matrix Estimation}}},
  author = {Zhao, Tuo and Wang, Zhaoran and Liu, Han},
  abstract = {We study the estimation of low rank matrices via nonconvex optimization. Compared with convex relaxation, nonconvex optimization exhibits superior empirical performance for large scale instances of low rank matrix estimation. However, the understanding of its theoretical guarantees are limited. In this paper, we define the notion of projected oracle divergence based on which we establish sufficient conditions for the success of nonconvex optimization. We illustrate the consequences of this general framework for matrix sensing. In particular, we prove that a broad class of nonconvex optimization algorithms, including alternating minimization and gradient-type methods, geometrically converge to the global optimum and exactly recover the true low rank matrices under standard conditions.},
  file = {/Users/ztzhang/Zotero/storage/Y3524M47/Zhao, Wang, Liu - Unknown - A Nonconvex Optimization Framework for Low Rank Matrix Estimation ⇤.pdf},
  keywords = {nonconvex optimization}
}

@article{Zhao2012,
  title = {Consistency of Community Detection in Networks under Degree-Corrected Stochastic Block Models},
  author = {Zhao, Yunpeng and Levina, Elizaveta and Zhu, Ji I},
  year = {2012},
  month = aug,
  volume = {40},
  pages = {2266--2292},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364},
  abstract = {Community detection is a fundamental problem in network analysis, with applications in many diverse areas. The stochastic block model is a common tool for model-based community detection, and asymptotic tools for checking consistency of community detection under the block model have been recently developed. However, the block model is limited by its assumption that all nodes within a community are stochastically equivalent, and provides a poor fit to networks with hubs or highly varying node degrees within communities, which are common in practice. The degree-corrected stochastic block model was proposed to address this shortcoming and allows variation in node degrees within a community while preserving the overall block community structure. In this paper we establish general theory for checking consistency of community detection under the degree-corrected stochastic block model and compare several community detection criteria under both the standard and the degree-corrected models. We show which criteria are consistent under which models and constraints, as well as compare their relative performance in practice. We find that methods based on the degree-corrected block model, which includes the standard block model as a special case, are consistent under a wider class of models and that modularity-type methods require parameter constraints for consistency, whereas likelihood-based methods do not. On the other hand, in practice, the degree correction involves estimating many more parameters, and empirically we find it is only worth doing if the node degrees within communities are indeed highly variable. We illustrate the methods on simulated networks and on a network of political blogs.},
  file = {/Users/ztzhang/Zotero/storage/LIIGKVPU/Zhao, Levina, Zhu - 2012 - Consistency of community detection in networks under degree-corrected stochastic block models.pdf},
  journal = {The Annals of Statistics},
  keywords = {62G20,Community detection,consistency,degree-corrected stochastic block models},
  number = {4}
}

@article{Zhao2017,
  title = {A {{Survey}} on {{Theoretical Advances}} of {{Community Detection}} in {{Networks}}},
  author = {Zhao, Yunpeng},
  year = {2017},
  month = sep,
  volume = {9},
  pages = {e1403},
  issn = {19395108},
  doi = {10.1002/wics.1403},
  abstract = {Real-world networks usually have community structure, that is, nodes are grouped into densely connected communities. Community detection is one of the most popular and best-studied research topics in network science and has attracted attention in many different fields, including computer science, statistics, social sciences, among others. Numerous approaches for community detection have been proposed in literature, from ad-hoc algorithms to systematic model-based approaches. The large number of available methods leads to a fundamental question: whether a certain method can provide consistent estimates of community labels. The stochastic blockmodel (SBM) and its variants provide a convenient framework for the study of such problems. This article is a survey on the recent theoretical advances of community detection. The authors review a number of community detection methods and their theoretical properties, including graph cut methods, profile likelihoods, the pseudo-likelihood method, the variational method, belief propagation, spectral clustering, and semidefinite relaxations of the SBM. The authors also briefly discuss other research topics in community detection such as robust community detection, community detection with nodal covariates and model selection, as well as suggest a few possible directions for future research.},
  archivePrefix = {arXiv},
  eprint = {1809.07691},
  eprinttype = {arxiv},
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  keywords = {.Belief propagation,.Community detection,.Graph cut,.Profile likelihood,.Pseudo likelihood,.Semidefinite relaxation,.Spectral clustering,.Theoretical property,.Theory,.Variational method,62G99,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  number = {5}
}

@article{Zhaoa,
  title = {Change-Point Detection in Dynamic Networks via Graphon Estimation},
  author = {Zhao, Zifeng and Chen, Li and Lin, Lizhen},
  abstract = {We propose a general approach for change-point detection in dynamic networks. The proposed method is model-free and covers a wide range of dynamic networks. The key idea behind our approach is to effectively utilize the network structure in designing change-point detection algorithms. This is done via an initial step of graphon estimation, where we propose a modified neighborhood smoothing (MNBS) algorithm for estimating the link probability matrices of a dynamic network. Based on the initial graphon estimation, we then develop a screening and thresholding algorithm for multiple change-point detection in dynamic networks. The convergence rate and consistency for the change-point detection procedure are derived as well as those for MNBS. When the number of nodes is large (e.g., exceeds the number of temporal points), our approach yields a faster convergence rate in detecting change-points comparing with an algorithm that simply employs averaged information of the dynamic network across time. Numerical experiments demonstrate robust performance of the proposed algorithm for change-point detection under various types of dynamic networks, and superior performance over existing methods is observed. A real data example is provided to illustrate the effectiveness and practical impact of the procedure.},
  annotation = {\_eprint: 1908.01823v1},
  file = {/Users/ztzhang/Zotero/storage/XE7N663X/Zhao, Chen, Lin - Unknown - Change-point detection in dynamic networks via graphon estimation.pdf}
}

@article{Zhou2013,
  title = {Learning Social Infectivity in Sparse Low-Rank Networks Using Multi-Dimensional Hawkes Processes},
  author = {Zhou, Ke and Zha, Hongyuan and Song, Le},
  year = {2013},
  volume = {31},
  pages = {641--649},
  issn = {1533-7928},
  abstract = {How will the behaviors of individuals in a social network be influenced by their neighbors, the authorities and the communities? Such knowledge is often hidden from us and we only observe its manifestation in the form of recurrent and time-stamped events occurring at the individuals involved. It is an important yet challenging problem to infer the network of social inference based on the temporal patterns of these historical events. We propose a convex optimization approach to discover the hidden network of social influence by modeling the recurrent events at different individuals as multi-dimensional Hawkes processes. Furthermore, our estimation procedure, using nuclear and {$\mathscr{l}$}1{$\mathscr{l}$}1 norm regularization simultaneously on the parameters, is able to take into account the prior knowledge of the presence of neighbor interaction, authority influence, and community coordination. To efficiently solve the problem, we also design an algorithm ADM4 which combines techniques of alternating direction method of multipliers and majorization minimization. We experimented with both synthetic and real world data sets, and showed that the proposed method can discover the hidden network more accurately and produce a better predictive model.},
  file = {/Users/ztzhang/Zotero/storage/VZ38URQR/Zhou, Zha, Song - 2013 - Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes.pdf},
  journal = {Journal of Machine Learning Research},
  keywords = {.Hawkes processes,.Network inference,Network extraction}
}


