Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Zhao2012,
abstract = {Community detection is a fundamental problem in network analysis, with applications in many diverse areas. The stochastic block model is a common tool for model-based community detection, and asymptotic tools for checking consistency of community detection under the block model have been recently developed. However, the block model is limited by its assumption that all nodes within a community are stochastically equivalent, and provides a poor fit to networks with hubs or highly varying node degrees within communities, which are common in practice. The degree-corrected stochastic block model was proposed to address this shortcoming and allows variation in node degrees within a community while preserving the overall block community structure. In this paper we establish general theory for checking consistency of community detection under the degree-corrected stochastic block model and compare several community detection criteria under both the standard and the degree-corrected models. We show which criteria are consistent under which models and constraints, as well as compare their relative performance in practice. We find that methods based on the degree-corrected block model, which includes the standard block model as a special case, are consistent under a wider class of models and that modularity-type methods require parameter constraints for consistency, whereas likelihood-based methods do not. On the other hand, in practice, the degree correction involves estimating many more parameters, and empirically we find it is only worth doing if the node degrees within communities are indeed highly variable. We illustrate the methods on simulated networks and on a network of political blogs.},
annote = {Degree-corrected method: address the problem caused by stochastically equivalence (hubs), allows variation in node degrees within a cluster, while preserving the overall block community structure.},
author = {Zhao, Yunpeng and Levina, Elizaveta and Zhu, Ji I},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhao, Levina, Zhu - 2012 - CONSISTENCY OF COMMUNITY DETECTION IN NETWORKS UNDER DEGREE-CORRECTED STOCHASTIC BLOCK MODELS.pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
keywords = {62G20,Community detection,consistency,degree-corrected stochastic block models},
month = {aug},
number = {4},
pages = {2266--2292},
publisher = {Institute of Mathematical Statistics},
title = {{CONSISTENCY OF COMMUNITY DETECTION IN NETWORKS UNDER DEGREE-CORRECTED STOCHASTIC BLOCK MODELS}},
volume = {40},
year = {2012}
}
@article{Matias2018,
abstract = {To model recurrent interaction events in continuous time, an extension of the stochastic block model is proposed where every individual belongs to a latent group and interactions between two individuals follow a conditional inhomogeneous Poisson process with intensity driven by the individuals' latent groups. The model is shown to be identifiable and its estimation is based on a semiparametric variational expectation-maximization algorithm. Two versions of the method are developed, using either a nonparametric histogram approach (with an adaptive choice of the partition size) or kernel intensity estimators. The number of latent groups can be selected by an integrated classification likelihood criterion. Finally, we demonstrate the performance of our procedure on synthetic experiments, analyse two datasets to illustrate the utility of our approach and comment on competing methods.},
annote = {Model the interactions {\{}(t{\_}m,i{\_}m,j{\_},),m=1,...M{\}} by point process:
1. Each node belongs to a latent cluster;
2, Interactions between two nodes i, j are Poisson processes with intensity function only dependent on there clusters k,l

They showed the identifiability of cluster probability vector $\backslash$pi and inter-group intensities $\backslash$alpha (up to label switching)

To infer the above parameters, variational EM algorithm is proposed. 
$\backslash$alpha is infered by histogram or kernel method.


They have many samples (i.e. interactions between each pair of nodes), while we have at most one. So we need to integrate interactions within each group in order to infer the intensity.},
archivePrefix = {arXiv},
arxivId = {1512.07075},
author = {Matias, Catherine and Rebafka, Tabea and Villers, Fanny},
doi = {10.1093/biomet/asy016},
eprint = {1512.07075},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Matias, Rebafka, Villers - 2018 - A semiparametric extension of the stochastic block model for longitudinal networks.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
number = {3},
pages = {665--680},
title = {{A semiparametric extension of the stochastic block model for longitudinal networks}},
url = {https://academic.oup.com/biomet/article/105/3/665/5032575 http://arxiv.org/abs/1512.07075},
volume = {105},
year = {2018}
}
@article{Candes2009,
abstract = {This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible; but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful. This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank r by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr polylog(n).},
archivePrefix = {arXiv},
arxivId = {0903.1476},
author = {Candes, Emmanuel J. and Tao, Terence},
eprint = {0903.1476},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Candes, Tao - 2009 - The Power of Convex Relaxation Near-Optimal Matrix Completion.pdf:pdf},
month = {mar},
title = {{The Power of Convex Relaxation: Near-Optimal Matrix Completion}},
url = {http://arxiv.org/abs/0903.1476},
year = {2009}
}
@techreport{Zhao,
abstract = {We propose a general approach for change-point detection in dynamic networks. The proposed method is model-free and covers a wide range of dynamic networks. The key idea behind our approach is to effectively utilize the network structure in designing change-point detection algorithms. This is done via an initial step of graphon estimation, where we propose a modified neighborhood smoothing (MNBS) algorithm for estimating the link probability matrices of a dynamic network. Based on the initial graphon estimation, we then develop a screening and thresholding algorithm for multiple change-point detection in dynamic networks. The convergence rate and consistency for the change-point detection procedure are derived as well as those for MNBS. When the number of nodes is large (e.g., exceeds the number of temporal points), our approach yields a faster convergence rate in detecting change-points comparing with an algorithm that simply employs averaged information of the dynamic network across time. Numerical experiments demonstrate robust performance of the proposed algorithm for change-point detection under various types of dynamic networks, and superior performance over existing methods is observed. A real data example is provided to illustrate the effectiveness and practical impact of the procedure.},
archivePrefix = {arXiv},
arxivId = {1908.01823v1},
author = {Zhao, Zifeng and Chen, Li and Lin, Lizhen},
eprint = {1908.01823v1},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhao, Chen, Lin - Unknown - Change-point detection in dynamic networks via graphon estimation.pdf:pdf},
title = {{Change-point detection in dynamic networks via graphon estimation}}
}
@book{Chi2007,
abstract = {Evolutionary clustering is an emerging research area essential to important applications such as clustering dynamic Web and blog contents and clustering data streams. In evolutionary clustering, a good clustering result should fit the current data well, while simultaneously not deviate too dramatically from the recent history. To fulfill this dual purpose , a measure of temporal smoothness is integrated in the overall measure of clustering quality. In this paper, we propose two frameworks that incorporate temporal smoothness in evolutionary spectral clustering. For both frameworks, we start with intuitions gained from the well-known k-means clustering problem, and then propose and solve corresponding cost functions for the evolutionary spectral clustering problems. Our solutions to the evolutionary spectral clustering problems provide more stable and consistent clustering results that are less sensitive to short-term noises while at the same time are adaptive to long-term cluster drifts. Furthermore, we demonstrate that our methods provide the optimal solutions to the relaxed versions of the corresponding evolutionary k-means clustering problems. Performance experiments over a number of real and synthetic data sets illustrate our evolutionary spectral clustering methods provide more robust clustering results that are not sensitive to noise and can adapt to data drifts.},
annote = {Make no assumption on the mechanism that governs changes in the cluster memberships.

Propose three measurement of cluster quality:
1. K-means
2. Negated average association (within group)
3. Graph cut

Introduce two cost functions: 
1. the snapshot cost associated with the error of current clustering, 
2. and the temporal cost that measures how the clustering preserves continuity in terms of cluster memberships,},
author = {Chi, Yun and Song, Xiaodan and Zhou, Dengyong and Hino, Koji and Tseng, Belle L},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Chi et al. - 2007 - Evolutionary Spectral Clustering by Incorporating Temporal Smoothness †.pdf:pdf},
isbn = {9781595936097},
keywords = {Experimentation,H28 [Database Management]: Database Applications-D,Measurement,Mining Data Streams,Preserving Cluster Membership,Preserving Cluster Quality,Temporal Smoothness,Theory * Keywords Evolutionary Spectral Clustering},
title = {{Evolutionary Spectral Clustering by Incorporating Temporal Smoothness †}},
year = {2007}
}
@article{Pensky2019,
abstract = {In the present paper, we have studied a Dynamic Stochastic Block Model (DSBM) under the assumptions that the connection probabilities , as functions of time, are smooth and that at most s nodes can switch their class memberships between two consecutive time points. We estimate the edge probability tensor by a kernel-type procedure and extract the group memberships of the nodes by spectral clustering. The procedure is computationally viable, adaptive to the unknown smoothness of the functional connection probabilities, to the rate s of membership switching, and to the unknown number of clusters. In addition, it is accompanied by non-asymptotic guarantees for the precision of estimation and clustering. MSC 2010 subject classifications: Primary 62F12, 05C80; secondary 62H30.},
annote = {Assume neither connection probabilities, nor class memberships change drastically from one time instant to another.

1. Extract group memberships at every timepoint by using a spectral cluastering procedure;
2. the clustering technique is applied to kernel-type estimators of the edge probability matrices
3. Using Lepskii's method, adapt the method to the unknown temporal smoothness.
4. By setting a threshold on the ratio of the eigenvalues of the estimated probability matrix, they find the estimated number of clusters.},
author = {Pensky, Marianna and Zhang, Teng},
doi = {10.1214/19-EJS1533},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Pensky, Zhang - 2019 - Spectral clustering in the dynamic stochastic block model.pdf:pdf},
issn = {1935-7524},
journal = {Electron. J. Stat.},
keywords = {05C80,62F12,62H30Time-varying network,adaptive estimation,dynamic stochastic block model,spectral clustering},
pages = {678--709},
title = {{Spectral clustering in the dynamic stochastic block model}},
url = {https://doi.org/10.1214/19-EJS1533},
volume = {13},
year = {2019}
}
@article{Gao2018,
abstract = {This paper surveys some recent developments in fundamental limits and optimal algorithms for network analysis. We focus on minimax optimal rates in three fundamental problems of network analysis: graphon estimation, community detection, and hypothesis testing. For each problem, we review state-of-the-art results in the literature followed by general principles behind the optimal procedures that lead to minimax estimation and testing. This allows us to connect problems in network analysis to other statistical inference problems from a general perspective.},
archivePrefix = {arXiv},
arxivId = {1811.06055},
author = {Gao, Chao and Ma, Zongming},
eprint = {1811.06055},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gao, Ma - 2018 - Minimax Rates in Network Analysis Graphon Estimation, Community Detection and Hypothesis Testing.pdf:pdf},
month = {nov},
title = {{Minimax Rates in Network Analysis: Graphon Estimation, Community Detection and Hypothesis Testing}},
url = {http://arxiv.org/abs/1811.06055},
year = {2018}
}
@article{Wolfe2013,
abstract = {We propose a nonparametric framework for the analysis of networks, based on a natural limit object termed a graphon. We prove consistency of graphon estimation under general conditions, giving rates which include the important practical setting of sparse networks. Our results cover dense and sparse stochastic blockmodels with a growing number of classes, under model misspecification. We use profile likelihood methods, and connect our results to approximation theory, nonparametric function estimation, and the theory of graph limits.},
archivePrefix = {arXiv},
arxivId = {1309.5936},
author = {Wolfe, Patrick J. and Olhede, Sofia C.},
eprint = {1309.5936},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Wolfe, Olhede - 2013 - Nonparametric graphon estimation(2).pdf:pdf},
month = {sep},
title = {{Nonparametric graphon estimation}},
url = {http://arxiv.org/abs/1309.5936},
year = {2013}
}
@article{Ngo2012,
abstract = {This paper describes gradient methods based on a scaled metric on the Grassmann manifold for low-rank matrix completion. The proposed methods significantly improve canonical gradient methods, especially on ill-conditioned matrices, while maintaining established global convegence and exact recovery guarantees. A connection between a form of subspace iteration for matrix completion and the scaled gradient descent procedure is also established. The proposed conjugate gradient method based on the scaled gradient outperforms several existing algorithms for matrix completion and is competitive with recently proposed methods.},
author = {Ngo, Thanh T. and Saad, Yousef},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/ys-2012-5.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Adv. Neural Inf. Process. Syst.},
pages = {1412--1420},
title = {{Scaled gradients on Grassmann manifolds for matrix completion}},
volume = {2},
year = {2012}
}
@techreport{Gao2017,
abstract = {Community detection is a fundamental statistical problem in network data analysis. In this paper, we present a polynomial time two-stage method that provably achieves optimal statistical performance in misclassification proportion for stochastic block model under weak regularity conditions. Our two-stage procedure consists of a refinement stage motivated by penalized local maximum likelihood estimation. This stage can take a wide range of weakly consistent community detection procedures as its initializer, to which it applies and outputs a community assignment that achieves optimal misclassification proportion with high probability. The theoretical property is confirmed by simulated examples.},
author = {Gao, Chao and Ma, Zongming and Zhang, Anderson Y and Zhou, Harrison H},
booktitle = {J. Mach. Learn. Res.},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2017 - Achieving Optimal Misclassification Proportion in Stochastic Block Models.pdf:pdf},
keywords = {Clustering,Community detection,Minimax rates,Network analysis,Spectral clustering},
pages = {1--45},
title = {{Achieving Optimal Misclassification Proportion in Stochastic Block Models}},
url = {http://jmlr.org/papers/v18/16-245.html.},
volume = {18},
year = {2017}
}
@article{Edelman1998,
abstract = {In this paper we develop new Newton and conjugate gradient algorithms on the Grassmann and Stiefel manifolds. These manifolds represent the constraints that arise in such areas as the symmetric eigenvalue problem, nonlinear eigenvalue problems, electronic structures computations, and signal processing. In addition to the new algorithms, we show how the geometrical framework gives penetrating new insights allowing us to create, understand, and compare algorithms. The theory proposed here provides a taxonomy for numerical linear algebra algorithms that provide a top level mathematical view of previously unrelated algorithms. It is our hope that developers of new algorithms and perturbation theories will benefit from the theory, methods, and examples in this paper.},
author = {Edelman, Alan and Arias, TOM{\'{A}}S A. and Smith, Steven T.},
doi = {10.1137/S0895479895290954},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/edelman98.pdf:pdf},
issn = {08954798},
journal = {SIAM J. Matrix Anal. Appl.},
keywords = {Conjugate gradient,Eigenvalue optimization,Eigenvalues and eigenvectors,Grassmann manifold,Invariant subspace,Newton's method,Orthogonality constraints,Rayleigh quotient iteration,Sequential quadratic programming,Stiefel manifold},
number = {2},
pages = {303--353},
publisher = {Society for Industrial and Applied Mathematics Publications},
title = {{The geometry of algorithms with orthogonality constraints}},
volume = {20},
year = {1998}
}
@techreport{Xu2015,
abstract = {There has been great interest in recent years on statistical models for dynamic networks. In this paper, I propose a stochastic block transition model (SBTM) for dynamic networks that is inspired by the well-known stochastic block model (SBM) for static networks and previous dynamic extensions of the SBM. Unlike most existing dynamic network models, it does not make a hidden Mar-kov assumption on the edge-level dynamics, allowing the presence or absence of edges to directly influence future edge probabilities while retaining the interpretability of the SBM. I derive an approximate inference procedure for the SBTM and demonstrate that it is significantly better at reproducing durations of edges in real social network data.},
annote = {All edges in a block at time t-1 are equally likely to re-appear at time t, and non-edges in a block at time t-1 are equally likely to appear at time t.},
author = {Xu, Kevin S},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Xu - 2015 - Stochastic Block Transition Models for Dynamic Networks.pdf:pdf},
title = {{Stochastic Block Transition Models for Dynamic Networks}},
year = {2015}
}
@misc{Rossetti2018,
abstract = {Several research studies have shown that complex networks modeling real-world phenomena are characterized by striking properties: (i) they are organized according to community structure, and (ii) their structure evolves with time. Many researchers have worked on methods that can efficiently unveil substructures in complex networks, giving birth to the field of community discovery. A novel and fascinating problem started capturing researcher interest recently: the identification of evolving communities. Dynamic networks can be used to model the evolution of a system: nodes and edges are mutable, and their presence, or absence, deeply impacts the community structure that composes them. This survey aims to present the distinctive features and challenges of dynamic community discovery and propose a classification of published approaches. As a “user manual,” this work organizes state-of-the-art methodologies into a taxonomy, based on their rationale, and their specific instantiation. Given a definition of network dynamics, desired community characteristics, and analytical needs, this survey will support researchers to identify the set of approaches that best fit their needs. The proposed classification could also help researchers choose in which direction to orient their future research.},
archivePrefix = {arXiv},
arxivId = {1707.03186},
author = {Rossetti, Giulio and Cazabet, R{\'{e}}my},
booktitle = {ACM Comput. Surv.},
doi = {10.1145/3172867},
eprint = {1707.03186},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Rossetti, Cazabet - 2018 - Community discovery in dynamic networks A survey.pdf:pdf},
issn = {15577341},
keywords = {Community discovery,Dynamic networks,Temporal networks},
month = {feb},
number = {2},
publisher = {Association for Computing Machinery},
title = {{Community discovery in dynamic networks: A survey}},
volume = {51},
year = {2018}
}
@techreport{Holme,
abstract = {The power of any kind of network approach lies in the ability to simplify a complex system so that one can better understand its function as a whole. Sometimes it is beneficial, however, to include more information than in a simple graph of only nodes and links. Adding information about times of interactions can make predictions and mechanistic understanding more accurate. The drawback, however, is that there are not so many methods available, partly because temporal networks is a relatively young field, partly because it more difficult to develop such methods compared to for static networks. In this colloquium, we review the methods to analyze and model temporal networks and processes taking place on them, focusing mainly on the last three years. This includes the spreading of infectious disease, opinions, rumors, in social networks; information packets in computer networks; various types of signaling in biology, and more. We also discuss future directions.},
annote = {Review paper.},
archivePrefix = {arXiv},
arxivId = {1508.01303v3},
author = {Holme, Petter},
eprint = {1508.01303v3},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Holme - Unknown - Modern temporal network theory A colloquium.pdf:pdf},
title = {{Modern temporal network theory: A colloquium}},
url = {http://www.sociopatterns.org/.}
}
@article{Chandrasekaran2011,
abstract = {Suppose we are given a matrix that is formed by adding an unknown sparse matrix to an unknown low-rank matrix. Our goal is to decompose the given matrix into its sparse and low-rank components. Such a problem arises in a number of applications in model and system identification, and is NP-hard in general. In this paper we consider a convex optimization formulation to splitting the specified matrix into its components, by minimizing a linear combination of the {\$}\backslashell{\_}1{\$} norm and the nuclear norm of the components. We develop a notion of $\backslash$emph{\{}rank-sparsity incoherence{\}}, expressed as an uncertainty principle between the sparsity pattern of a matrix and its row and column spaces, and use it to characterize both fundamental identifiability as well as (deterministic) sufficient conditions for exact recovery. Our analysis is geometric in nature, with the tangent spaces to the algebraic varieties of sparse and low-rank matrices playing a prominent role. When the sparse and low-rank matrices are drawn from certain natural random ensembles, we show that the sufficient conditions for exact recovery are satisfied with high probability. We conclude with simulation results on synthetic matrix decomposition problems.},
author = {Chandrasekaran, Venkat and Sanghavi, Sujay and Parrilo, Pablo A. and Willsky, Alan S.},
doi = {10.1137/090761793},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Chandrasekaran et al. - 2011 - Rank-sparsity incoherence for matrix decomposition.pdf:pdf},
issn = {10526234},
journal = {SIAM J. Optim.},
keywords = {Convex relaxation,L1 norm minimization,Matrix decomposition,Nuclear norm minimization,Rank,Semidefinite programming,Sparsity,Uncertainty principle},
number = {2},
pages = {572--596},
title = {{Rank-sparsity incoherence for matrix decomposition}},
volume = {21},
year = {2011}
}
@article{Chi2019,
abstract = {Substantial progress has been made recently on developing provably accurate and efficient algorithms for low-rank matrix factorization via nonconvex optimization. While conventional wisdom often takes a dim view of nonconvex optimization algorithms due to their susceptibility to spurious local minima, simple iterative methods such as gradient descent have been remarkably successful in practice. The theoretical footings, however, had been largely lacking until recently. In this tutorial-style overview, we highlight the important role of statistical models in enabling efficient nonconvex optimization with performance guarantees. We review two contrasting approaches: (1) two-stage algorithms, which consist of a tailored initialization step followed by successive refinement; and (2) global landscape analysis and initialization-free algorithms. Several canonical matrix factorization problems are discussed, including but not limited to matrix sensing, phase retrieval, matrix completion, blind deconvolution, robust principal component analysis, phase synchronization, and joint alignment. Special care is taken to illustrate the key technical insights underlying their analyses. This article serves as a testament that the integrated consideration of optimization and statistics leads to fruitful research findings.},
archivePrefix = {arXiv},
arxivId = {arXiv:1809.09573v1},
author = {Chi, Yuejie and Lu, Yue M. and Chen, Yuxin},
doi = {10.1109/tsp.2019.2937282},
eprint = {arXiv:1809.09573v1},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/Chi et al. 2018.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Trans. Signal Process.},
pages = {1--1},
title = {{Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview}},
year = {2019}
}
@techreport{Borgs,
abstract = {We design algorithms for fitting a high-dimensional statistical model to a large, sparse network without revealing sensitive information of individual members. Given a sparse input graph G, our algorithms output a node-differentially private nonparametric block model approximation. By node-differentially private, we mean that our output hides the insertion or removal of a vertex and all its adjacent edges. If G is an instance of the network obtained from a generative nonparametric model defined in terms of a graphon W , our model guarantees consistency: as the number of vertices tends to infinity, the output of our algorithm converges to W in an appropriate version of the L 2 norm. In particular, this means we can estimate the sizes of all multi-way cuts in G. Our results hold as long as W is bounded, the average degree of G grows at least like the log of the number of vertices, and the number of blocks goes to infinity at an appropriate rate. We give explicit error bounds in terms of the parameters of the model; in several settings, our bounds improve on or match known nonprivate results.},
author = {Borgs, Christian and Chayes, Jennifer T and Smith, Adam},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Borgs, Chayes, Smith - Unknown - Private Graphon Estimation for Sparse Graphs.pdf:pdf},
title = {{Private Graphon Estimation for Sparse Graphs *}},
url = {http://arxiv.org/abs/1506.06162}
}
@article{Pensky2019a,
abstract = {In the present paper we consider a dynamic stochastic network model. The objective is estimation of the tensor of connection probabilities {\$}\backslashLambda{\$} when it is generated by a Dynamic Stochastic Block Model (DSBM) or a dynamic graphon. In particular, in the context of the DSBM, we derive a penalized least squares estimator {\$}\backslashwidehat{\{}\backslashLambda{\}}{\$} of {\$}\backslashLambda{\$} and show that {\$}\backslashwidehat{\{}\backslashLambda{\}}{\$} satisfies an oracle inequality and also attains minimax lower bounds for the risk. We extend those results to estimation of {\$}\backslashLambda{\$} when it is generated by a dynamic graphon function. The estimators constructed in the paper are adaptive to the unknown number of blocks in the context of the DSBM or to the smoothness of the graphon function. The technique relies on the vectorization of the model and leads to much simpler mathematical arguments than the ones used previously in the stationary set up. In addition, all results in the paper are non-asymptotic and allow a variety of extensions.},
annote = {From Duplicate 1 (Dynamic network models and graphon estimation - Pensky, Marianna)

From Duplicate 1 (DYNAMIC NETWORK MODELS AND GRAPHON ESTIMATION - Pensky, Marianna)

1. Fully nonparametric model that does not assume a probabilistic mechanism which governs the evolution of the network in time. It treats connection probabilities for each group as functional data.

2. Provides a minimax study of estimation of the tensor of connection probabilities in a dynamic setting. And the approach is nonasymptotic.

3. Use vectorization of the model. This technique allows to reduce the problem of estimatin of an unknown tensor of connection probabilities to a solution of a functional linear regression problem with sub-Gaussian errors.},
archivePrefix = {arXiv},
arxivId = {1607.00673},
author = {Pensky, Marianna},
doi = {10.1214/18-aos1751},
eprint = {1607.00673},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Pensky - 2019 - DYNAMIC NETWORK MODELS AND GRAPHON ESTIMATION(2).pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
keywords = {05C80,60G05,62F35,Dynamic network,graphon,minimax rate,nonparametric regression,stochastic block model},
month = {aug},
number = {4},
pages = {2378--2403},
publisher = {Institute of Mathematical Statistics},
title = {{Dynamic network models and graphon estimation}},
url = {https://doi.org/10.1214/18-AOS1751},
volume = {47},
year = {2019}
}
@techreport{Toyoda2003,
abstract = {Recent advances in storage technology make it possible to store a series of large Web archives. It is now an exciting challenge for us to observe evolution of the Web. In this paper, we propose a method for observing evolution of web communities. A web community is a set of web pages created by individuals or associations with a common interest on a topic. So far, various link analysis techniques have been developed to extract web communities. We analyze evolution of web communities by comparing four Japanese web archives crawled from 1999 to 2002. Statistics of these archives and community evolution are examined, and the global behavior of evolution is described. Several metrics are introduced to measure the degree of web community evolution , such as growth rate, novelty, and stability. We developed a system for extracting detailed evolution of communities using these metrics. It allows us to understand when and how communities emerged and evolved. Some evolution examples are shown using our system.},
annote = {Proposed different types of community changes, such as emerge, dissolve, grow, and shrink, as well as a set of metrics to quantify such changes for community evolution analysis.},
author = {Toyoda, Masashi and Kitsuregawa, Masaru},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Toyoda, Kitsuregawa - 2003 - Extracting Evolution of Web Communities from a Series of Web Archives.pdf:pdf},
keywords = {Algorithms Keywords Web,H54 [Information Interfaces and Presentation]: Hy-,Link analysis,Measurement,evolution,web community},
title = {{Extracting Evolution of Web Communities from a Series of Web Archives}},
year = {2003}
}
@article{Olhede2014,
abstract = {In this article we introduce the network histogram: a statistical summary of network interactions, to be used as a tool for exploratory data analysis. A network histogram is obtained by fitting a stochastic blockmodel to a single observation of a network dataset. Blocks of edges play the role of histogram bins, and community sizes that of histogram bandwidths or bin sizes. Just as standard histograms allow for varying bandwidths, different blockmodel estimates can all be considered valid representations of an underlying probability model, subject to bandwidth constraints. Here we provide methods for automatic bandwidth selection, by which the network histogram approximates the generating mechanism that gives rise to exchangeable random graphs. This makes the blockmodel a universal network representation for unlabeled graphs. With this insight, we discuss the interpretation of network communities in light of the fact that many different community assignments can all give an equally valid representation of such a network. To demonstrate the fidelity-versus-interpretability tradeoff inherent in considering different numbers and sizes of communities, we analyze two publicly available networks - political weblogs and student friendships - and discuss how to interpret the network histogram when additional information related to node and edge labeling is present.},
author = {Olhede, S. C. and Wolfe, P. J.},
doi = {10.1073/pnas.1400374111},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Olhede, Wolfe - 2014 - Network histograms and universality of blockmodel approximation.pdf:pdf},
issn = {0027-8424},
journal = {Proc. Natl. Acad. Sci.},
month = {oct},
number = {41},
pages = {14722--14727},
publisher = {Proceedings of the National Academy of Sciences},
title = {{Network histograms and universality of blockmodel approximation}},
volume = {111},
year = {2014}
}
@book{Tsybakov2009,
address = {New York, NY},
author = {Tsybakov, Alexandre B.},
doi = {10.1007/b13794},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Tsybakov - 2009 - Introduction to Nonparametric Estimation.pdf:pdf},
isbn = {978-0-387-79051-0},
publisher = {Springer New York},
series = {Springer Series in Statistics},
title = {{Introduction to Nonparametric Estimation}},
url = {http://link.springer.com/10.1007/b13794},
year = {2009}
}
@article{Keshavan2009a,
abstract = {Let M be a random (alpha n) x n matrix of rank r{\textless}{\textless}n, and assume that a uniformly random subset E of its entries is observed. We describe an efficient algorithm that reconstructs M from |E| = O(rn) observed entries with relative root mean square error RMSE {\textless}= C(rn/|E|){\^{}}0.5 . Further, if r=O(1), M can be reconstructed exactly from |E| = O(n log(n)) entries. These results apply beyond random matrices to general low-rank incoherent matrices. This settles (in the case of bounded rank) a question left open by Candes and Recht and improves over the guarantees for their reconstruction algorithm. The complexity of our algorithm is O(|E|r log(n)), which opens the way to its use for massive data sets. In the process of proving these statements, we obtain a generalization of a celebrated result by Friedman-Kahn-Szemeredi and Feige-Ofek on the spectrum of sparse random matrices.},
archivePrefix = {arXiv},
arxivId = {0901.3150},
author = {Keshavan, Raghunandan H. and Montanari, Andrea and Oh, Sewoong},
eprint = {0901.3150},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Keshavan, Montanari, Oh - 2009 - Matrix Completion from a Few Entries.pdf:pdf},
month = {jan},
title = {{Matrix Completion from a Few Entries}},
url = {http://arxiv.org/abs/0901.3150},
year = {2009}
}
@article{Wan2019,
abstract = {Graphical Abstract Highlights d Neurons are tracked from birth to entire circuit at cell-type and functional levels d Neurogenesis and emergence of coordinated activity is analyzed at a single-cell level d Motoneurons, active first, form ensembles that synchronize globally, based on size d Neuron maturation is stereotyped, based on birth time and anatomical origin In Brief Wan et al. reconstruct neurogenesis and the emergence of coordinated neuronal activity at the single-cell level in the zebrafish spinal cord by tracking neuron lineages, movements, molecular identities, and activity in the entire developing circuit. They find that functional maturation of neurons is stereotyped, based on birth time and anatomical origin, and that early motoneuron activity leads ensembles that synchronize globally, based on network size.},
author = {Wan, Yinan and Wei, Ziqiang and Looger, Loren L. and Koyama, Minoru and Druckmann, Shaul and {Keller Correspondence}, Philipp J and Keller, Philipp J.},
doi = {10.1016/j.cell.2019.08.039},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/WanKeller2019.pdf:pdf},
issn = {00928674},
journal = {Cell},
keywords = {calcium imaging,circuit development,computational data analysis,embryonic development,light-sheet microscopy,population activity,spinal cord,zebrafish},
month = {sep},
title = {{Single-Cell Reconstruction of Emerging Population Activity in an Entire Developing Circuit}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867419309584 https://doi.org/10.1016/j.cell.2019.08.039},
volume = {179},
year = {2019}
}
@techreport{Wang1987,
author = {Wang, Yuchung J and George, ; and Wong, Y},
booktitle = {J. Am. Stat. Assoc.},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Wang, George, Wong - 1987 - Stochastic Blockmodels for Directed Graphs.pdf:pdf},
number = {397},
pages = {8--19},
title = {{Stochastic Blockmodels for Directed Graphs}},
volume = {82},
year = {1987}
}
@article{Xu2012,
abstract = {This paper introduces an algorithm for the nonnegative matrix factorization-and-completion problem, which aims to find nonnegative low-rank matrices X and Y so that the product XY approximates a nonnegative data matrix M whose elements are partially known (to a certain accuracy). This problem aggregates two existing problems: (i) nonnegative matrix factorization where all entries of M are given, and (ii) low-rank matrix completion where nonnegativity is not required. By taking the advantages of both nonnegativity and low-rankness, one can generally obtain superior results than those of just using one of the two properties. We propose to solve the non-convex constrained least-squares problem using an algorithm based on the classic alternating direction augmented Lagrangian method. Preliminary convergence properties of the algorithm and numerical simulation results are presented. Compared to a recent algorithm for nonnegative matrix factorization, the proposed algorithm produces factorizations of similar quality using only about half of the matrix entries. On tasks of recovering incomplete grayscale and hyperspectral images, the proposed algorithm yields overall better qualities than those produced by two recent matrix-completion algorithms that do not exploit nonnegativity.},
author = {Xu, Yangyang and Yin, Wotao and Wen, Zaiwen and Zhang, Yin},
doi = {10.1007/s11464-012-0194-5},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Xu et al. - 2012 - An alternating direction algorithm for matrix completion with nonnegative factors.pdf:pdf},
issn = {16733452},
journal = {Front. Math. China},
keywords = {alternating direction method,hyperspectral unmixing,matrix completion,nonnegative matrix factorization},
month = {apr},
number = {2},
pages = {365--384},
title = {{An alternating direction algorithm for matrix completion with nonnegative factors}},
volume = {7},
year = {2012}
}
@book{Absil2009,
abstract = {Many problems in the sciences and engineering can be rephrased as optimization problems on matrix search spaces endowed with a so-called manifold structure. This book shows how to exploit the special structure of such problems to develop efficient numerical algorithms. It places careful emphasis on both the numerical formulation of the algorithm and its differential geometric abstraction--illustrating how good algorithms draw equally from the insights of differential geometry, optimization, and numerical analysis. Two more theoretical chapters provide readers with the background in differential geometry necessary to algorithmic development. In the other chapters, several well-known optimization methods such as steepest descent and conjugate gradients are generalized to abstract manifolds. The book provides a generic development of each of these methods, building upon the material of the geometric chapters. It then guides readers through the calculations that turn these geometrically formulated methods into concrete numerical algorithms. The state-of-the-art algorithms given as examples are competitive with the best existing algorithms for a selection of eigenspace problems in numerical linear algebra. Optimization Algorithms on Matrix Manifoldsoffers techniques with broad applications in linear algebra, signal processing, data mining, computer vision, and statistical analysis. It can serve as a graduate-level textbook and will be of interest to applied mathematicians, engineers, and computer scientists. {\textcopyright} 2008 by Princeton University Press. All Rights Reserved.},
author = {Absil, P. A. and Mahony, R. and Sepulchre, R.},
booktitle = {Optim. Algorithms Matrix Manifolds},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/Optimization{\_}Algorithms{\_}on{\_}Matrix{\_}Manifolds.pdf:pdf},
isbn = {9780691132983},
title = {{Optimization algorithms on matrix manifolds}},
year = {2009}
}
@article{Ginestet2017,
abstract = {In recent years, it has become common practice in neuroscience to use networks to summarize relational information in a set of measurements, typically assumed to be reflective of either functional or structural relationships between regions of interest in the brain. One of the most basic tasks of interest in the analysis of such data is the testing of hypotheses, in answer to questions such as "Is there a difference between the networks of these two groups of subjects?" In the classical setting, where the unit of interest is a scalar or a vector, such questions are answered through the use of familiar two-sample testing strategies. Networks, however, are not Euclidean objects, and hence classical methods do not directly apply. We address this challenge by drawing on concepts and techniques from geometry and high-dimensional statistical inference. Our work is based on a precise geometric characterization of the space of graph Laplacian matrices and a nonparametric notion of averaging due to Fr{\'{e}}chet. We motivate and illustrate our resulting method-ologies for testing in the context of networks derived from functional neu-roimaging data on human subjects from the 1000 Functional Connectomes Project. In particular, we show that this global test is more statistically powerful than a mass-univariate approach. In addition, we have also provided a method for visualizing the individual contribution of each edge to the overall test statistic.},
author = {Ginestet, Cedric E and Li, Jun and Balachandran, Prakash and Rosenberg, Steven and {Kolaczyk †}, Eric D},
doi = {10.1214/16-AOAS1015},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Ginestet et al. - 2017 - HYPOTHESIS TESTING FOR NETWORK DATA IN FUNCTIONAL NEUROIMAGING.pdf:pdf},
journal = {Ann. Appl. Stat.},
keywords = {Frechet mean,fMRI,graph Laplacian,hypothesis testing,matrix manifold,network data,object data},
number = {2},
pages = {725--750},
title = {{HYPOTHESIS TESTING FOR NETWORK DATA IN FUNCTIONAL NEUROIMAGING}},
volume = {11},
year = {2017}
}
@techreport{Zhaoa,
abstract = {We study the estimation of low rank matrices via nonconvex optimization. Compared with convex relaxation, nonconvex optimization exhibits superior empirical performance for large scale instances of low rank matrix estimation. However, the understanding of its theoretical guarantees are limited. In this paper, we define the notion of projected oracle divergence based on which we establish sufficient conditions for the success of nonconvex optimization. We illustrate the consequences of this general framework for matrix sensing. In particular, we prove that a broad class of nonconvex optimization algorithms, including alternating minimization and gradient-type methods, geometrically converge to the global optimum and exactly recover the true low rank matrices under standard conditions.},
author = {Zhao, Tuo and Wang, Zhaoran and Liu, Han},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Zhao, Wang, Liu - Unknown - A Nonconvex Optimization Framework for Low Rank Matrix Estimation ⇤.pdf:pdf},
title = {{A Nonconvex Optimization Framework for Low Rank Matrix Estimation ⇤}}
}
@inproceedings{Greene2010,
author = {Greene, Derek and Doyle, D{\'{o}}nal and Cunningham, P{\'{a}}draig},
booktitle = {2010 Int. Conf. Adv. Soc. Networks Anal. Min.},
doi = {10.1109/ASONAM.2010.17},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Greene, Doyle, Cunningham - 2010 - Tracking the Evolution of Communities in Dynamic Social Networks.pdf:pdf},
isbn = {978-1-4244-7787-6},
month = {aug},
pages = {176--183},
publisher = {IEEE},
title = {{Tracking the Evolution of Communities in Dynamic Social Networks}},
url = {http://ieeexplore.ieee.org/document/5562773/},
year = {2010}
}
@article{Lyzinski2017,
abstract = {In disciplines as diverse as social network analysis and neuroscience, many large graphs are believed to be composed of loosely connected smaller graph primitives, whose structure is more amenable to analysis We propose a robust, scalable, integrated methodology for community detection and community comparison in graphs. In our procedure, we first embed a graph into an appropriate Euclidean space to obtain a low-dimensional representation, and then cluster the vertices into communities. We next employ nonparametric graph inference techniques to identify structural similarity among these communities. These two steps are then applied recursively on the communities, allowing us to detect more fine-grained structure. We describe a hierarchical stochastic blockmodel - namely, a stochastic blockmodel with a natural hierarchical structure - and establish conditions under which our algorithm yields consistent estimates of model parameters and motifs, which we define to be stochastically similar groups of subgraphs. Finally, we demonstrate the effectiveness of our algorithm in both simulated and real data. Specifically, we address the problem of locating similar sub-communities in a partially reconstructed Drosophila connectome and in the social network Friendster.},
archivePrefix = {arXiv},
arxivId = {1503.02115},
author = {Lyzinski, Vince and Tang, Minh and Athreya, Avanti and Park, Youngser and Priebe, Carey E.},
doi = {10.1109/TNSE.2016.2634322},
eprint = {1503.02115},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Lyzinski et al. - 2017 - Community Detection and Classification in Hierarchical Stochastic Blockmodels(2).pdf:pdf},
issn = {23274697},
journal = {IEEE Trans. Netw. Sci. Eng.},
keywords = {Community detection,classification,hierarchical random graphs,stochastic blockmodel},
month = {jan},
number = {1},
pages = {13--26},
publisher = {IEEE Computer Society},
title = {{Community Detection and Classification in Hierarchical Stochastic Blockmodels}},
volume = {4},
year = {2017}
}
@article{Gao2015a,
abstract = {Network analysis is becoming one of the most active research areas in statistics. Significant advances have been made recently on developing theories, methodologies and algorithms for analyzing networks. However, there has been little fundamental study on optimal estimation. In this paper, we establish optimal rate of convergence for graphon estimation. For the stochastic block model with k clusters , we show that the optimal rate under the mean squared error is n −1 log k + k 2 /n 2. The minimax upper bound improves the existing results in literature through a technique of solving a quadratic equation. When k ≤ √ n log n, as the number of the cluster k grows, the minimax rate grows slowly with only a logarithmic order n −1 log k. A key step to establish the lower bound is to construct a novel subset of the parameter space and then apply Fano's lemma, from which we see a clear distinction of the nonparametric graphon estimation problem from classical nonparametric regression, due to the lack of identifia-bility of the order of nodes in exchangeable random graph models. As an immediate application, we consider nonparametric graphon estimation in a H{\"{o}}lder class with smoothness $\alpha$. When the smoothness $\alpha$ ≥ 1, the optimal rate of convergence is n −1 log n, independent of $\alpha$, while for $\alpha$ ∈ (0, 1), the rate is n −2$\alpha$/($\alpha$+1) , which is, to our surprise, identical to the classical nonparametric rate.},
annote = {Developed upper and minimax lower bounds for the risk of estimation of the matrix of connection probabilities.},
archivePrefix = {arXiv},
arxivId = {1410.5837v3},
author = {Gao, Chao and Lu, Yu and Zhou, Harrison H.},
doi = {10.1214/15-AOS1354},
eprint = {1410.5837v3},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gao, Lu, Zhou - 2015 - RATE-OPTIMAL GRAPHON ESTIMATION(3).pdf:pdf},
issn = {00905364},
journal = {Ann. Stat.},
keywords = {60G05,Graphon,Minimax rate,Network,Nonparametric regression,Stochastic block model,graphon,minimax rate,nonparametric regression,stochastic block model},
month = {dec},
number = {6},
pages = {2624--2652},
publisher = {Institute of Mathematical Statistics},
title = {{RATE-OPTIMAL GRAPHON ESTIMATION}},
volume = {43},
year = {2015}
}
@techreport{Gao2016,
abstract = {Biclustering structures in data matrices were first formalized in a seminal paper by John Hartigan (Hartigan, 1972) where one seeks to cluster cases and variables simultaneously. Such structures are also prevalent in block modeling of networks. In this paper, we develop a theory for the estimation and completion of matrices with biclustering structures, where the data is a partially observed and noise contaminated matrix with a certain underlying biclustering structure. In particular, we show that a constrained least squares estimator achieves minimax rate-optimal performance in several of the most important scenarios. To this end, we derive unified high probability upper bounds for all sub-Gaussian data and also provide matching minimax lower bounds in both Gaussian and binary cases. Due to the close connection of graphon to stochastic block models, an immediate consequence of our general results is a minimax rate-optimal estimator for sparse graphons.},
author = {Gao, Chao and Lu, Yu and Ma, Zongming and Zhou, Harrison H},
booktitle = {J. Mach. Learn. Res.},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2016 - Optimal Estimation and Completion of Matrices with Biclustering Structures.pdf:pdf},
keywords = {Biclustering,graphon,matrix completion,missing data,sparse network,stochastic block models},
pages = {1--29},
title = {{Optimal Estimation and Completion of Matrices with Biclustering Structures}},
volume = {17},
year = {2016}
}
@article{Boyd2010,
author = {Boyd, S and Parikh, N and Chu, E and Eckstein, J and Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
doi = {10.1561/2200000016},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Boyd et al. - 2010 - Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.pdf:pdf},
journal = {Found. Trends R Mach. Learn.},
number = {1},
pages = {1--122},
title = {{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}},
volume = {3},
year = {2010}
}
@article{Yang2011,
abstract = {Although a large body of work is devoted to finding communities in static social networks, only a few studies examined the dynamics of communities in evolving social networks. In this paper, we propose a dynamic stochastic block model for finding communities and their evolution in a dynamic social network. The proposed model captures the evolution of communities by explicitly modeling the transition of community memberships for individual nodes in the network. Unlike many existing approaches for modeling social networks that estimate parameters by their most likely values (i.e., point estimation), in this study, we employ a Bayesian treatment for parameter estimation that computes the posterior distributions for all the unknown parameters. This Bayesian treatment allows us to capture the uncertainty in parameter values and therefore is more robust to data noise than point estimation. In addition, an efficient algorithm is developed for Bayesian inference to handle large sparse social networks. Extensive experimental studies based on both synthetic data and real-life data demonstrate that our model achieves higher accuracy and reveals more insights in the data than several state-of-the-art algorithms. {\textcopyright} 2010 The Author(s).},
annote = {Assumes that for each node, its membership forms a Markov chain independent of other nodes; however, the connection probabilities do not change in time.

Employ a Bayesian treatment for parameter estimation that computes the posterior distributions for all the unknown parameters.},
author = {Yang, Tianbao and Chi, Yun and Zhu, Shenghuo and Gong, Yihong and Jin, Rong},
doi = {10.1007/s10994-010-5214-7},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Yang et al. - 2011 - Detecting communities and their evolutions in dynamic social networks - A Bayesian approach.pdf:pdf},
issn = {08856125},
journal = {Mach. Learn.},
keywords = {Bayesian inference,Community,Community evolution,Dynamic stochastic block model,Gibbs sampling,Social network},
month = {feb},
number = {2},
pages = {157--189},
title = {{Detecting communities and their evolutions in dynamic social networks - A Bayesian approach}},
volume = {82},
year = {2011}
}
@article{Keshavan2009,
abstract = {Given a matrix M of low-rank, we consider the problem of reconstructing it from noisy observations of a small, random subset of its entries. The problem arises in a variety of applications, from collaborative filtering (the `Netflix problem') to structure-from-motion and positioning. We study a low complexity algorithm introduced by Keshavan et al.(2009), based on a combination of spectral techniques and manifold optimization, that we call here OptSpace. We prove performance guarantees that are order-optimal in a number of circumstances.},
archivePrefix = {arXiv},
arxivId = {0906.2027},
author = {Keshavan, Raghunandan H. and Montanari, Andrea and Oh, Sewoong},
eprint = {0906.2027},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Keshavan, Montanari, Oh - 2009 - Matrix Completion from Noisy Entries.pdf:pdf},
month = {jun},
title = {{Matrix Completion from Noisy Entries}},
url = {http://arxiv.org/abs/0906.2027},
year = {2009}
}
@article{Klopp2015,
abstract = {The objective of the present paper is to develop a minimax theory for  the varying coefficient model in a nonasymptotic setting. We consider a high-dimensional sparse varying coefficient model where only few of the covariates are present and only some of those covariates are time dependent. Our analysis allows the time-dependent covariates to have different degrees of smoothness and to be spatially inhomogeneous. We develop the minimax lower bounds for the quadratic risk and construct an adaptive estimator which attains those lower bounds within a constant (if all time-dependent covariates are spatially homogeneous) or logarithmic factor of the number of observations.},
author = {Klopp, Olga and Pensky, Marianna},
doi = {10.1214/15-aos1309},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Klopp, Pensky - 2015 - Sparse high-dimensional varying coefficient model Nonasymptotic minimax study.pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
month = {jun},
number = {3},
pages = {1273--1299},
publisher = {Institute of Mathematical Statistics},
title = {{Sparse high-dimensional varying coefficient model: Nonasymptotic minimax study}},
volume = {43},
year = {2015}
}
@article{Sarkar2005,
abstract = {This paper explores two aspects of social network modeling. First, we generalize a successful static model of relationships into a dynamic model that accounts for friendships drifting over time. Second, we show how to make it tractable to learn such models from data, even as the number of entities n gets large. The generalized model associates each entity with a point in p-dimensional Euclidean latent space. The points can move as time progresses but large moves in latent space are improbable. Observed links between entities are more likely if the entities are close in latent space. We show how to make such a model tractable (sub-quadratic in the number of entities) by the use of appropriate kernel functions for similarity in latent space; the use of low dimensional KD-trees; a new efficient dynamic adaptation of multidimensional scaling for a first pass of approximate projection of entities into latent space; and an efficient conjugate gradient update rule for non-linear local optimization in which amortized time per entity during an update is O(log n). We use both synthetic and real-world data on up to 11,000 entities which indicate near-linear scaling in computation time and improved performance over four alternative approaches. We also illustrate the system operating on twelve years of NIPS co-authorship data.},
annote = {A dynamic version of the latent space model.

The latent points follow a (continuous state space) Markov chain, with transition kernel given by a Gaussian perturbation on the current position with zero mean and small variance.},
author = {Sarkar, Purnamrita and Moore, Andrew W.},
doi = {10.1145/1117454.1117459},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Sarkar, Moore - 2005 - Dynamic social network analysis using latent space models.pdf:pdf},
issn = {19310145},
journal = {ACM SIGKDD Explor. Newsl.},
month = {dec},
number = {2},
pages = {31--40},
title = {{Dynamic social network analysis using latent space models}},
url = {http://portal.acm.org/citation.cfm?doid=1117454.1117459},
volume = {7},
year = {2005}
}
@techreport{KaAlbert,
abstract = {Complex networks describe a wide range of systems in nature and society. Frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the Internet, a network of routers and computers connected by physical links. While traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. This article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. After reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network's robustness against failures and attacks. CONTENTS},
author = {ka Albert, R{\'{e}} and szl{\'{o}} Barab{\'{a}} si, Albert-L{\'{a}}},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/ka Albert, szl{\'{o}} Barab{\'{a}} si - Unknown - Statistical mechanics of complex networks.pdf:pdf},
title = {{Statistical mechanics of complex networks}}
}
@techreport{Wolfe,
abstract = {We propose a nonparametric framework for the analysis of networks , based on a natural limit object termed a graphon. We prove consistency of graphon estimation under general conditions, giving rates which include the important practical setting of sparse networks. Our results cover dense and sparse stochastic blockmodels with a growing number of classes, under model misspecification. We use profile likelihood methods, and connect our results to approximation theory, nonparametric function estimation, and the theory of graph limits.},
archivePrefix = {arXiv},
arxivId = {1309.5936v1},
author = {Wolfe, Patrick J and Olhede, Sofia C},
eprint = {1309.5936v1},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Wolfe, Olhede - Unknown - Nonparametric graphon estimation.pdf:pdf},
keywords = {05C80,62G05,62G20,graph limits,nonparametric regression,sparse random graphs,statistical network analysis,stochastic blockmodels},
title = {{Nonparametric graphon estimation}}
}
@article{Hoff2002,
abstract = { of pseu- dolikelihood estimators in this  have been  are more global than local in  and that  For  in which actors belong to prespeci ed },
annote = {Each node is associated with a point in a latent space and probability of connection is higher for nodes whose latent points are closer.},
author = {Hoff, Peter D. and Raftery, Adrian E. and Handcock, Mark S.},
doi = {10.1198/016214502388618906},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Hoff, Raftery, Handcock - 2002 - Latent space approaches to social network analysis.pdf:pdf},
issn = {01621459},
journal = {J. Am. Stat. Assoc.},
keywords = {Conditional independence model,Latent position model,Network data,Random graph,Visualization},
month = {dec},
number = {460},
pages = {1090--1098},
title = {{Latent space approaches to social network analysis}},
volume = {97},
year = {2002}
}
@article{Klopp2017,
abstract = {Inhomogeneous random graph models encompass many network models such as stochastic block models and latent position models. We consider the problem of statistical estimation of the matrix of connection probabilities based on the observations of the adjacency matrix of the network. Taking the stochastic block model as an approximation, we construct estimators of network connection probabilities-the ordinary block constant least squares estimator, and its restricted version. We show that they satisfy oracle inequalities with respect to the block constant oracle. As a consequence, we derive optimal rates of estimation of the probability matrix. Our results cover the important setting of sparse networks. Another consequence consists in establishing upper bounds on the minimax risks for graphon estimation in the L 2 norm when the probability matrix is sampled according to a graphon model. These bounds include an additional term accounting for the "agnostic" error induced by the variability of the latent unobserved variables of the graphon model. In this setting, the optimal rates are influenced not only by the bias and variance components as in usual nonparametric problems but also include the third component, which is the agnostic error. The results shed light on the differences between estimation under the empirical loss (the probability matrix estimation) and under the integrated loss (the graphon estimation). 1. Introduction. Consider a network defined as an undirected graph with n nodes. Assume that we observe the values A ij ∈ {\{}0, 1{\}} where A ij = 1 is interpreted as the fact that the nodes i and j are connected and A ij = 0 otherwise. We set A ii = 0 for all 1 ≤ i ≤ n and we assume that A ij is a Bernoulli random variable with parameter (0) ij = P(A ij = 1) for 1 ≤ j {\textless} i ≤ n. The random variables A ij , 1 ≤ j {\textless} i ≤ n, are assumed independent. We denote by A the adjacency matrix, that is, the n × n symmetric matrix with entries A ij for 1 ≤ j {\textless} i ≤ n and zero di},
author = {Klopp, Olga and Tsybakov, Alexandre B. and Verzelen, Nicolas},
doi = {10.1214/16-AOS1454},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Klopp, Tsybakov, Verzelen - 2017 - Oracle inequalities for network models and sparse graphon estimation.pdf:pdf},
issn = {00905364},
journal = {Ann. Stat.},
keywords = {Inhomogeneous random graph,Networks,Oracle inequality,Sparse graphon,Sparsity,Stochastic block model},
month = {feb},
number = {1},
pages = {316--354},
publisher = {Institute of Mathematical Statistics},
title = {{Oracle inequalities for network models and sparse graphon estimation}},
volume = {45},
year = {2017}
}
@article{Samelson1971,
abstract = {In this note we describe those additive mappings from a second symmetric product space to another, over a field of characteristic not 2 or 3, which preserve decomposable elements of the form ??u ??? u where u is a vector and ?? is a scalar. This leads to the corresponding result concerning additive mappings from one vector space of symmetric matrices to another which preserve rank less than or equal to one. We also discuss some consequences of this characterization theorem. ?? 2005 Elsevier Inc. All rights reserved.},
author = {Samelson, H. and Hobby, C. R. and Dugundji, J. and Arens, Richard},
file = {:Users/bgemily/Documents/Academic/SC/graphon/paper/pjm-v16-n1-p01-p.pdf:pdf},
issn = {00308730},
journal = {Pacific J. Math.},
number = {3},
pages = {1},
title = {{Pacific journal of mathematics}},
volume = {37},
year = {1971}
}
@techreport{Su2018,
abstract = {Estimating the probabilities of linkages in a network has gained increasing interest in recent years. One popular model for network analysis is the exchangeable graph model (ExGM) characterized by a two-dimensional function known as a graphon. Estimating an underlying graphon becomes the key of such analysis. Several nonparametric estimation methods have been proposed , and some are provably consistent. However, if certain useful features of the nodes (e.g., age and schools in social network context) are available, none of these methods was designed to incorporate this source of information to help with the estimation. This paper develops a consistent graphon estimation method that integrates the information from both the adjacency matrix itself and node features. We show that properly leveraging the features can improve the estimation. A cross-validation method is proposed to automatically select the tuning parameter of the method.},
archivePrefix = {arXiv},
arxivId = {1809.00420v1},
author = {Su, Yi and Wong, Raymond K W and Lee, Thomas C M},
eprint = {1809.00420v1},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Su, Wong, Lee - 2018 - Network estimation via graphon with node features.pdf:pdf},
keywords = {consistency,exchangeable graph model,feature assisted neighborhood smoothing (FANS),generative model,nonparametric},
title = {{Network estimation via graphon with node features}},
year = {2018}
}
@article{Sun2016,
abstract = {Matrix factorization is a popular approach for large-scale matrix completion. The optimization formulation based on matrix factorization can be solved very efficiently by standard algorithms in practice. However, due to the non-convexity caused by the factorization model, there is a limited theoretical understanding of this formulation. In this paper, we establish a theoretical guarantee for the factorization formulation to correctly recover the underlying low-rank matrix. In particular, we show that under similar conditions to those in previous works, many standard optimization algorithms converge to the global optima of a factorization formulation, and recover the true low-rank matrix. We study the local geometry of a properly regularized factorization formulation and prove that any stationary point in a certain local region is globally optimal. A major difference of our work from the existing results is that we do not need resampling in either the algorithm or its analysis. Compared to other works on nonconvex optimization, one extra difficulty lies in analyzing nonconvex constrained optimization when the constraint (or the corresponding regularizer) is not "consistent" with the gradient direction. One technical contribution is the perturbation analysis for non-symmetric matrix factorization.},
author = {Sun, Ruoyu and Luo, Zhi Quan},
doi = {10.1109/TIT.2016.2598574},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Sun, Luo - 2016 - Guaranteed Matrix Completion via Non-Convex Factorization.pdf:pdf},
issn = {00189448},
journal = {IEEE Trans. Inf. Theory},
keywords = {Matrix completion,Perturbation analysis,SGD,alternating minimization,matrix factorization,nonconvex optimization},
month = {nov},
number = {11},
pages = {6535--6579},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Guaranteed Matrix Completion via Non-Convex Factorization}},
volume = {62},
year = {2016}
}
@article{Xu2014,
abstract = {Significant efforts have gone into the development of statistical models for analyzing data in the form of networks, such as social networks. Most existing work has focused on modeling static networks, which represent either a single time snapshot or an aggregate view over time. There has been recent interest in statistical modeling of dynamic networks, which are observed at multiple points in time and offer a richer representation of many complex phenomena. In this paper, we present a state-space model for dynamic networks that extends the well-known stochastic blockmodel for static networks to the dynamic setting. We fit the model in a near-optimal manner using an extended Kalman filter (EKF) augmented with a local search. We demonstrate that the EKF-based algorithm performs competitively with a state-of-the-art algorithm based on Markov chain Monte Carlo sampling but is significantly less computationally demanding. {\textcopyright} 2007-2012 IEEE.},
annote = {introduce a state-space model through time on (the logit transform of) the probability of connection between groups

The network snap- shots are modeled using the stochastic blockmodel (SBM). The state evolution is modeled by a sto- chastic dynamic system.

both group membership and connectivity parameters across groups may vary through time.

Their (online) iterative estimation procedure is based on alternating two steps: a label-switching method to explore the space of node groups configuration, and the (extended) Kalman filter that optimizes the likelihood when the groups memberships are known},
archivePrefix = {arXiv},
arxivId = {1403.0921},
author = {Xu, Kevin S. and Hero, Alfred O.},
doi = {10.1109/JSTSP.2014.2310294},
eprint = {1403.0921},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Xu, Hero - 2014 - Dynamic stochastic blockmodels for time-evolving social networks(2).pdf:pdf},
issn = {19324553},
journal = {IEEE J. Sel. Top. Signal Process.},
keywords = {State-space social network model,dynamic network,extended Kalman filter,on-line estimation},
number = {4},
pages = {552--562},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Dynamic stochastic blockmodels for time-evolving social networks}},
volume = {8},
year = {2014}
}
@article{Candes2009a,
author = {Cand{\`{e}}s, Emmanuel J. and Recht, Benjamin},
doi = {10.1007/s10208-009-9045-5},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Cand{\`{e}}s, Recht - 2009 - Exact Matrix Completion via Convex Optimization.pdf:pdf},
issn = {1615-3375},
journal = {Found. Comput. Math.},
month = {dec},
number = {6},
pages = {717--772},
title = {{Exact Matrix Completion via Convex Optimization}},
url = {http://link.springer.com/10.1007/s10208-009-9045-5},
volume = {9},
year = {2009}
}
@techreport{Matias2016,
abstract = {Statistical node clustering in discrete time dynamic networks is an emerging field that raises many challenges. Here, we explore statistical properties and frequentist inference in a model that combines a stochastic block model (SBM) for its static part with independent Markov chains for the evolution of the nodes groups through time. We model binary data as well as weighted dynamic random graphs (with discrete or continuous edges values). Our approach, motivated by the importance of controlling for label switching issues across the different time steps, focuses on detecting groups characterized by a stable within group connectivity behavior. We study identifiability of the model parameters , propose an inference procedure based on a variational expectation maximization algorithm as well as a model selection criterion to select for the number of groups. We carefully discuss our initialization strategy which plays an important role in the method and compare our procedure with existing ones on synthetic datasets. We also illustrate our approach on dynamic contact networks, one of encounters among high school students and two others on animal interactions. An implementation of the method is available as a R package called dynsbm.},
annote = {Infer the number of clusters?},
archivePrefix = {arXiv},
arxivId = {1506.07464v2},
author = {Matias, Catherine and Miele, Vincent},
eprint = {1506.07464v2},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Matias, Miele - 2016 - Statistical clustering of temporal networks through a dy-namic stochastic block model.pdf:pdf},
isbn = {1506.07464v2},
keywords = {()},
title = {{Statistical clustering of temporal networks through a dy-namic stochastic block model}},
url = {http://lbbe.univ-lyon1.fr/dynsbm},
year = {2016}
}
@article{Kim2018,
abstract = {We present a selective review of statistical modeling of dynamic networks. We focus on models with latent variables, specifically, the latent space models and the latent class models (or stochastic blockmodels), which investigate both the observed features and the unobserved structure of networks. We begin with an overview of the static models, and then we introduce the dynamic extensions. For each dynamic model, we also discuss its applications that have been studied in the literature, with the data source listed in Appendix. Based on the review, we summarize a list of open problems and challenges in dynamic network modeling with latent variables. MSC 2010 subject classifications: Primary 62-02, 62-07; secondary 05C90.},
annote = {A review of invariant models based on latent space model and stochastic block model.},
author = {Kim, Bomin and Lee, Kevin H and Xue, Lingzhou and Niu, Xiaoyue},
doi = {10.1214/18-SS121},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Kim et al. - 2018 - A review of dynamic network models with latent variables.pdf:pdf},
issn = {1935-7516},
journal = {Stat. Surv.},
keywords = {Dynamic networks,latent space model,latent variable model,social network analysis,stochastic blockmodel},
pages = {105--135},
title = {{A review of dynamic network models with latent variables}},
url = {https://doi.org/10.1214/18-SS121},
volume = {12},
year = {2018}
}
@article{Airoldi2013,
abstract = {Non-parametric approaches for analyzing network data based on exchangeable graph models (ExGM) have recently gained interest. The key object that defines an ExGM is often referred to as a graphon. This non-parametric perspective on network modeling poses challenging questions on how to make inference on the graphon underlying observed network data. In this paper, we propose a computationally efficient procedure to estimate a graphon from a set of observed networks generated from it. This procedure is based on a stochastic blockmodel approximation (SBA) of the graphon. We show that, by approximating the graphon with a stochastic block model, the graphon can be consistently estimated, that is, the estimation error vanishes as the size of the graph approaches infinity.},
archivePrefix = {arXiv},
arxivId = {1311.1731},
author = {Airoldi, Edoardo M and Costa, Thiago B and Chan, Stanley H},
eprint = {1311.1731},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Airoldi, Costa, Chan - 2013 - Stochastic blockmodel approximation of a graphon Theory and consistent estimation(2).pdf:pdf},
month = {nov},
title = {{Stochastic blockmodel approximation of a graphon: Theory and consistent estimation}},
url = {http://arxiv.org/abs/1311.1731},
year = {2013}
}
@article{Gupta2000,
abstract = {We propose matrix-variate beta type III distribution. Several properties of this distribution including Laplace transform, marginal distribution and its relationship with matrix-variate beta type I and type II distributions are also studied.},
author = {Gupta, Arjun K. and Nagar, Daya K.},
doi = {10.1155/s0161171200002398},
file = {:Users/bgemily/Library/Application Support/Mendeley Desktop/Downloaded/Gupta, Nagar - 2000 - Matrix-variate beta distribution.pdf:pdf},
issn = {0161-1712},
journal = {Int. J. Math. Math. Sci.},
number = {7},
pages = {449--459},
publisher = {Hindawi Limited},
title = {{Matrix-variate beta distribution}},
volume = {24},
year = {2000}
}
